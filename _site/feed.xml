<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="http://greydanus.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://greydanus.github.io/" rel="alternate" type="text/html" /><updated>2021-06-28T19:30:01-07:00</updated><id>http://greydanus.github.io/feed.xml</id><title type="html">Natural Intelligence</title><subtitle>A science blog by Sam Greydanus</subtitle><entry><title type="html">Piecewise-constant Neural ODEs</title><link href="http://greydanus.github.io/2021/06/11/piecewise-nodes/" rel="alternate" type="text/html" title="Piecewise-constant Neural ODEs" /><published>2021-06-11T04:00:00-07:00</published><updated>2021-06-11T04:00:00-07:00</updated><id>http://greydanus.github.io/2021/06/11/piecewise-nodes</id><content type="html" xml:base="http://greydanus.github.io/2021/06/11/piecewise-nodes/">&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;&quot;&gt;
    &lt;video id=&quot;video_sim&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
    	&lt;source src=&quot;/assets/piecewise-nodes/video_simulator_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_sim_button&quot; onclick=&quot;playPauseSim()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align: left;margin-left:10px;margin-right:10px;&quot;&gt;Using model-based planning to play billiards. The goal is to impart the tan cue ball with an initial velocity so as to move the blue ball to the black target.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;&quot;&gt;
    &lt;video id=&quot;video_base&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
    	&lt;source src=&quot;/assets/piecewise-nodes/video_base_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_base_button&quot; onclick=&quot;playPauseBase()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align:left;margin-left:10px;margin-right:10px;&quot;&gt;A baseline ODE-RNN trained on billiards dynamics can also be used for model-based planning. It&apos;s inefficient because it has to &quot;tick&quot; at a constant rate.&lt;/div&gt;
  &lt;/div&gt;
   &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;&quot;&gt;
    &lt;video id=&quot;video_ours&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
    	&lt;source src=&quot;/assets/piecewise-nodes/video_ours_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_ours_button&quot; onclick=&quot;playPauseOurs()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align:left;margin-left:10px;margin-right:10px;&quot;&gt;By contrast, our model, trained on the same task, can perform planning in many fewer steps by jumping over spans of time where motion is predictable.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt; 
function playPauseSim() { 
  var video = document.getElementById(&quot;video_sim&quot;); 
  var button = document.getElementById(&quot;video_sim_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 

function playPauseBase() { 
  var video = document.getElementById(&quot;video_base&quot;); 
  var button = document.getElementById(&quot;video_base_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 

function playPauseOurs() { 
  var video = document.getElementById(&quot;video_ours&quot;); 
  var button = document.getElementById(&quot;video_ours_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 
&lt;/script&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://arxiv.org/abs/2106.06621&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://github.com/greydanus/piecewise_node#run-in-your-browser&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;colab-span&quot;&gt;Run&lt;/span&gt; in browser&lt;/a&gt;
	&lt;a href=&quot;https://github.com/greydanus/piecewise_node&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;change-it-is-said-happens-slowly-and-then-all-at-once&quot;&gt;Change, it is said, happens slowly and then all at once…&lt;/h2&gt;

&lt;p&gt;Billiards balls move across a table before colliding and changing trajectories; water molecules cool slowly and then undergo a rapid phase transition into ice; and economic systems enjoy periods of stability interspersed with abrupt market downturns. That is to say, many time series exhibit periods of relatively homogeneous change divided by important events. Despite this, recurrent neural networks (RNNs), popular for time series modeling, treat time in uniform intervals – potentially wasting prediction resources on long intervals of relatively constant change.&lt;/p&gt;

&lt;p&gt;A recent family of models called &lt;a href=&quot;https://arxiv.org/abs/1806.07366&quot;&gt;Neural ODEs&lt;/a&gt; has attracted interest as a means of mitigating these problems. They parameterize the &lt;em&gt;time derivative&lt;/em&gt; of a hidden state with a neural network and then integrate it over arbitrary amounts of time. This allows them to treat time as a continuous variable. Integration can even be performed using adaptive integrators like &lt;a href=&quot;https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods&quot;&gt;Runge-Kutta&lt;/a&gt;, thus allocating more compute to difficult state transitions.&lt;/p&gt;

&lt;p&gt;Adaptive integration is especially attractive in scenarios where “key events” are separated by variable amounts of time. In the game of billiards, these key events may consist of collisions between balls, walls, and pockets. Between these events, the balls simply undergo linear motion. That motion is not difficult to predict, but it is non-trivial for a model to learn to skip over it so as to focus on the more chaotic dynamics of collisions; this requires a model to employ some notion of &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0004370299000521&quot;&gt;&lt;em&gt;temporal abstraction&lt;/em&gt;&lt;/a&gt;. This problem is not unique to billiards. The same challenge occurs in robotics, where a robot arm occasionally interacts with external objects at varying intervals. It may also occur in financial markets, scientific timeseries, and other environments where change happens at a variable rate.&lt;/p&gt;

&lt;h2 id=&quot;towards-temporally-abstract-hidden-state-dynamics&quot;&gt;Towards temporally-abstract hidden state dynamics&lt;/h2&gt;

&lt;p&gt;In this post, I am going to introduce a special case of Neural ODEs that my research group has been experimenting with recently. The core idea is to restrict the hidden state of a Neural ODE so that it has locally-linear dynamics. The benefit of such a model is that it can be integrated &lt;em&gt;exactly&lt;/em&gt; using Euler integration, and it can also be integrated &lt;em&gt;adaptively&lt;/em&gt; because we allow these locally-linear dynamics to extend over variable-sized durations of time. Like RNNS and Neural ODEs, our model uses a hidden state \(h\) to summarize knowledge about the world at a given point in time. Also, it performs updates on this hidden state using cell updates (eg. with vanilla, LSTM, or GRU cells). But our model differs from existing models in that the amount of simulation time that occurs between cell updates is not fixed. Rather, it changes according to the variable \(\Delta t\), which is itself predicted.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
  &lt;img src=&quot;/assets/piecewise-nodes/hero.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Our model also predicts a &lt;em&gt;hidden state velocity&lt;/em&gt;, \(\dot h\), at each cell update; this enables us to evolve the hidden state dynamics continuously over time according to \(h(t+\Delta t) = h + \dot h \Delta t\). In other words, the hidden state velocity allows us to parameterize &lt;em&gt;the locally-linear dynamics of the hidden state&lt;/em&gt;. Thus when our model needs to simulate long spans of homogeneous change (eg, a billiard ball undergoing linear motion), it can do so with a single cell update.&lt;/p&gt;

&lt;p&gt;In order to compare our model to existing timeseries models (RNNs and Neural ODEs), we used both of them to model a series of simple physics problems including the collisions of two billiards balls. We found that our jumpy model was able to learn these dynamics at least as well as the baseline while using a fraction of the forward simulation steps. This makes it a great candidate for model-based planning because it can predict the outcome of taking an action much more quickly than a baseline model. And since the hidden-state dynamics are piecewise-linear over time, we can solve for the hidden state at arbitrary points along a trajectory. This allows us to simulate the dynamics &lt;em&gt;at a higher temporal resolution than the original training data&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
    &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;&quot;&gt;
    &lt;video id=&quot;video_sim2&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
      &lt;source src=&quot;/assets/piecewise-nodes/video_sim_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_sim2_button&quot; onclick=&quot;playPauseSim2()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align: left;margin-left:10px;margin-right:10px;&quot;&gt;This video will give you a sense of the underlying temporal resolution of the billiards dataset on which we trained the model.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;&quot;&gt;
    &lt;video id=&quot;video_interp&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
    	&lt;source src=&quot;/assets/piecewise-nodes/video_interp_2.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_interp_button&quot; onclick=&quot;playPauseInterp()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align:left;margin-left:10px;&quot;&gt;This video shows how we can use our model to generate simulations at a higher temporal resolution than that of the original simulator. 
&lt;!--     We can do this because the latent dynamics of the model are continuous and piecewise-linear in time. --&gt;
  &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt; 
function playPauseSim2() { 
  var video = document.getElementById(&quot;video_sim2&quot;); 
  var button = document.getElementById(&quot;video_sim2_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 

function playPauseJumpy2() { 
  var video = document.getElementById(&quot;video_jumpy2&quot;); 
  var button = document.getElementById(&quot;video_jumpy2_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 

function playPauseInterp() { 
  var video = document.getElementById(&quot;video_interp&quot;); 
  var button = document.getElementById(&quot;video_interp_button&quot;);
  if (video.paused) {
    video.play();
	button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
	button.textContent = &quot;Play&quot;;}
} 
&lt;/script&gt;

&lt;p&gt;I am going to give more specific examples of how our model improves over regular timeseries models later. But first we need to talk about what these timeseries models are good at and why they are worth improving in the first place.&lt;/p&gt;

&lt;h2 id=&quot;the-value-of-timeseries-models&quot;&gt;The value of timeseries models&lt;/h2&gt;

&lt;p&gt;Neural network-based timeseries models like RNNs and Neural ODEs are interesting because they can learn complex, long-range structure in time series data simply by predicting one point at a time. For example, if you train them on observations of a robot arm, you can use them to generate realistic paths that the arm might take.&lt;/p&gt;

&lt;p&gt;One of the things that makes these models so flexible is that they use a hidden vector \(h\) to store memories of past observations. And they can &lt;em&gt;learn&lt;/em&gt; to read, write, and erase information from \(h\) in order to make accurate predictions about the future. RNNs do this in discrete steps whereas Neural ODEs permit hidden state dynamics to be continuous in time. Both models are Turing-complete and, unlike other models that are Turing-complete (eg. HMMs or FSMs), they can learn and operate on noisy, high-dimensional data. Here is an incomplete list of things people have trained these models (mostly RNNs) to do:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-&quot;&gt;Translate text from one language to another&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openai.com/blog/solving-rubiks-cube/&quot;&gt;Control a robot hand in order to solve a Rubik’s Cube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rdcu.be/bVI7G&quot;&gt;Defeat professional human gamers in StarCraft&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openaccess.thecvf.com/content_cvpr_2016/html/Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.html&quot;&gt;Caption images&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1308.0850&quot;&gt;Generate realistic handwriting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.isca-speech.org/archive/interspeech_2014/i14_1964.html&quot;&gt;Convert text to speech&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.jmlr.org/proceedings/papers/v48/amodei16.html&quot;&gt;Convert speech to text&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.03477&quot;&gt;Sketch simple images&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://greydanus.github.io/2017/01/07/enigma-rnn/&quot;&gt;Learn the Enigma cipher&lt;/a&gt; [one of my first projects :D]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.03907&quot;&gt;Predict patient ICU data such as aiastolic arterial blood pressure&lt;/a&gt; [Neural ODEs]&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;limitations-of-these-sequence-models&quot;&gt;Limitations of these sequence models&lt;/h2&gt;

&lt;p&gt;Let’s begin with the limitations of RNNs, use them to motivate Neural ODEs, and then discuss the contexts in which even Neural ODEs have shortcomings. The first and most serious limitation of RNNs is that they can only predict the future by way of discrete, uniform “ticks”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Uniform ticks.&lt;/strong&gt; At each tick they make one observation of the world, perform one read-erase-write operation on their memory, and output one state vector. This seems too rigid. We wouldn’t divide our perception of the world into uniform segments of, say, ten minutes. This would be silly because the important events of our daily routines are not spaced equally apart.&lt;/p&gt;

&lt;p&gt;Consider the game of billiards. When you prepare to strike the cue ball, you imagine how it will collide with other balls and eventually send one of them into a pocket. And when you do this, you do not think about the constant motion of the cue ball as it rolls across the table. Instead, you think about the near-instantaneous collisions between the cue ball, walls, and pockets. Since these collisions are separated by variable amounts of time, making this plan requires that you jump from one collision event to another without much regard for the intervening duration. This is something that RNNs cannot do.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
    &lt;div style=&quot;width:100%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;padding-right:10px;&quot;&gt;
    &lt;video id=&quot;video_pool&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
      &lt;source src=&quot;/assets/piecewise-nodes/pool_shot.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;video_pool_button&quot; onclick=&quot;playPausePool()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align: left;&quot;&gt;A professional pool player making a remarkable shot. We&apos;ll never know exactly what was going through his head when he did this, but we can say at the very least he was planning over a sequence of collisions. An RNN, by contrast, would focus most of its compute on simulating the linear motion of the ball in between collisions.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt; 
function playPausePool() { 
  var video = document.getElementById(&quot;video_pool&quot;); 
  var button = document.getElementById(&quot;video_pool_button&quot;);
  if (video.paused) {
    video.play();
  button.textContent = &quot;Pause&quot;;}
  else {
    video.pause(); 
  button.textContent = &quot;Play&quot;;}
} 
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Discrete time steps.&lt;/strong&gt; Another issue with RNNs is that they perceive time as a series of discrete “time steps” that connect neighboring states. Since time is actually a continuous variable – it has a definite value even in between RNN ticks – we really should use models that treat it as such. In other words, when we ask our model what the world looked like at time \( t=1.42\) seconds, it should not have to locate the two ticks that are nearest in time and then interpolate between them, as is the case with RNNs. Rather, it should be able to give a well-defined answer.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Avoiding discrete, uniform timesteps with Neural ODEs.&lt;/strong&gt; These problems represent some of the core motivations for Neural ODEs. Neural ODEs parameterize the time derivative of the hidden state and, when combined with an ODE integrator, can be used to model dynamical systems where time is a continuous variable. These models represent a young and rapidly expanding area of machine learning research. One unresolved challenge with these models is getting them to run efficiently with adaptive ODE integrators…&lt;/p&gt;

&lt;p&gt;The problem is that adaptive ODE integrators must perform several function evaluations in order to estimate local curvature when performing an integration step. The curvature information determines how far the integrator can step forward in time, subject to a constant error budget. This is a particularly serious issue in the context of neural networks, which may have very irregular local curvatures at initialization. A single Neural ODE training step can take up to five times longer to evaluate than a comparable RNN architecture, making it challenging to scale these models.&lt;sup id=&quot;fnref:fn7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn7&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; The curvature problem has, in fact, already motivated some work on regularizing the curvature of Neural ODEs so as to train them more efficiently.&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; But even with regularization, these models are more difficult to train than RNNs. Furthermore, there are many tasks where regularizing curvature is counterproductive, for example, modeling elastic collisions between two bodies.&lt;sup id=&quot;fnref:fn18&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn18&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;our-results&quot;&gt;Our Results&lt;/h2&gt;

&lt;p&gt;Our work on piecewise-constant Neural ODEs was an attempt to fix these issues. Our model can jump over different durations of time and can tick more often when a lot is happening and less often otherwise. As I explained earlier, these models are different from regular RNNs in that they predict a hidden state velocity in addition to a hidden state. Taken together, these two quantities represent a linear dynamics function in the RNN’s latent space. A second modification is to have the model predict the duration of time \(\Delta t\) over which its dynamics functions are valid. In some cases, when change is happening at a constant rate, this value can be quite large.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning linear motion.&lt;/strong&gt; To show this more clearly, we conducted a simple toy experiment. We created a toy dataset of perfectly linear motion and checked to see whether our model would learn to summarize the whole thing in one step. As the figure below shows, it learned to do exactly that. Meanwhile, the regular RNN had to summarize the same motion in a series of tiny steps.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
  &lt;img src=&quot;/assets/piecewise-nodes/lines.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Learning a change of basis.&lt;/strong&gt; Physicists will tell you that the way a system changes over time is only linear with respect to a particular coordinate system. For example, an object undergoing constant circular motion has nonlinear dynamics when we use Cartesian coordinates, but linear dynamics when we use polar coordinates. That’s why physicists use different coordinates to describe different physical systems: &lt;u&gt;&lt;i&gt;all else being equal, the best coordinates are those that are maximally linear with respect to the dynamics.&lt;/i&gt;&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;Since our model forces dynamics to be linear in latent space, the encoder and decoder layers naturally learn to transform input data into a basis where the dynamics are linear. For example, when we train our model on a dataset of circular trajectories represented in Cartesian coordinates, it learns to summarize such trajectories in a single step. This implies that our model has learned a Cartesian-to-Polar change of basis.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
  &lt;img src=&quot;/assets/piecewise-nodes/circles.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Learning from pixel videos.&lt;/strong&gt; Our model can learn more complicated change-of-basis functions as well. Later in the paper, we trained our model on pixel observations of two billiards balls. The pixel “coordinate system” is extremely nonlinear with respect to the linear motion of the two balls. And yet our model was able to predict the dynamics of the system far more effectively than the baseline model, while using three times fewer “ticks”. The fact that our model could make jumpy predictions on this dataset implies that it found a basis where the billiards dynamics were linear for significant durations of time – something that is strictly impossible in a pixel basis.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
  &lt;img src=&quot;/assets/piecewise-nodes/pixel_billiards.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;In fact, we suspect that forcing dynamics to be linear in latent space actually biased our model to find linear dynamics. We hypothesize that the baseline model performed worse on this task because it had no such inductive bias. This is generally a good inductive bias to build into a model because most real-world dynamics can be approximated with piecewise-linear functions&lt;/p&gt;

&lt;h2 id=&quot;planning&quot;&gt;Planning&lt;/h2&gt;

&lt;p&gt;One of the reasons we originally set out to build this model was that we wanted to use it for planning. We were struck by the fact that many events one would want to plan over – collisions, in the case of billiards – are separated by variable durations of time. We suspected that a model that could jump through uneventful time intervals would be particularly effective at planning because it could plan over the events that really mattered (eg, collisions).&lt;/p&gt;

&lt;p&gt;In order to test this hypothesis, we compared our model to RNN and ODE-RNN baselines on a simple planning task in the billiards environment. The goal was to impart one ball, the “cue ball” (visualized in tan) with an initial velocity such that it would collide with the second ball and the second ball would ultimately enter a target region (visualized in black). You can see videos of such plans at the beginning of this post.&lt;/p&gt;

&lt;p&gt;We found that our model used at least half the wall time of the baselines and produced plans with a higher probability of success. These results are preliminary – and part of ongoing work – but they do support our initial hypothesis.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Simulator&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Baseline RNN&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Baseline ODE-RNN&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Our model&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.2%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;55.6%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;17.0%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;61.6%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
  &lt;img src=&quot;/assets/piecewise-nodes/planning2d.png&quot; style=&quot;width:45%&quot; /&gt;
&lt;/div&gt;

&lt;!-- Quite a few researchers have wrestled with the fact that RNNs tick through time at a uniform rate. So there are a number of recent projects that aim to make RNNs more temporally abstract. Our work is related, and hopefully complementary, to these approaches. --&gt;

&lt;h2 id=&quot;related-work-aside-from-rnns-and-neural-odes&quot;&gt;Related work aside from RNNs and Neural ODEs&lt;/h2&gt;

&lt;!-- Quite a few researchers have wrestled with the same limitations of RNNs that we have. So there are a number of related works aimed at solving the same issues. Among the most relevant of these works is a family of models called Neural ODEs.

**Neural ODEs.** The past few years have seen a surge of interest in these models. The basic idea of a Neural ODE is to parameterize the derivative of some variable with a neural network and then integrate it. For example, if you wanted to obtain the continuous-time dynamics of a hidden state \\(h_t\\), you would start by setting \\(\frac{\partial h_t}{\partial t}=f_{NN}(h_t)\\) where \\(f_{NN}\\) is a neural network. Then you could integrate that function over time to get dynamics:

$$ h_{t_1} ~=~ h_{t_0} + \int_{t_0}^{t_1} f_{NN}(h_t) ~~ dt $$

One of the remarkable things about this approach is that you can literally integrate your model with an ODE integrator, eg. ``scipy.integrate.solve_ivp``. Likewise, you can backpropagate error signals to your model with a second call to the integrator.

**Connection to our work.** Neural ODEs can be integrated _adaptively_; in other words, the size of the integration step can be made proportional to the local curvature. So in theory, if one were to regularize a Neural ODE to have very low curvature, one might be able to see the same jumpy behavior that we document in Jumpy RNNs. In practice, figuring out how to properly regularize the curvature of these models remains an open question.[^fn6] And current versions of Neural ODEs tend to be _more_ computationally demanding to evaluate than regular RNN models. In a recent paper about modeling RNN hidden state dynamics with ODEs[^fn7], for example, the authors mention that the ODE forward passes took 60% -- 120% longer than standard RNNs since they had to be continuously solved even when no observations were occurring.

Jumpy RNNs resemble Neural ODEs in that they parameterize the derivative of a hidden state. But unlike Neural ODEs, Jumpy RNNs assume that the function being integrated is piecewise-linear and they do not require an ODE solver. The local linearity assumption makes our model extremely efficient to integrate over long spans of time -- much more efficient, for example, than a baseline RNN, and by extension, a Neural ODE.[^fn0]

**Other related works.**  --&gt;

&lt;p&gt;Quite a few researchers have wrestled with the same limitations of RNNs and Neural ODEs that we have in this post. For example, there are a number of other RNN-based models designed with temporal abstraction in mind: Koutnik et al. (2014)&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; proposed dividing an RNN internal state into groups and only performing cell updates on the \(i^{th}\) group after \(2^{i-1}\) time steps. More recent works have aimed to make this hierarchical structure more adaptive, either by data-specific rules&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; or by a learning  mechanism&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. But although these hierarchical recurrent models can model data at different timescales, they still must perform cell updates at every time step in a sequence and cannot jump over regions of homogeneous change.&lt;/p&gt;

&lt;p&gt;For a discussion of these methods (and many others), check out &lt;a href=&quot;https://arxiv.org/abs/2106.06621&quot;&gt;the full paper&lt;/a&gt;, which we link to at the top of this post.
&lt;!-- Another relevant work from reinforcement learning is &quot;Embed to Control&quot;[^fn5]. This work is similar to ours in that it assumes that dynamics are linear in latent space. But unlike our work, the E2C model performs inference over discrete, uniform time steps and does not learn a jumpy behavior. --&gt;&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;

&lt;p&gt;Neural networks are already a widely used tool, but they still have fundamental limitations. In this post, we reckoned with the fact that they struggle at adaptive timestepping and the computational expense of integration. In order to make RNNs and Neural ODEs more useful in more contexts, it is essential to find solutions to such restrictions. With this in mind, we proposed a PC-ODE model which can skip over long durations of comparatively homogeneous change and focus on pivotal events as the need arises. We hope that this line of work will lead to models that can represent time more efficiently and flexibly.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Yulia Rubanova, Ricky TQ Chen, and David Duvenaud. &lt;a href=&quot;https://papers.nips.cc/paper/8773-latent-ordinary-differential-equations-for-irregularly-sampled-time-series&quot;&gt;Latent odes for irregularly-sampled time series&lt;/a&gt;. &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;, 2019. &lt;a href=&quot;#fnref:fn7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Chris Finlay, Jörn-Henrik Jacobsen, Levon Nurbekyan, and Adam M Oberman. &lt;a href=&quot;https://arxiv.org/abs/2002.02798&quot;&gt;How to train your neural ode: the world of jacobian and kinetic regularization&lt;/a&gt;. &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;, 2020. &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn18&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jia, Junteng, and Austin R. Benson. &lt;a href=&quot;https://papers.nips.cc/paper/2019/hash/59b1deff341edb0b76ace57820cef237-Abstract.html&quot;&gt;Neural jump stochastic differential equations&lt;/a&gt;. Neural Information Processing Systems, 2019 &lt;a href=&quot;#fnref:fn18&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jan Koutnik, Klaus Greff, Faustino Gomez, and Juergen Schmidhuber. &lt;a href=&quot;https://arxiv.org/abs/1402.3511&quot;&gt;A Clockwork RNN&lt;/a&gt;. &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;, pp. 1863–1871, 2014. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Wang Ling, Isabel Trancoso, Chris Dyer, and Alan W Black. &lt;a href=&quot;https://arxiv.org/abs/1511.04586&quot;&gt;Character-based neural machine translation&lt;/a&gt;. &lt;em&gt;Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics&lt;/em&gt;, 2015. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Junyoung Chung, Sungjin Ahn, and Yoshua Bengio. &lt;a href=&quot;https://arxiv.org/abs/1609.01704&quot;&gt;Hierarchical multiscale recurrent neural networks&lt;/a&gt;. &lt;em&gt;5th International Conference on Learning Representations&lt;/em&gt;, ICLR 2017. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Sam Greydanus, Stefan Lee, and Alan Fern</name></author><summary type="html">We propose a timeseries model that can be adaptively integrated. It jumps over simulation steps that are predictable and spends more time on those that are not.</summary></entry><entry><title type="html">Scaling down Deep Learning</title><link href="http://greydanus.github.io/2020/12/01/scaling-down/" rel="alternate" type="text/html" title="Scaling down Deep Learning" /><published>2020-12-01T03:00:00-08:00</published><updated>2020-12-01T03:00:00-08:00</updated><id>http://greydanus.github.io/2020/12/01/scaling-down</id><content type="html" xml:base="http://greydanus.github.io/2020/12/01/scaling-down/">&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px&quot;&gt;
    &lt;div style=&quot;min-width:250px; vertical-align: top; text-align:center;&quot;&gt;
    &lt;video id=&quot;demoDisplay&quot; style=&quot;width:100%;min-width:250px;&quot;&gt;
    	&lt;source src=&quot;/assets/scaling-down/construction.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
    &lt;button class=&quot;playbutton&quot; id=&quot;demo_button&quot; onclick=&quot;playPauseDemo()&quot;&gt;Play&lt;/button&gt; 
    &lt;div style=&quot;text-align:left;&quot;&gt;Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.&lt;/div&gt;
  	&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function playPauseDemo() { 
	  var video = document.getElementById(&quot;demoDisplay&quot;);
	  var button = document.getElementById(&quot;demo_button&quot;);
	  if (video.paused) {
	    video.play();
		button.textContent = &quot;Pause&quot;;}
	  else {
	    video.pause(); 
		button.textContent = &quot;Play&quot;;}
	} 
&lt;/script&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://arxiv.org/abs/2011.14439&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://bit.ly/3fghqVu&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;colab-span&quot;&gt;Run&lt;/span&gt; in browser&lt;/a&gt;
	&lt;a href=&quot;https://github.com/greydanus/mnist1d&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;By any scientific standard, the Human Genome Project &lt;a href=&quot;https://deepblue.lib.umich.edu/handle/2027.42/62798&quot;&gt;was enormous&lt;/a&gt;: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/10746727/&quot;&gt;Feany and Bender (2000)&lt;/a&gt;, can teach us an astonishing amount about humans.&lt;/p&gt;

&lt;p&gt;The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including &lt;a href=&quot;https://jmlr.org/papers/v15/srivastava14a.html&quot;&gt;dropout&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam&lt;/a&gt;, &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf&quot;&gt;convolutional networks&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;generative adversarial networks&lt;/a&gt;, and &lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;variational autoencoders&lt;/a&gt; began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.&lt;/p&gt;

&lt;p&gt;They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and &lt;a href=&quot;https://arxiv.org/abs/2004.08900&quot;&gt;hundreds of thousands of dollars&lt;/a&gt; of electricity to train.&lt;/p&gt;

&lt;p&gt;Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.&lt;/p&gt;

&lt;p&gt;In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:50%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/overview_a.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;padding-bottom: 20px;padding-right:10px&quot;&gt;Constructing the MNIST-1D dataset. Like MNIST, the classifier&apos;s objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:49.4%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/overview_b.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/tsne.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to &lt;a href=&quot;https://twitter.com/hippopedoid&quot;&gt;Dmitry Kobak&lt;/a&gt; for making this plot.&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;example-use-cases&quot;&gt;Example use cases&lt;/h2&gt;

&lt;p&gt;In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding lottery tickets.&lt;/strong&gt; It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by &lt;a href=&quot;https://arxiv.org/abs/1803.03635&quot;&gt;Frankle &amp;amp; Carbin (2019)&lt;/a&gt; challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.&lt;/p&gt;

&lt;p&gt;Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also &lt;a href=&quot;https://bit.ly/3nCEIaL&quot;&gt;reproduce these results&lt;/a&gt; in their browser in a few minutes.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/lottery_a1.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/lottery_a2.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Finding and analyzing lottery tickets. In &lt;b&gt;a-b)&lt;/b&gt;, we isolate a &quot;minimum viable example&quot; of the effect. Recent work by &lt;a href=&quot;https://arxiv.org/abs/1906.02773&quot;&gt;Morcos et al (2019)&lt;/a&gt; shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in &lt;b&gt;c)&lt;/b&gt; we plot the asymptotic performance of a 92% sparse ticket. In &lt;b&gt;d)&lt;/b&gt; we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/lottery_b1.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/lottery_b2.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
    &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Next, in &lt;b&gt;e)&lt;/b&gt; we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket&apos;s performance can be attributed to a spatial inductive bias. Finally, in &lt;b&gt;f)&lt;/b&gt; we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in &lt;a href=&quot;https://arxiv.org/abs/1803.03635&quot;&gt;Frankle &amp;amp; Carbin (2019)&lt;/a&gt;, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In &lt;b&gt;g)&lt;/b&gt;, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps give rise to spatial biases.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;You can also visualize the actual masks selected via random and lottery pruning:
&lt;br /&gt;&lt;button class=&quot;playbutton&quot; id=&quot;mask_button&quot; style=&quot;width:150px;&quot; onclick=&quot;hideShowMasks()&quot;&gt;Visualize masks&lt;/button&gt;&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; id=&quot;lottery_masks&quot; style=&quot;display: none; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:100%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/lottery_mask_vis.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
    &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Visualizing first layer weight masks of random tickets and lottery tickets. For interpretabilty, we have sorted the mask along the hidden layer axis according to the number of adjacent unmasked parameters. This helps reveal a bias towards local connectivity in the lottery ticket masks. Notice how there are many more vertically-adjacent unmasked parameters in the lottery ticket masks. These vertically-adjacent parameters correspond to local connectivity along the input dimension, which in turn biases the sparse model towards data with spatial structure. Best viewed with zoom.&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
 function hideShowMasks() {
  var x = document.getElementById(&quot;lottery_masks&quot;);
  var button = document.getElementById(&quot;mask_button&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;block&quot;;
    button.textContent = &quot;Hide masks&quot;;
  } else {
    x.style.display = &quot;none&quot;;
    button.textContent = &quot;Visualize masks&quot;;
  }
}
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Observing deep double descent.&lt;/strong&gt; Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually &lt;em&gt;reduce&lt;/em&gt; a model’s test accuracy&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.&lt;/p&gt;

&lt;p&gt;Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results &lt;a href=&quot;https://bit.ly/2UBWWNu&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:46.8%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/ddd_a.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:52.5%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/ddd_b.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to predict for other models like CNNs, RNNs, and Transformers. Here we see that a CNN has a double descent peak at the same interpolation threshold but the effect is much less pronounced.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Gradient-based metalearning.&lt;/strong&gt; The goal of metalearning is to “learn how to learn.” A model does this by having two levels of optimization: the first is a fast inner loop which corresponds to a traditional learning objective and second is a slow outer loop which updates the “meta” properties of the learning process. One of the simplest examples of metalearning is gradient-based hyperparameter optimization. The concept was was proposed by &lt;a href=&quot;https://ieeexplore.ieee.org/document/6789800&quot;&gt;Bengio (2000)&lt;/a&gt; and then scaled to deep learning models by &lt;a href=&quot;https://arxiv.org/abs/1502.03492&quot;&gt;Maclaurin et al. (2015)&lt;/a&gt;. The basic idea is to implement a fully-differentiable neural network training loop and then backpropagate through the entire process in order to optimize hyperparameters like learning rate and weight decay.&lt;/p&gt;

&lt;p&gt;Metalearning is a promising topic but it is very difficult to scale. First of all, metalearning algorithms consume enormous amounts of time and compute. Second of all, implementations tend to grow complex since there are twice as many hyperparameters (one set for each level of optimization) and most deep learning frameworks are not set up well for metalearning. This places an especially high incentive on debugging and iterating metalearning algorithms on small-scale datasets such as MNIST-1D. For example, it took just a few hours to implement and debug the gradient-based hyperparameter optimization of a learning rate shown below. You can reproduce these results &lt;a href=&quot;https://bit.ly/38OSyTu&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:32.4%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_lr_a.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:33%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_lr_b.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
    &lt;div style=&quot;width:32%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_lr_c.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Metalearning a learning rate: looking at the third plot, the optimal learning rate appears to be 0.6. Unlike many gradient-based metalearning implementations, ours takes seconds to run and occupies a few dozen lines of code. This allows researchers to iterate on novel ideas before scaling.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Metalearning an activation function.&lt;/strong&gt; Having implemented a “minimal working example” of gradient-based metalearning, we realized that it permitted a simple and novel extension: metalearning an activation function. With a few more hours of researcher time, we were able to parameterize our classifier’s activation function with a second neural network and then learn the weights using meta-gradients. Shown below, our learned activation function substantially outperforms baseline nonlinearities such as ReLU, Elu&lt;sup id=&quot;fnref:fn5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, and Swish&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. You can reproduce these results &lt;a href=&quot;https://bit.ly/38V4GlQ&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:32.7%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_afunc_a.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32.5%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_afunc_b.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
    &lt;div style=&quot;width:33%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/metalearn_afunc_c.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Metalearning an activation function. Starting from an ELU shape, we use gradient-based metalearning to find the optimal activation function of a neural network trained on the MNIST-1D dataset. The activation function itself is parameterized by a second (meta) neural network. Note that the ELU baseline (red) is obscured by the &lt;i&gt;tanh&lt;/i&gt; baseline (blue) in the figure above.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;We transferred this activation function to convolutional models trained on MNIST and CIFAR-10 images and found that it achieves middle-of-the-pack performance. It is especially good at producing low training loss early in optimization, which is the objective that it was trained on in MNIST-1D. When we rank nonlinearities by final test loss, though, it achieves middle-of-the-pack performance. We suspect that running the same metalearning algorithm on larger models and datasets would further refine our activation function, allowing it to at least match the best hand-designed activation function. We leave this to future work, though.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Measuring the spatial priors of deep networks.&lt;/strong&gt; A large part of deep learning’s success is rooted in “deep priors” which include hard-coded translation invariances (e.g., convolutional filters), clever architectural choices (e.g., self-attention layers), and well-conditioned optimization landscapes (e.g., batch normalization). Principle among these priors is the translation invariance of convolution. A primary motivation for this dataset was to construct a toy problem that could effectively quantify a model’s spatial priors. The second figure in this post illustrates that this is indeed possible with MNIST-1D. One could imagine that other models with more moderate spatial priors would sit somewhere along the continuum between the MLP and CNN benchmarks. Reproduce &lt;a href=&quot;https://bit.ly/3fghqVu&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benchmarking pooling methods.&lt;/strong&gt; Our final case study begins with a specific question: &lt;em&gt;What is the relationship between pooling and sample efficiency?&lt;/em&gt; We had not seen evidence that pooling makes models more or less sample efficient, but this seemed an important relationship to understand. With this in mind, we trained models with different pooling methods and training set sizes and found that, while pooling tended to be effective in low-data regimes, it did not make much of a difference in high-data regimes. We do not fully understand this effect, but hypothesize that pooling is a mediocre architectural prior which is better than nothing in low-data regimes and then ends up restricting model expression in high-data regimes. By the same token, max-pooling may also be a good architectural prior in the low-data regime, but start to delete information – and thus perform worse compared to L2 pooling – in the high-data regime. Reproduce &lt;a href=&quot;https://bit.ly/3lGmTqY&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:33%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/pooling_a.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32.3%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/pooling_b.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
    &lt;div style=&quot;width:31.9%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/scaling-down/pooling_c.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;Benchmarking common pooling methods. We observe that pooling helps performance in low-data regimes and hinders it in high-data regimes. While we do not entirely understand this effect, we hypothesize that pooling is a mediocre architectural prior that is better than nothing in low-data regimes but becomes overly restrictive in high-data regimes.&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;when-to-scale&quot;&gt;When to scale&lt;/h2&gt;

&lt;p&gt;This post is not an argument against large-scale machine learning research. That sort of research has proven its worth time and again and has come to represent one of the most exciting aspects of the ML research ecosystem. Rather, this post argues &lt;em&gt;in favor&lt;/em&gt; of small-scale machine learning research. Neural networks do not have problems with scaling or performance – but they do have problems with interpretability, reproducibility, and iteration speed. We see carefully-controlled, small-scale experiments as a great way to address these problems.&lt;/p&gt;

&lt;p&gt;In fact, small-scale research is complimentary to large-scale research. As in biology, where fruit fly genetics helped guide the Human Genome Project, we believe that small-scale research should always have an eye on how to successfully scale. For example, several of the findings reported in this post are at the point where they should be investigated at scale. We would like to show that large scale lottery tickets also learn spatial inductive biases, and show evidence that they develop local connectivity. We would also like to try metalearning an activation function on a larger model in the hopes of finding an activation that will outperform ReLU and Swish in generality.&lt;/p&gt;

&lt;p&gt;We should emphasize that we are only ready to scale these results now that we have isolated and understood them in a controlled setting. We believe that scaling a system is only a good idea once the relevant causal mechanisms have been isolated and understood.&lt;/p&gt;

&lt;!-- ## Context

The machine learning community has grown rapidly in recent years. This growth has accelerated the rate of scientific innovation, but it has also produced multiple competing narratives about the field&apos;s ultimate direction and objectives. In this section, we will explore three such narratives in order to place MNIST-1D in its proper context.

**Scaling trends.** One of the defining features of machine learning in the 2010&apos;s was a [massive increase](https://openai.com/blog/ai-and-compute/) in the scale of datasets, models, and compute infrastructure. This scaling pattern allowed neural networks to achieve breakthrough results on a wide range of benchmarks. Yet while this scaling effect has helped neural networks take on commercial and political relevance, opinions differ about how much more &quot;intelligence&quot; it can generate. One one hand, many researchers and organizations argue that [scaling is a crucial path](https://openai.com/blog/ai-and-compute/) to making neural networks behave more intelligently. On the other hand, there is a healthy but marginal population of researchers who are not primarily motivated by scale. They are united by a common desire to change research methodologies, advocating a shift [away from human-engineered datasets and architectures](https://arxiv.org/abs/1905.10985), an [emphasis on human-like learning patterns](https://arxiv.org/abs/1911.01547), and [better integration with traditional symbolic AI approaches](https://arxiv.org/abs/1801.00631).

Once again, the genetics analogy is useful. In genetics, scale has been most effective when small-scale experiments have helped to guide the direction and vision of large-scale experiments. For example, the organizers of the Human Genome Project regularly used yeast and fly genomes to [guide analysis of the human genome](https://deepblue.lib.umich.edu/handle/2027.42/62798). Thus one should be suspicious of research agendas that place disproportionate emphasis on large-scale experiments, since a healthy research ecosystem needs both. The fast, small scale projects permit creativity and deep understanding, whereas the large-scale projects expose fertile new research territory.

**Understanding vs. performance.** Researchers are also divided over the value of understanding versus performance. Some contend that a high-performing algorithm [need not be interpretable](https://youtu.be/93Xv8vJ2acI?t=788) so long as it saves lives or produces economic value. Others argue that hard-to-interpret deep learning models should not be deployed in sensitive real-world contexts. Both arguments have merit, but the best path forward seems to be to focus on understanding high-performing algorithms better so that this tradeoff becomes less severe. One way to do this is by identifying things we don&apos;t understand about neural networks, reproducing these things on a toy problem like MNIST-1D, and then performing ablation studies to isolate the causal mechanisms.

**Ecological impacts.** A growing number of researchers and organizations claim that deep learning will have positive [environmental](https://www.sciencedirect.com/science/article/abs/pii/0304380087900974) [applications](https://arxiv.org/abs/1906.05433). This may be true in the long run, but so far artificial intelligence has done little to solve environmental problems. In the meantime, deep learning models are [consuming massive amounts of electricity](https://arxiv.org/abs/1906.02243) to train and deploy. Our hope is that benchmarks like MNIST-1D will encourage researchers to spend more time iterating on small datasets and toy models before scaling, making more efficient use of electricity in the process.

 --&gt;

&lt;h2 id=&quot;other-small-datasets&quot;&gt;Other small datasets&lt;/h2&gt;
&lt;p&gt;The core inspiration for this work stems from an admiration of and, we daresay, infatuation with the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST dataset&lt;/a&gt;. While it has some notable flaws – some of which we have addressed – it also has many lovable qualities and underappreciated strengths: it is simple, intuitive, and provides the perfect sandbox for exploring creative new ideas.&lt;/p&gt;

&lt;p&gt;Our work also bears philosophical similarities to the &lt;a href=&quot;https://arxiv.org/abs/2005.13092&quot;&gt;Synthetic Petri Dish&lt;/a&gt; by Rawal et al. (2020). It was published concurrently and the authors make similar references to biology in order to motivate the use of small synthetic datasets for exploratory research. Their work differs from ours in that they use metalearning to obtain their datasets whereas we construct ours by hand. The purpose of the Synthetic Petri Dish is to accelerate neural architecture search whereas the purpose of our dataset is to accelerate “science of deep learning” questions.&lt;/p&gt;

&lt;p&gt;There are many other small-scale datasets that are commonly used to investigate “science of deep learning” questions. The examples in the &lt;a href=&quot;https://www.cs.toronto.edu/~kriz/cifar.html&quot;&gt;CIFAR-10 dataset&lt;/a&gt; are four times larger than MNIST examples but the total number of training examples is the same. CIFAR-10 does a better job of discriminating between MLP and CNN architectures, and between various CNN architectures such as vanilla CNNs versus ResNets. The &lt;a href=&quot;https://github.com/zalandoresearch/fashion-mnist&quot;&gt;FashionMNIST dataset&lt;/a&gt; is the same size as MNIST but a bit more difficult. One last option is &lt;a href=&quot;https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets&quot;&gt;Scikit-learn&lt;/a&gt;’s datasets: there are dozens of options, some synthetic and others real. But making real world analogies to, say, digit classification, is not possible and one can often do very well on them using simple linear or kernel-based methods.&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;

&lt;p&gt;There is a counterintuitive possibility that in order to explore the limits of how large we can scale neural networks, we may need to explore the limits of how small we can scale them first. Scaling models and datasets downward in a way that preserves the nuances of their behaviors at scale will allow researchers to iterate quickly on fundamental and creative ideas. This fast iteration cycle is the best way of obtaining insights about how to incorporate progressively more complex inductive biases into our models. We can then transfer these inductive biases across spatial scales in order to dramatically improve the sample efficiency and generalization properties of large-scale models. We see the humble MNIST-1D dataset as a first step in that direction.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Trunk, Gerard V. “&lt;a href=&quot;https://ieeexplore.ieee.org/document/4766926&quot;&gt;A problem of dimensionality: A simple example&lt;/a&gt;.” IEEE Transactions on pattern analysis and machine intelligence 3 (1979): 306-307. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Belkin, Mikhail, et al. “&lt;a href=&quot;https://www.pnas.org/content/116/32/15849&quot;&gt;Reconciling modern machine-learning practice and the classical bias–variance trade-off&lt;/a&gt;.” Proceedings of the National Academy of Sciences 116.32 (2019): 15849-15854. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Spigler, Stefano, et al. “&lt;a href=&quot;https://arxiv.org/abs/1810.09665&quot;&gt;A jamming transition from under-to over-parametrization affects loss landscape and generalization&lt;/a&gt;.” arXiv preprint arXiv:1810.09665 (2018). &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Nakkiran, Preetum, et al. “&lt;a href=&quot;https://arxiv.org/abs/1912.02292&quot;&gt;Deep double descent: Where bigger models and more data hurt&lt;/a&gt;.” arXiv preprint arXiv:1912.02292 (2019). &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Clevert, Djork-Arné, Thomas Unterthiner, and Sepp Hochreiter. &lt;a href=&quot;https://arxiv.org/abs/1511.07289&quot;&gt;Fast and accurate deep network learning by exponential linear units (elus).&lt;/a&gt; ICLR 2016. &lt;a href=&quot;#fnref:fn5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Ramachandran, Prajit, Barret Zoph, and Quoc V. Le. &lt;a href=&quot;https://arxiv.org/abs/1710.05941&quot;&gt;Searching for activation functions&lt;/a&gt;. (2017). &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">In order to explore the limits of how large we can scale neural networks, we may need to explore the limits of how small we can scale them first.</summary></entry><entry><title type="html">Optimizing a Wing</title><link href="http://greydanus.github.io/2020/10/14/optimizing-a-wing/" rel="alternate" type="text/html" title="Optimizing a Wing" /><published>2020-10-14T04:00:00-07:00</published><updated>2020-10-14T04:00:00-07:00</updated><id>http://greydanus.github.io/2020/10/14/optimizing-a-wing</id><content type="html" xml:base="http://greydanus.github.io/2020/10/14/optimizing-a-wing/">&lt;p style=&quot;font-size: 20px;text-align: center;color: #999;&quot;&gt;&lt;i&gt;(My last post in a series about human flight; &lt;a target=&quot;_blank&quot; style=&quot;color: #777;&quot; href=&quot;../../../../2020/10/12/story-of-flight/&quot;&gt;post 1&lt;/a&gt;, &lt;a target=&quot;_blank&quot; style=&quot;color: #777;&quot; href=&quot;../../../../2020/10/13/stepping-stones/&quot;&gt;post 2&lt;/a&gt;).&lt;/i&gt;&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; text-align:center; width:80%&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/optimizing-a-wing/wing_shape.png&quot; onclick=&quot;toggleWingShape()&quot; style=&quot;width:315px&quot; id=&quot;wingShapeImage&quot; /&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/optimizing-a-wing/wing_flow.png&quot; onclick=&quot;toggleWingFlow()&quot; style=&quot;width:315px&quot; id=&quot;wingFlowImage&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left;&quot;&gt;&lt;b&gt;Figure 1:&lt;/b&gt; In this post, we&apos;ll simulate a wind tunnel, place a rectangular occlusion in it, and then use gradient descent to turn it into a wing. &lt;p style=&quot;color:grey; display:inline;&quot;&gt;[The images above are videos. Click to pause or play.]&lt;/p&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://bit.ly/3j3Wcu4&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://bit.ly/2H5r401&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;colab-span&quot;&gt;Run&lt;/span&gt; in browser&lt;/a&gt;
	&lt;a href=&quot;https://github.com/greydanus/optimize_wing&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Legos are an excellent meta-toy in that they represent the potential for a near-infinite number of toys depending on how you assemble them. Each brick has structure. But each brick is only interesting to the extent that it can combine with other bricks, forming new and more complex structures. So in order to enjoy Legos, you have to figure out how they fit together and come up with a clever way of making the particular toy you have in mind. Once you have mastered a few simple rules, the open-ended design of Lego bricks lets you build anything you can imagine.&lt;/p&gt;

&lt;p&gt;Our universe has the same versatile structure. It seems to run according to just a few simple forces, but as those forces interact, they give rise to intricate patterns across many scales of space and time. You see this everywhere you look in nature – in the fractal design of a seashell or the intricate polities of a coral. In the convection of a teacup or the circulation of the atmosphere. And this simple structure even determines the shape and behavior of man’s most complicated flying machines.&lt;/p&gt;

&lt;p&gt;To see this more clearly, we are going to start from the basic physical laws of airflow and use them to derive the shape of a wing.&lt;sup id=&quot;fnref:fn18&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn18&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Since we are using so few assumptions, the wing shape we come up with will be as fundamental as the physics of the air that swirls around it. This is pretty fundamental. In fact, if an alien species started building flying machines on another planet, they would probably converge on a similar shape.&lt;/p&gt;

&lt;h2 id=&quot;navier-stokes&quot;&gt;Navier-Stokes&lt;/h2&gt;

&lt;p&gt;We will begin this journey with the &lt;a href=&quot;https://www.britannica.com/science/Navier-Stokes-equation&quot;&gt;Navier-Stokes equation&lt;/a&gt;, which sums up pretty much everything we know about fluid dynamics. It describes how tiny fluid parcels interact with their neighbors. The process of solving fluid dynamics problems comes down to writing out this equation and then deciding which terms we can safely ignore. In our case, we would like to simulate the flow of air through a wind tunnel and then use it to evaluate various wing shapes.&lt;/p&gt;

&lt;p&gt;Since the pressure differences across a wind tunnel are small, one of the first assumptions we can make is that air is incompressible. This lets us use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations#Incompressible_flow&quot;&gt;incompressible form&lt;/a&gt; of the Navier-Stokes equation:&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;longEqnWithSmallScript_A&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} ~=~ - \underbrace{(\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection}} ~+~ \underbrace{\nu \nabla^2 \mathbf{u}}_{\text{viscous diffusion}} \\
~+~ \underbrace{f}_{\text{velocity $\uparrow$ due to forces}}\)
&lt;/span&gt;
&lt;span id=&quot;longEqnWithLargeScript_A&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} ~=~ - \underbrace{(\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection}} ~+~ \underbrace{\nu \nabla^2 \mathbf{u}}_{\text{viscous diffusion}} ~+~ \underbrace{f}_{\text{velocity $\uparrow$ due to forces}}\)
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Another term we can ignore is viscous diffusion. Viscous diffusion describes how fluid parcels distribute their momenta due to sticky interactions with their neighbors. We would say that a fluid with high viscosity is “thick”: common examples include molasses and motor oil. Even though air is much thinner, viscous interactions still cause a layer of slow-moving air to form along the surface of an airplane wing. However, we can ignore this boundary layer because its contribution to the aerodynamics of the wing is small compared to that of self-advection.&lt;/p&gt;

&lt;p&gt;The final term we can ignore is the forces term, as there will be no forces on the air once it enters the wind tunnel. And so we are left with but a hair of the original Navier-Stokes hairball:&lt;/p&gt;

\[\underbrace{\frac{\partial \mathbf{u}}{\partial t}}_{\text{velocity update}} = \underbrace{- (\mathbf{u} \cdot \nabla)\mathbf{u}}_{\text{self-advection (&quot;velocity follows itself&quot;)}}\]

&lt;p&gt;This simple expression describes the effects that really dominate wind tunnel physics. It says, intuitively, that “the change in velocity over time is due to the fact that velocity follows itself.” So the entire simulation comes down to two simple rules:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;
		Rule 1: Velocity follows itself &lt;div id=&quot;advection_info_toggle&quot; onclick=&quot;hideShowAdvection()&quot; style=&quot;cursor: pointer;display:inline&quot;&gt;(+)&lt;/div&gt;
		&lt;ul&gt;
		&lt;div id=&quot;advection_info&quot; style=&quot;display: none;&quot;&gt;&lt;i&gt;The technical term for this effect is &quot;self-advection.&quot; Advection is when a field, say, of smoke, is moved around by the velocity of a fluid. Self-advection is a special case where the field being advected is the velocity field, and so it actually advects itself. In principle, a self-advection step is as simple as moving the velocity field according to x&apos; = v * dt + x at every point on the grid. We can simulate self-advection over time by repeating this over and over again.&lt;/i&gt;&lt;/div&gt;
		&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;
		&lt;!-- &lt;b&gt;Rule 1: Velocity follows itself&lt;/b&gt; --&gt;
		Rule 2: Volume is conserved &lt;div id=&quot;projection_info_toggle&quot; onclick=&quot;hideShowProjection()&quot; style=&quot;cursor: pointer;display:inline&quot;&gt;(+)&lt;/div&gt;
		&lt;ul&gt;
		&lt;div id=&quot;projection_info&quot; style=&quot;display: none;&quot;&gt;&lt;i&gt;This rule comes from our incompressibility assumption and the process of enforcing it is called projection. Since volume is conserved, fluid parcels can only move into positions that their neighbors have recently vacated. This puts a strong constraint on our simulation&apos;s velocity field: it needs to be volume-conserving. Fortunately, Helmholtz’s theorem tells us that any vector field can be decomposed into an incompressible field and a gradient field, as a figure from &lt;a href=&quot;https://drive.google.com/file/d/1upKFdtnM0xcTVxNsPHI1KCvmcanAJheL/view?usp=sharing&quot;&gt;this paper&lt;/a&gt; shows:
			&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:70%&quot;&gt;
				&lt;img src=&quot;/assets/optimizing-a-wing/decomposition.png&quot; style=&quot;width:100%&quot; /&gt;
			&lt;/div&gt;
		One way to make our velocity field incompressible is to find the gradient field and then subtract it from the original field as shown above. This &lt;i&gt;projects&lt;/i&gt; our velocity field onto a volume-conserving manifold.&lt;/i&gt;
		&lt;/div&gt;
		&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By alternating between these two rules, we can iteratively 1) move the system forward in time and 2) enforce conservation of volume and mass. In practice, we implement each rule as a separate function and then apply both functions to the system at every time step. This allows us to simulate, say, a gust of wind passing through the wind tunnel. But before we can direct this wind over a wing, we need to decide how to represent the wing itself.&lt;/p&gt;

&lt;h2 id=&quot;representing-the-wing&quot;&gt;Representing the Wing&lt;/h2&gt;

&lt;div&gt;
&lt;div style=&quot;display:inline&quot;&gt;The wing is an internal boundary, or occlusion, of the flow. A good way to represent an occlusion is with a mask of zeros and ones. But since the goal of our wind tunnel is to try out different wing shapes, we need our wing to be continuously deformable. So we will allow the mask to take on continuous values between zero and one, making it semi-permeable in proportion to its mask values. This lets us add semi-permeable obstructions to the wind tunnel as shown:&lt;/div&gt; &lt;div id=&quot;filter_info_toggle&quot; onclick=&quot;hideShowFilter()&quot; style=&quot;cursor: pointer;display:inline&quot;&gt;(+)&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;filter_info&quot; style=&quot;display: none;&quot;&gt;&lt;i&gt;&lt;b&gt;A note on filtering.&lt;/b&gt; In practice, the wing is still not quite continuously deformable. Big differences in the mask at neighboring grid points can lead to sharp boundary conditions and non-physical airflows around the mask. One way to reduce this effect is to apply a Gaussian filter around the edges of the mask so as to prevent these grid-level pathologies. This approach may seem a bit arbitrary at first glance, but it is actually a common simulation technique used in, for example, &lt;a href=&quot;https://doi.org/10.1007/s00158-010-0594-7&quot;&gt;topology optimization&lt;/a&gt;, &lt;a href=&quot;https://web.stanford.edu/group/ctr/ResBriefs03/gullbrand.pdf&quot;&gt;large&lt;/a&gt; &lt;a href=&quot;https://doi.org/10.1063/1.3485774&quot;&gt;eddy simulation&lt;/a&gt;, and &lt;a href=&quot;https://graphics.stanford.edu/courses/cs468-03-fall/Papers/Levin_MovingLeastSquares.pdf&quot;&gt;3D graphics&lt;/a&gt;.&lt;/i&gt;&lt;/div&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:19.5%; min-width:150px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/mask/mask_0.00.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Mask = 0.0&lt;/div&gt;
  &lt;/div&gt;
    &lt;div style=&quot;width:19.5%; min-width:150px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/mask/mask_0.05.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Mask = 0.05&lt;/div&gt;
  &lt;/div&gt;
    &lt;div style=&quot;width:19.5%; min-width:150px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/mask/mask_0.12.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Mask = 0.12&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:19.5%; min-width:150px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/mask/mask_0.50.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Mask = 0.5&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:19.5%; min-width:150px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/mask/mask_1.00.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Mask = 1.0&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;choosing-an-objective&quot;&gt;Choosing an Objective&lt;/h2&gt;

&lt;p&gt;Now we are at the point where we can simulate how air flows over arbitrary, semi-permeable shapes. But in order to determine which of these shapes makes a better wing, we still need to define a measure of performance. There are many qualities that one could look for in a good wing, but we will begin with the most obvious: it should convert horizontal air velocity into upward force as efficiently as possible. We can measure this ability using something called the lift-drag ratio where “lift” measures the upward force generated by the wing and “drag” measures the frictional forces between the air and the wing. Since “change in downward airflow” in the tunnel is proportional to the upward force on the wing, we can use it as a proxy for lift. Likewise, “change in rightward airflow” is a good proxy for the drag forces on the wing. With this in mind, we can write out the objective function as&lt;/p&gt;

\[\max_{\theta} L/D\]

&lt;p&gt;where \(\theta\) represents some tunable parameters associated with the shape of the wing mask and \(L/D\) can be obtained using the initial and final wind velocities of the simulation according to&lt;/p&gt;

\[\begin{align}
     L/D &amp;amp;= \frac{\text{lift}}{\text{drag}}\\
    &amp;amp;= \frac{\text{change in downward airflow}}{-\text{change in rightward airflow}}\\
    &amp;amp;= \frac{ -\big ( v_y(t)-v_y(0) \big )}{-\big ( v_x(t)-v_x(0) \big )}\\
    &amp;amp;= \frac{ v_y(t)-v_y(0) }{ v_x(t)-v_x(0)}
\end{align}\]

&lt;p&gt;Solving this optimization problem will give us a wing shape that generates the most efficient lift possible. In other words, we new have the correct problem setup; what remains is to figure out how to solve it.&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;

&lt;div&gt;
&lt;div style=&quot;display:inline&quot;&gt;We are going to solve this problem with gradient ascent. Gradient ascent is simple and easy to implement, but there is one important caveat: we need a way to efficiently compute the gradient of the objective function with respect to the wing mask parameters. This involves differentiating through each step of the fluid simulation in turn – all of the way back to the initial conditions. This would be difficult to implement by hand, but fortunately there is a tool called &lt;a href=&quot;https://github.com/HIPS/autograd&quot;&gt;Autograd&lt;/a&gt; which can perform this back-propagation of gradients automatically. We will use Autograd to compute the gradients of the mask parameters, move the mask parameters in that direction, and then repeat this process until the lift-drag ratio reaches a local maximum.&lt;/div&gt; &lt;div id=&quot;autograd_info_toggle&quot; onclick=&quot;hideShowAutograd()&quot; style=&quot;cursor: pointer;display:inline&quot;&gt;(+)&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;autograd_info&quot; style=&quot;display: none;&quot;&gt;&lt;i&gt;&lt;b&gt;A note on Autograd.&lt;/b&gt; Amazingly, every mathematical operation we&apos;ve described so far – from the wing masking operation to the advection and projection functions to the lift-drag ratio – is differentiable. This is why we can use Autograd to compute analytic gradients with respect to the mask parameters. Autograd uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Automatic_differentiation&quot;&gt;automatic differentiation&lt;/a&gt;, closely related to the &lt;a href=&quot;http://www.dolfin-adjoint.org/en/latest/documentation/maths/2-problem.html&quot;&gt;adjoint method&lt;/a&gt;, to propagate gradient information backwards through the simulation until it reaches the parameters of the wing mask. We can do all of this in a one-line function transformation:&lt;code&gt;grad_fn = autograd.value_and_grad(get_lift_drag_ratio)&lt;/code&gt;.&lt;/i&gt;&lt;/div&gt;

&lt;p&gt;So let’s review. Our goal is to simulate a wind tunnel and use it to derive a wing shape. We began by writing down the general Navier-Stokes equation and eliminating irrelevant terms: all of them but self-advection. Next, we figured out how to represent a wing shape in the tunnel using a continuously-deformable occlusion. Finally, we wrote down an equation for what a good wing should do and discussed how to optimize it. Now it is time to put everything together in about two hundred lines of code and see what happens when we run it…&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; min-width: 300px; text-align:center;&quot;&gt;
	&lt;img alt=&quot;&quot; src=&quot;/assets/optimizing-a-wing/optimize_wing.png&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:43%; min-width: 300px; text-align:center;&quot;&gt;
	&lt;p style=&quot;display:inline;&quot;&gt;&lt;div style=&quot;color:black;font-size: 18px&quot;&gt;Final result&lt;/div&gt; &lt;div style=&quot;color:grey;&quot;&gt;[Click image to pause or play.]&lt;/div&gt;&lt;/p&gt;
	&lt;img style=&quot;width:100%&quot; alt=&quot;&quot; src=&quot;/assets/optimizing-a-wing/wing.png&quot; onclick=&quot;toggleBasicWing()&quot; id=&quot;basicWing&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Sure enough, we get a beautiful little wing. Of all possible shapes, this is the very best one for creating efficient lift in our wind tunnel. This wing is definitely a toy solution since our simulation is coarse and not especially accurate. However, after making a few simple improvements we would be able to design real airplane wings this way. We would just need to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Simulate in 3D instead of 2D&lt;/li&gt;
  &lt;li&gt;Use a mesh parameterization instead of a grid&lt;/li&gt;
  &lt;li&gt;Make the flow laminar and compressible&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Aside from these improvements, the overall principle is much the same. In both cases, we write down some words and symbols, turn them into code, and then use the code to shape our wing.&lt;sup id=&quot;fnref:fn14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn14&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; The fact that we can do all of this without ever building a physical wing makes it feel a bit like magic. But this process really works, for when we &lt;a href=&quot;http://aero-comlab.stanford.edu/Papers/jameson-cincin-pm.pdf#page=36&quot;&gt;put these wings on airplanes&lt;/a&gt; and trust them with our lives, they carry us safely to our destinations.&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&quot;fnref:fn17&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn17&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Just like the real wind tunnels of the twentieth century, these simulated wind tunnels need to go through lots of debugging before we can trust them. In fact, while building this demo we discovered a number of ways that things can go wrong. Here are some of the most amusing failure cases:&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/optimizing-a-wing/sim_bloopers.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Several of these wings are just plain dreadful. But others seem reasonable, if unexpected. The two-wing solution is particularly amusing. We did not intend for this “biplane” solution to occur, and yet it is a completely viable way of solving the objective we wrote down. One advantage to keeping the problem setup so simple is that, in doing so, we left space for these surprising behaviors to occur.&lt;/p&gt;

&lt;h2 id=&quot;the-manifold-of-solutions&quot;&gt;The Manifold of Solutions&lt;/h2&gt;

&lt;p&gt;There are variations on the base wing shape which excel in particular niches. Sometimes we will want a wing that is optimal at high speeds and other times we will want one that is optimal at low speeds. In order to accommodate a large fuselage, we might want an extra-thick wing. Alternatively, in order to reduce its overall weight, we might want to keep it thin. It turns out that we can change simulation parameters and add auxiliary losses to find optimal wing shapes for each of these scenarios.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:60%; min-width: 300px&quot;&gt;
	&lt;img src=&quot;/assets/optimizing-a-wing/sim_manifold.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;Our wind tunnel simulation is interesting first, because it illustrates how the Platonic ideal of wing design is rooted in the laws of physics. As we saw in the earlier posts, there were many cultural and technological forces that contributed to airfoil design. These forces were important for many reasons, but they were not the primary factor in the wing shapes they produced – physics was.&lt;/p&gt;

&lt;p&gt;But to balance this idea, we have also shown how a million variants of the Platonic form of a wing can fulfill particular needs. Indeed, these variants could be said to occupy complimentary niches in the same way that different birds and flying insects occupy different niches in nature. After all, even though nature follows the laws of physics with absolute precision, she takes a consummate joy in variation. Look at the variety of wing shapes in birds, for example.&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; Species of hummingbirds have wings with low aspect ratios that enable quick, agile flight patterns. Other birds, like the albatross, have high aspect ratios for extreme efficiency. Still others, like the common raven, are good all-around fliers. Remarkably, we are beginning to see this same speciation occur in modern aircraft as well. There are surveillance planes built for speed and stealth, short-winged bush planes built for maneuverability, and massive commercial airliners built for efficiency.&lt;sup id=&quot;fnref:fn5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn5&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:36.4815%; min-width:200px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/bird_shapes.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;A figure from &lt;a href=&quot;https://doi.org/10.2307/3677110&quot;&gt;Lockwood (1998)&lt;/a&gt; arranging bird species by wing pointedness and wingtip convexity. Different wing designs stem from adaptations to different ecological niches.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:62.073%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/norberg2002.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;A plot by &lt;a href=&quot;https://doi.org/10.1002/jmor.10013&quot;&gt;Lindhe (2002)&lt;/a&gt; showing aspect ratio versus wing loading index in some birds, airplanes, a hang-glider, a butterfly, and a maple seed. Just like the families of birds, different human flying machines display substantial variation along these axes.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Perhaps less intuitively, even a single bird is capable of a huge range of wing shapes. The falcon, for example, uses different wing shapes for soaring, diving, turning, and landing. Its wings are not static things, but rather deformable, dynamic objects which are constantly adapting to their surroundings. And once again, we are beginning to see the same thing happen in modern aircrafts like the Boeing 747. The figure below shows how its triple-slotted wing design lets pilots reconfigure the airfoil shape during takeoff, cruising, and landing.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:55%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/bird_morph.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:44.3%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/optimizing-a-wing/plane_morph.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing Thoughts&lt;/h2&gt;

&lt;p&gt;One of the lessons from attempting to optimize a wing is that the optimization itself is never the full story. When we write down the optimization objective (like we did above), our minds already have a vague desire to obtain a wing. And behind that desire, our minds may want to obtain a wing because we are drawn to the technology of flight. And perhaps we are drawn to flight for the same reasons that the early aviators were – because it promises freedom, glory, and adventure. And behind those desires – what? The paradox of an objective function is that it always seems to have a deeper objective behind it.&lt;/p&gt;

&lt;p&gt;The deeper objectives do not change as quickly. Even as the early aviators progressed from wingsuits to gliders to planes, they retained the same fundamental desire to fly. Their specific desires, of course, were different: some wanted to survive a tower jump and others wanted to break the speed of sound. And their specific desires led to specific improvements in technology such as a better understanding of the Smeaton coefficient or a stable supercritical airfoil. Once they made these improvements, the next generation was able to use them to pursue more ambitious goals. But even as this cycle progressed, the more deeply-held desire to fly continued to inspire and unify their efforts.&lt;/p&gt;

&lt;!-- The desire to fly is remarkable in that it is something that our biology alone cannot satisfy. In this way we are a bit like hermit crabs -- creatures who are born without the ability to grow a shell and yet need one to survive as adults. As they mature, they must cast about their tide pools for a suitable shell. And when they find one, they clean it, fit themselves to it, and their bodies grow or shrink to make the fit perfect. But whereas hermit crabs seek out shells because they want safety, humans seek out flight because they are after things like freedom, adventure, and beauty. We are not trying to achieve stasis; rather, we are aiming for a future that is different and better. That is what made us a flying species in the first place and that is what will propel us even higher tomorrow. --&gt;
&lt;div class=&quot;imgcap_noborder&quot; style=&quot;text-align:center&quot;&gt;
  &lt;img src=&quot;/assets/optimizing-a-wing/hummingbird.png&quot; style=&quot;width:15%;min-width:150px;&quot; /&gt;
&lt;/div&gt;

&lt;!-- So we beat on, wings angled into the wind, borne ceaselessly into the future. --&gt;

&lt;h2 id=&quot;thanks&quot;&gt;Thanks&lt;/h2&gt;

&lt;p&gt;Thanks to Maclaurin et al. (2018) for releasing Autograd&lt;sup id=&quot;fnref:fn18:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn18&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; to the world along with a number of thought-provoking demos.
Thanks to Stephan Hoyer, Shan Carter, and Matthew Johnson for conversations that shaped some of the early versions
of this work. And thanks to Andrew Sosanya, Jason Yosinski, and Tina White for feedback on early versions of this
essay. Special thanks to my family and friends for serving as guinea pigs for early iterations of this story.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleWingShape() {

		path = document.getElementById(&quot;wingShapeImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;wing_shape.png&quot;) {
	        document.getElementById(&quot;wingShapeImage&quot;).src = &quot;/assets/optimizing-a-wing/wing_shape.gif&quot;;
	    } else {
	        document.getElementById(&quot;wingShapeImage&quot;).src = &quot;/assets/optimizing-a-wing/wing_shape.png&quot;;
	    }
	}
&lt;/script&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleWingFlow() {

		path = document.getElementById(&quot;wingFlowImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;wing_flow.png&quot;) {
	        document.getElementById(&quot;wingFlowImage&quot;).src = &quot;/assets/optimizing-a-wing/wing_flow.gif&quot;;
	    } else {
	        document.getElementById(&quot;wingFlowImage&quot;).src = &quot;/assets/optimizing-a-wing/wing_flow.png&quot;;
	    }
	}

function toggleBasicWing() {

    path = document.getElementById(&quot;basicWing&quot;).src
      if (path.split(&apos;/&apos;).pop() == &quot;wing.png&quot;) {
          document.getElementById(&quot;basicWing&quot;).src = &quot;/assets/optimizing-a-wing/wing_flow.gif&quot;;
      } else {
          document.getElementById(&quot;basicWing&quot;).src = &quot;/assets/optimizing-a-wing/wing.png&quot;;
      }
  }

function hideShowAdvection() {
  var x = document.getElementById(&quot;advection_info&quot;);
  var y = document.getElementById(&quot;advection_info_toggle&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;inline&quot;; y.textContent = &quot;(–)&quot;
  } else {
    x.style.display = &quot;none&quot;; y.textContent = &quot;(+)&quot;
  }
}
function hideShowProjection() {
  var x = document.getElementById(&quot;projection_info&quot;);
  var y = document.getElementById(&quot;projection_info_toggle&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;inline&quot;; y.textContent = &quot;(–)&quot;
  } else {
    x.style.display = &quot;none&quot;; y.textContent = &quot;(+)&quot;
  }
}
function hideShowFilter() {
  var x = document.getElementById(&quot;filter_info&quot;);
  var y = document.getElementById(&quot;filter_info_toggle&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;inline&quot;; y.textContent = &quot;(–)&quot;
  } else {
    x.style.display = &quot;none&quot;; y.textContent = &quot;(+)&quot;
  }
}
function hideShowAutograd() {
  var x = document.getElementById(&quot;autograd_info&quot;);
  var y = document.getElementById(&quot;autograd_info_toggle&quot;);
  if (x.style.display === &quot;none&quot;) {
    x.style.display = &quot;inline&quot;; y.textContent = &quot;(–)&quot;
  } else {
    x.style.display = &quot;none&quot;; y.textContent = &quot;(+)&quot;
  }
}
&lt;/script&gt;

&lt;script&gt;
    function getBrowserSize(){
       var w, h;

         if(typeof window.innerWidth != &apos;undefined&apos;)
         {
          w = window.innerWidth; //other browsers
          h = window.innerHeight;
         } 
         else if(typeof document.documentElement != &apos;undefined&apos; &amp;&amp; typeof      document.documentElement.clientWidth != &apos;undefined&apos; &amp;&amp; document.documentElement.clientWidth != 0) 
         {
          w =  document.documentElement.clientWidth; //IE
          h = document.documentElement.clientHeight;
         }
         else{
          w = document.body.clientWidth; //IE
          h = document.body.clientHeight;
         }
       return {&apos;width&apos;:w, &apos;height&apos;: h};
}

if(parseInt(getBrowserSize().width) &lt; 600){
 document.getElementById(&quot;longEqnWithLargeScript_A&quot;).style.display = &quot;none&quot;;
}
if(parseInt(getBrowserSize().width) &gt; 600){
 document.getElementById(&quot;longEqnWithSmallScript_A&quot;).style.display = &quot;none&quot;;
}
&lt;/script&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn18&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Specifically, we build on ideas laid out in &lt;a href=&quot;https://github.com/HIPS/autograd/blob/master/examples/fluidsim/wing.png&quot;&gt;Maclaurin et al. (2018)&lt;/a&gt;. &lt;a href=&quot;#fnref:fn18&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn18:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;https://optimization.mccormick.northwestern.edu/index.php/Wing_Shape_Optimization&quot;&gt;this online textbook page&lt;/a&gt; for an overview of full-scale wing optimization techniques. &lt;a href=&quot;#fnref:fn14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jameson, Antony and Vassberg, John. &lt;a href=&quot;https://doi.org/10.2514/6.2001-538&quot;&gt;Computational fluid dynamics for aerodynamic design - Its current and future impact&lt;/a&gt;, &lt;em&gt;American Institute of Aeronautics &amp;amp; Astronautics&lt;/em&gt;, 2012. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn17&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Jameson, Antony. &lt;a href=&quot;http://aero-comlab.stanford.edu/Papers/AirplaneDesignShanghai.pdf&quot;&gt;Airplane Design with Aerodynamic Shape Optimization&lt;/a&gt;, &lt;em&gt;Commercial Aircraft Company of China, Shanghai&lt;/em&gt;, 2010. &lt;a href=&quot;#fnref:fn17&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Lockwood, Rowan and Swaddle, John P. and Rayner, Jeremy M. V. &lt;a href=&quot;https://doi.org/10.2307/3677110&quot;&gt;Avian Wingtip Shape Reconsidered: Wingtip Shape Indices and Morphological Adaptations to Migration&lt;/a&gt;, &lt;em&gt;Journal of Avian Biology&lt;/em&gt; Vol. 29, No. 3, pp. 273-292, 1998. &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Norberg, Ulla M. Lindhe. &lt;a href=&quot;https://doi.org/10.1002/jmor.10013&quot;&gt;Structure, Form, and Function of Flight in Engineering and the Living World&lt;/a&gt;. &lt;em&gt;Journal of Morphology&lt;/em&gt;, 2002. &lt;a href=&quot;#fnref:fn5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">How does physics shape flight? To show how fundamental wings are, I derive one from scratch by differentiating through a wind tunnel simulation.</summary></entry><entry><title type="html">The Stepping Stones of Flight</title><link href="http://greydanus.github.io/2020/10/13/stepping-stones/" rel="alternate" type="text/html" title="The Stepping Stones of Flight" /><published>2020-10-13T04:00:00-07:00</published><updated>2020-10-13T04:00:00-07:00</updated><id>http://greydanus.github.io/2020/10/13/stepping-stones</id><content type="html" xml:base="http://greydanus.github.io/2020/10/13/stepping-stones/">&lt;p&gt;By the year 1900, humans seemed to have figured out all the important ideas of aviation. There were patents for dozens of self-powered aircrafts including biplanes,&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; seaplanes,&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; and bombers.&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; There were also designs for retractable landing gear,&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; aileron wing controls,&lt;sup id=&quot;fnref:fn5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; and curved airfoils.&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; To many people, these designs indicated that the age of the airplane was at hand. Indeed, by this time there were already two commercial airline startups&lt;sup id=&quot;fnref:fn7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; and one program for constructing bombers, fully funded by the French government.&lt;sup id=&quot;fnref:fn3:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; But there was just one problem: nobody had managed to fly a real airplane yet. In fact, the Wright brothers were still several years from achieving that breakthrough. As for bombers, seaplanes, and airline companies – such things were still many decades away.&lt;/p&gt;

&lt;p&gt;This bizarre gap between theory and practice brings into question the meaning of the word invention. Generally speaking, one would think of an invention as a detailed design of the sort that could be patented. But in the case of the airplane, dozens of people patented airplanes that never could have flown. Did those people really invent airplanes? Otto Lilienthal, the first glider pilot, would have answered in the negative. “To design an aircraft is nothing” he wrote, “To build one is something. But to fly is everything.”&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot;&gt;
  &lt;img src=&quot;/assets/stepping-stones/lilienthal.png&quot; style=&quot;width:35%; min-width:250px&quot; /&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;Otto Lilienthal&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;airfoils&quot;&gt;Airfoils&lt;/h3&gt;

&lt;p&gt;In order to focus on the practical stepping stones of flight, let’s adopt Lilienthal’s perspective. In other words, let’s focus on the changes in wing design that led to the most significant empirical improvements in flight. When we start down this path, one of the first things we notice is that most of these improvements are related to the cross-sectional shape of a wing, also known as the airfoil. Generally speaking, an airfoil has no moving parts. In fact, it is just a two-dimensional shape that influences the speed of air above and below a wing. Prior to the Wright brothers, few people gave serious thought to airfoil design. But it just so happened that the details of this shape play a critical role in determining the lift and drag profile of a wing. Only through repeated iteration of design and demonstration did we become aware of the airfoil’s surprising complexity.&lt;/p&gt;

&lt;p&gt;Lilienthal, with his emphasis on practical results, was the first person to realize how much airfoils matter. They came to his attention when he set out to build a glider that could support the weight of a man. In order to build such an apparatus, he needed to know how the lift and drag characteristics of various wings scaled with length, width, and thickness. In thinking about these questions, he quickly realized that the cross-sectional shape was an important design parameter. He started by studying the airfoils of bird wings, especially those of storks. Then, with their shapes in mind, he built artificial replicas in his laboratory and tested their lift coefficients. These methodical experiments took nearly twenty years of work, after which he published his findings in his thorough (and beautifully illustrated) book, &lt;em&gt;Birdflight as the Basis of Aviation&lt;/em&gt;.&lt;sup id=&quot;fnref:fn14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn14&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; Taking what he had learned from biology, Lilienthal spent the latter part of his life building and flying human-scale gliders – the first winged flying machines that could carry a human through the air. And so, with an eye on nature and great attention to detail, Lilienthal achieved the goal he had been working towards since his twenties.&lt;/p&gt;

&lt;p&gt;But even Lilienthal, for all his care, made some errors. The Wright brothers used his results to design their first glider, and when that glider crashed unexpectedly, they realized that something was wrong. After performing their own set of wind tunnel experiments, they determined that the widely-accepted value of the Smeaton coefficient – a key part of Lilienthal’s lift and drag equations – was about 60% too high.&lt;sup id=&quot;fnref:fn15&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn15&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; Starting from this discovery, they reworked their entire wing design. They tested out hundreds of airfoils in a miniature wind tunnel and finally settled on a new airfoil shape. It was slightly wider and more arched, and the highest point of its arch was closer to the front of the wing (more “forward camber”). In spite of these changes, it looked only slightly different from their original wing shape. And yet its improved lift and stability was what the Wrights needed in order to build the world’s first self-propelled airplane.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:53%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/storks.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;A figure from Otto Lilienthal&apos;s book &lt;a href=&quot;http://www.luftfahrt-bibliothek.de/datenarchiv/otto-lilienthal-der-vogelflug-als-grundlage-der-fliegekunst.pdf&quot;&gt;&lt;i&gt;Birdflight as the Basis of Aviation&lt;/i&gt;&lt;/a&gt;. Lilienthal studied bird wings and carried out small scale experiments for two decades (1867-1889) in preparation for building his gliders.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:45%; min-width:250px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/lilienthal_vs_wright.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Years of careful experiments by the Wright brothers yielded a new wing shape with a slightly more forward camber. This seemingly small change was crucial to the &lt;i&gt;Flyer&apos;s&lt;/i&gt; success..&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Although Lilienthal and the Wrights lived on different continents and had very different lives, they were united by the fact that they each spent years doing tedious, small-scale experiments in order to understand flight on a deep level. Only after this exploratory phase did they build real flying machines. In a way, those long hours of tedium are a sacrifice one must make when they set out to pursue the romantic ideal of flight. In profiling the early aviators, we saw that the frontier of flight often attracted radical and temperamental dreamers. These were not reliable people. And yet each of them had to discipline and civilize themselves, becoming the most practical of the lot of us, before they could become heroes. Interestingly, the next breakthroughs in flight were to involve the same dynamic, but this time playing out across nations rather than individuals. This was the era of the national labs.&lt;/p&gt;

&lt;h3 id=&quot;the-national-labs&quot;&gt;The National Labs&lt;/h3&gt;

&lt;p&gt;National labs were a new phenomenon that emerged in the 1910’s and 1920’s as forward-thinking governments started to reckon with the military and economic applications of flight. Leading up to World War I, airplanes were still slow, unreliable, and expensive. They were great for stunts and parades, but close to useless on the battlefield. One of the main goals of the national labs was to change this.&lt;/p&gt;

&lt;p&gt;The first improvements in airfoil design came out of Britain’s National Physical Laboratory. Managers at this lab used its infrastructure and manpower to test airfoil designs much more thoroughly than the hobbyist-inventors before them. One of their key findings was that thicker wings with even more forward camber gave better lift. As soon as they made this discovery, they built it into military planes like the Airco DH.2 fighter (1915) and the Vickers Vimy bomber (1917).&lt;/p&gt;

&lt;p&gt;But even though these changes in airfoil design improved lift, they did not improve stability. World War I era biplanes suffered from a dangerous effect called “thin airfoil stall.” This effect occurred when streams of air above and below a wing collided behind it, creating unpredictable drag and sending the plane into a stall. German engineers were the first to find a solution to this problem. They found that thicker airfoils like the Göttingen 398 could mitigate thin airfoil stall and make fighter planes more maneuverable. They used these insights to build the Fokker Dr. I (1917) which was one of the most dangerous fighters of the war.&lt;sup id=&quot;fnref:fn8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn8&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;The most amazing thing about flight research during World War I was the speed at which national labs turned research into real technology. Often it only took a year or two. The condensed timeline and extreme real-world impact of airplanes led to dramatic improvements in their designs and finalized their transition from the world of ideas to the world of things. And the wonderful thing about having an idea take root in the world is its tendency to become the bedrock for an entirely new generation of ideas.&lt;/p&gt;

&lt;p&gt;That is the story of the 1920’s and 1930’s, which is when the mathematical theory of flight got started. Government physicists in the United States finally had time to come up with theories that explained experimental results. Then they used these theories to make airfoils better in small but important ways. Their work culminated in the 1933 National Advisory Committee for Aeronautics (NACA) Report 460, which set the industry standard for the next several decades. World War II planes like the DC-2 transport and the B-17 Flying Fortress used these results.&lt;sup id=&quot;fnref:fn9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn9&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt; And after the war, designs like the NACA 2412 found their way into commercial plane designs, some of which are still in use today.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:32.6%; min-width:220px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/wright_tunnel.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;The 1901 wind tunnel that the Wright brothers used to study airfoil shapes.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:28.2%; min-width:220px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/langley.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;A man standing in the enormous Langley wind tunnel in 1925.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:38.1%; min-width:220px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/ww1_vs_laminar.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;The progression of notable airfoils developed by national labs between 1915 and 1945.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The process of minor improvements based on theory continued into the 1940’s, when NACA researchers invented the laminar flow airfoil and installed it on the P-51 Mustang.&lt;sup id=&quot;fnref:fn9:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn9&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt; In practice, the laminar flow “correction” was rather small and it led to modest improvements. But it represented a milestone in that it was one of the first major innovations motivated by theory rather than human intuition or observations of biology. Focusing on the causal mechanisms of flight ended up being crucial for later innovations in the supersonic regime since the way air behaves at those speeds is much less intuitive.&lt;/p&gt;

&lt;p&gt;In fact, there is a deep connection between how well we understand the laws of nature and what we can build in the world. The laws of nature are the rules of the game. We are constantly learning more about these rules and we can only innovate in proportion to how well we understand them. To see this, consider evolution for a moment. Over millions of years, it has deformed life so as to probe the laws of nature at many different scales. So with time, the fundamental forces of nature have constrained and shaped life into the variety of forms we see today. Human design mimics this trial-and-error approach, but our mental models of the world give us an advantage. They speed our search in proportion to how much of the physical world they can explain. And by acting on our mental models, we can make intuitive leaps that evolution, in all of its billions of years, never could have managed. One such intuitive leap was made by Richard Whitcomb when he discovered supercritical airfoils.&lt;/p&gt;

&lt;h3 id=&quot;supercritical-airfoils&quot;&gt;Supercritical Airfoils&lt;/h3&gt;

&lt;p&gt;This discovery occurred in 1965, which was a time when the aerospace industry was trying to improve supersonic flight. Jet engines, which were invented at the end of World War II, had improved to the point where they produced enough force to accelerate planes to supersonic speeds. But once planes reached these speeds, the physics of airflow started to change and existing airfoil designs stopped working. NACA researchers realized that they would have to rethink every aspect of wing design in order to adapt. One of the most challenging problems was what to do with airfoil design.&lt;sup id=&quot;fnref:fn9:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn9&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;At the time, many of Whitcomb’s colleagues were looking for solutions in aerodynamic theory. Whitcomb took a different approach: he grabbed a can of putty and headed for the Langley wind tunnel.&lt;sup id=&quot;fnref:fn10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn10&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; He knew that the problem with existing airfoils was that air flowed at a higher rate around the top of the wing than the bottom. As the plane approached supersonic speeds, the air on top was the first to hit the sound barrier. Energy, normally dissipated as sound, would then be moving at the same speed as the air itself and slowly start to accumulate. A shock wave would form. Then the shock wave would create all sorts of pathological drag and instabilities.&lt;sup id=&quot;fnref:fn11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn11&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:99%; min-width:350px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/supercritical_wide.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;With this in mind, Whitcomb used putty to decrease the camber of the wing so as to lower the airspeed above it. Then he added a slight concavity to the underside of the wing to maintain lift and stability. All of this was based on his intuition for how air flowed over a wing at high speeds, but it ended up being extraordinarily effective. His “supercritical” wing design allowed the United States to build the fastest bombers, fighters, and reconnaissance planes of the Cold War. And surprisingly, this wing design turned out to be stable and efficient even at subsonic speeds. Today’s commercial airliners, which cruise at speeds around Mach 0.85, all use supercritical airfoils to improve fuel efficiency.&lt;/p&gt;

&lt;p&gt;Looking over the history of wing design, it is easy to see that the boundary between imagination and the constraints of the real world is where invention happens. When ideas are fully constrained to our minds, we have the tendency to indulge in impractical fantasies. And yet we need imagination too. For without it, we are limited to the incremental trial-and-error pace of evolution. Imagination is our one clear advantage over evolution, for it requires no intermediary. For evolution to invent a wing, there needed to be a half-winged precursor. But imagination has a strangely liberating effect in that it allows us to move from the ground to the sky in a single intuitive leap.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:54.8%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/kurochkin2010.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;An evolutionary pathway from small sauropods to flying birds, proposed by &lt;a href=&quot;10.1134/S0031030110120129&quot;&gt;Kurochkin and Bogdanovich (2010)&lt;/a&gt;. Each intermediary took hundreds of thousands of years of natural selection.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:44.4%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/sound_barrier.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;The Supermarine Spitfire (top) was one of the fastest planes of World War II. The Bell X-1 (bottom) unseated the Spitfire and broke the sound barrier a few years later. Notice how different the two planes look; human design lacks intermediaries.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;physical-theories&quot;&gt;Physical Theories&lt;/h3&gt;

&lt;p&gt;Since the first half of the twentieth century when the core breakthroughs of aeronautics occurred, scientists have been hard at work on physical theories that can explain those breakthroughs. These theories have expanded into fields of study like “computational fluid dynamics,” “aeronautical science,” and “turbulent flow.” Such principles are quite complex, but the question they aim to answer is simple: &lt;em&gt;how do wings work?&lt;/em&gt; We are going to answer that question in the next section by obtaining our own wing starting from nothing but the physics of airflow.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%;margin-bottom: 200px; margin-top: 50px&quot;&gt;
    &lt;a href=&quot;../../../../2020/10/14/optimizing-a-wing/&quot; id=&quot;featuredlink&quot; target=&quot;_blank&quot; style=&quot;margin-right: 10px;&quot;&gt;Post #3: Optimizing a Wing&lt;/a&gt;
&lt;/div&gt;

&lt;h3 id=&quot;appendix-airfoil-timeline&quot;&gt;Appendix: Airfoil Timeline&lt;/h3&gt;

&lt;p&gt;Here is a complete timeline of the airfoils we discussed in this post. Outlines in the first three columns were obtained from primary sources and are technically accurate. Outlines in the fourth row are believed to be technically accurate – or close 🤷‍♂️&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%;&quot;&gt;
  &lt;div style=&quot;width:99%; min-width:350px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/stepping-stones/airfoil-timeline-full.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Wenham, Francis Herbert. &lt;a href=&quot;https://babel.hathitrust.org/cgi/pt?id=uc1.b4513625&amp;amp;view=1up&amp;amp;seq=24&quot;&gt;On aërial locomotion and the laws by which heavy bodies impelled through the air are sustained&lt;/a&gt;, &lt;em&gt;Annual Report of the Aëronautical Society of Great Britain&lt;/em&gt;, p. 10-20, 1866. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Allward, Maurice. An Illustrated History of Seaplanes and Flying Boats, &lt;em&gt;New York: Dorset Press&lt;/em&gt;, p. 11, 1981. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Crosby, Francis. The Complete Guide to Fighters &amp;amp; Bombers of the World: An Illustrated History of the World’s Greatest Military Aircraft, &lt;em&gt;London: Anness Publishing Ltd.&lt;/em&gt;, p. 16, 2006. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn3:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Gibbs-Smith, Charles Harvard. Aviation. &lt;em&gt;London: NMSI&lt;/em&gt;, p. 57, 2003. &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Boulton, Matthew Piers Watt. On Aerial Locomotion. &lt;em&gt;Bradbury &amp;amp; Evans, London&lt;/em&gt;, 1864. &lt;a href=&quot;#fnref:fn5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Gibbs-Smith, 2003. p. 68. &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;National Air and Space Museum. The Ariel: The First Carriage Of The Ærial Transit Company. &lt;em&gt;National Air and Space Museum Collection&lt;/em&gt;, 1843. &lt;a href=&quot;#fnref:fn7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Otto Lilienthal. &lt;em&gt;Birdflight as the Basis of Aviation.&lt;/em&gt; Longmans, Green, and Co., London, 1 edition, 1889. &lt;a href=&quot;#fnref:fn14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn15&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;The wrong value of this coefficient had been in use for more than a hundred years and was part of the accepted equation for lift. So in determining that this number was wrong, the Wrights made a major discovery. &lt;a href=&quot;#fnref:fn15&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Topnotch Gist. &lt;a href=&quot;https://youtu.be/NGZ7gRlwLJs&quot;&gt;The History And Evolution of Modern Airplane Wing Design&lt;/a&gt;. &lt;em&gt;YouTube&lt;/em&gt;, 2020. &lt;a href=&quot;#fnref:fn8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://www.century-of-flight.freeola.com/Aviation%20history/evolution%20of%20technology/Airfoils.htm&quot;&gt;Airfoils&lt;/a&gt; and &lt;a href=&quot;http://www.century-of-flight.freeola.com/Aviation%20history/evolution%20of%20technology/Supercritical%20Airfoil.htm&quot;&gt;Supercritical Airfoils&lt;/a&gt;. &lt;em&gt;Century of Flight&lt;/em&gt;. &lt;a href=&quot;#fnref:fn9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn9:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;#fnref:fn9:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Garrison, Peter. &lt;a href=&quot;https://www.airspacemag.com/history-of-flight/the-man-who-could-see-air-28723910/?page=2&quot;&gt;The Man Who Could See Air&lt;/a&gt;. &lt;em&gt;Air &amp;amp; Space Magazine&lt;/em&gt;, 2002 &lt;a href=&quot;#fnref:fn10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Many of the airfoil shapes used in this post were taken from NASA’s &lt;a href=&quot;https://history.nasa.gov/SP-4305/p115.htm&quot;&gt;historical archives&lt;/a&gt;. See “SP-4305 Engineer in Charge” &lt;a href=&quot;https://history.nasa.gov/&quot;&gt;&lt;em&gt;NASA History Division&lt;/em&gt;&lt;/a&gt;, 1986. &lt;a href=&quot;#fnref:fn11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">How did flight become a reality? Let&apos;s look at the inventors who took flight from the world of ideas to the world of things – focusing in particular on airfoil design.</summary></entry><entry><title type="html">The Story of Flight</title><link href="http://greydanus.github.io/2020/10/12/story-of-flight/" rel="alternate" type="text/html" title="The Story of Flight" /><published>2020-10-12T04:00:00-07:00</published><updated>2020-10-12T04:00:00-07:00</updated><id>http://greydanus.github.io/2020/10/12/story-of-flight</id><content type="html" xml:base="http://greydanus.github.io/2020/10/12/story-of-flight/">&lt;div&gt;
  &lt;style&gt;
      #linkbutton:link, #linkbutton:visited {
        padding: 6px 0px;
        text-decoration: none;
        display: inline-block;

        border: 2px solid #777;
        padding: 10px;
        font-size: 20px;
        min-width: 200px;
        width: 50%;
        text-align: center;
        color: #999;
        margin: 0px auto;
        cursor: pointer;
        margin-bottom: 10px;
      }

      #linkbutton:hover, #linkbutton:active {
        background-color: rgba(245, 245, 245);
      }

    .playbutton {
      background-color: rgba(0, 153, 51);
      /*background-color: rgba(255, 130, 0);*/
      border-radius: 4px;
      color: white;
      padding: 3px 8px;
      /*width: 60px;*/
      text-align: center;
      text-decoration: none;
      text-transform: uppercase;
      font-size: 12px;
      /*display: block;*/
      /*margin-left: auto;*/
      margin: 8px 0px;
      margin-right: auto;
      min-width:80px;
    }
  &lt;/style&gt;
&lt;/div&gt;

&lt;!-- &lt;div class=&quot;imgcap_noborder&quot;&gt;
  &lt;img src=&quot;/assets/story-of-flight/hummingbird.png&quot; style=&quot;width:10%;min-width:150px;&quot;&gt;
&lt;/div&gt; --&gt;

&lt;p&gt;When I was growing up, hummingbirds used to fly into our garage and get stuck. I remember finding one perched on a windowsill, weak from exertion. It let me fold my hands around it and carry it outside. And when I opened my hands, it lay on my palms for a moment. That’s when the sunlight ignited its iridescent plumage and engulfed its whole body in a cloud of blues and greens. Then it understood it was free, whirred its wings, and vanished into the open air. Long after it had departed, my mind’s eye gazed upon the little bird. With an idle curiosity, I tried to imagine how natural forces could have wrought such a thing. We know of lift and drag, thrust and gravity as rough textbook concepts. But it’s another thing entirely to gaze upon a creature of beauty and sophistication and realize that it was shaped in part by those simple forces.&lt;/p&gt;

&lt;p&gt;Since my encounter with the hummingbird, I have always been naturally drawn to flight. It’s a bizarre desire to possess, since humans did not evolve to fly. And yet many humans have felt the same way over the years. Entire cultures, even, have dreamed of flight. And step by step, they have used technology to fashion their own artificial wings and bring about the modern-day miracle of flight. The purpose of this series of posts is to recount that epic adventure. I will tell it through the lens of history, looking at the individual people who wanted to fly, the lens of technology, looking at the key inventions leading up to modern airplanes, and the lens of physics, looking at the equations of airflow that made it all possible. As a final flourish, I will derive a wing from scratch by simulating a wind tunnel, differentiating through it, and using gradient descent to deform a rectangular occlusion into a wing.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:32.8%; min-width:200px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/leonardo.jpg&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;Leonardo da Vinci, an important figure in the history of flight.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32.8%; min-width:200px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/lilienthal.jpg&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Otto Lilienthal, who made key technological breakthroughs in wing shape and design.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:32.8%; min-width:200px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/wing_shape.png&quot; id=&quot;wingShapeImage&quot; onclick=&quot;toggleWingShape()&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Optimizing our own wing in a fluid simulation. &lt;p style=&quot;color:grey;display:inline;&quot;&gt;[Click to pause or play.]&lt;/p&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;the-early-aviators&quot;&gt;The Early Aviators&lt;/h3&gt;

&lt;p&gt;In the past century alone, airplane design has progressed from the Wright brothers’ ramshackle &lt;em&gt;Flyer&lt;/em&gt; to Lockheed Martin’s streamlined &lt;em&gt;SR-71 Blackbird&lt;/em&gt;. In parallel, our commercial aviation system has developed to the point where anyone can enjoy the possibilities of flight. Flight has become so common and so reasonable that it’s easy to forget the towering lusts and follies that accompanied its invention. But if we are to understand why humans wanted to fly in the first place, we need to relive those lusts and follies. One way to do this is by looking back at the lives of the early aviators.&lt;/p&gt;

&lt;p&gt;Perhaps none of the early aviators wanted to fly as much as the tower jumpers. Beginning in the Middle Ages, there was a string of inventors who fashioned wings for themselves and then leaped from towers in imitation of birds. These daredevils were the tower jumpers. Having neglected the essential calculations of lift and drag, they relied mostly on wits, intuition, and dumb luck to survive. Alas, gravity tended to be stronger. Most of their attempts ended in death or serious injury. But one exception to the rule was the Andalusian inventor Abbas ibn Firnas. The story goes that he made his jump at the astonishing age of seventy years. Once he was airborne, his feather suit cushioned his fall and allowed him to glide to the ground unharmed.&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Somehow, in spite of his wild deeds, Abbas lived on to the respectable age of 78.&lt;/p&gt;

&lt;p&gt;The common folk of Andalusia must have enjoyed laughter and endless conversations about Abbas and his wingsuit. They would have asked, why does he want to fly? Pigs do not have wings and they are quite content about it. Why should humans, who likewise have no wings, want to pretend at flight? They would have been making a good point. After all, the tower jumpers needed to be more than half mad to take the risks they did. But on a fundamental level, they were probably driven by things that most humans can relate to: the desires for freedom, glory, and adventure.&lt;/p&gt;

&lt;h3 id=&quot;the-freedom-of-flight&quot;&gt;The Freedom of Flight&lt;/h3&gt;

&lt;p&gt;We can see this in Leonardo da Vinci, whose work on flight was deeply rooted in a desire for freedom. Most people know that da Vinci painted the Mona Lisa and sketched a number of remarkable flying machines. However, few of them are aware of the pressures that shaped him.&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; Leonardo began life as the illegitimate son of an Italian aristocrat and a peasant woman. And so he had to support himself from an early age by taking on strict apprenticeships and painting for wealthy patrons. The fact that he was gay complicated things even further.&lt;/p&gt;

&lt;p&gt;His life reached a moment of crisis on his 27th birthday when he and his friends were imprisoned for acts of sodomy. Imprisonment affected him deeply. As soon as he was released, he sketched a machine meant to “open a prison from the inside” and another for tearing bars off of windows. Around the same time, he became obsessed with bird flight and began buying birds at markets in order to sketch them. When he finished sketching them, he would free them from their cages. “Once you have tasted flight,” he wrote, “you will forever walk the earth with your eyes turned skyward. For there you have been, and there you will always long to return.” For da Vinci, flight seems to have been a metaphor for freedom and an antidote to the horrors of captivity.&lt;/p&gt;

&lt;h3 id=&quot;the-glory-of-flight&quot;&gt;The Glory of Flight&lt;/h3&gt;

&lt;p&gt;But freedom is not the only reason people wanted to fly. For others, flight was a shot at glory – and nobody loved glory more than the French chemist Pilatre de Rozier. This man was quite a character. He was known to breathe fire, seduce older women, and give himself fake titles.&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;As a young scientist, he signed his papers, “Apothecary,” then “first Apothecary,”” and finally, “Pharmacy Inspector” of the Prince of Limbourg. This impressed his colleagues until they discovered that the Prince of Limbourg did not, in fact, exist. In a twist of irony, it was this same hunger for glory that also led de Rozier to his greatest scientific breakthroughs. The first was the match, which he invented in order to show off his fire breathing skills in a public lecture. The second was the gas mask, which he used in a stunt that involved lowering himself into the fumes of a vat of fermenting beer. The final, and most significant breakthrough, was his completion of the first manned voyage in a hot air balloon. King Louis XVI wanted to put criminals in the balloon but de Rozier objected, saying “The glory should not be given to criminals!”&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Pilatre was far from perfect, but his bravery and showmanship inspired people and gave aeronauts an immensely positive image in France. His initial balloon launch attracted a crowd of over a hundred thousand people. When these people saw him land safely, common attitudes about flight changed. No longer was human flight seen as a thing of folly. It became a source of national pride and a crowning achievement of science. And for many, it began to represent an exciting new frontier.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:35.5%; min-width:180px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/davinci_glider.jpg&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align: left;&quot;&gt;A page from one of da Vinci&apos;s journals describes an &quot;air screw&quot; that resembles a modern helicopter. &lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:26.9%; min-width:130px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/balloon.png&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Pilatre de Rozier and his companion take off in a hot air balloon.&lt;/div&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:36.4%; min-width:180px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/story-of-flight/earhart.jpg&quot; style=&quot;width:100%&quot; /&gt;
    &lt;div style=&quot;text-align:left;&quot;&gt;Amelia Earhart sitting upon the nose of her plane in 1936.&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Like any new frontier, flight called most strongly to those with a sense of imagination and adventure. One person who heeded this call was &lt;a href=&quot;https://en.wikipedia.org/wiki/Antoine_de_Saint-Exup%C3%A9ry&quot;&gt;Antoine de Saint-Exupery&lt;/a&gt;. In his short life, he became both a decorated military pilot and one of France’s best poets and novelists. He managed this double act by blending his writing with his flying until they became almost the same activity. There are eccentric stories about how he wrote poetry during military scouting missions and once circled a landing strip for an hour to finish reading a good novel.&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; To Saint-Exupery, flight was as much an adventure of the mind as it was the body. In fact, he argued that these two adventures were inseparable: the way a mind perceives the physical world determines how the body will eventually shape it. Or, as he put it, “A rock pile ceases to be a rock pile the moment a single man contemplates it, bearing within him the image of a cathedral.” His own life supports that idea, for, in thinking and writing about flight from the lens of an artist, he transformed it into something that promised not only freedom and glory, but also beauty and adventure.&lt;/p&gt;

&lt;p&gt;The other side of venturing into a frontier is that one must leave behind the comforts of civilized life. Even as airplanes improved in the early 1900’s, they remained costly, dangerous, and generally impractical. So every one of the early aviators had to make sacrifices in order to fly. But one person who had to make especially tough choices was Amelia Earhart.&lt;/p&gt;

&lt;p&gt;Earhart was one of the best early airplane pilots and famously went missing during an attempt to fly around the world. The first, and most obvious choice she had to make was to risk her life in pursuit of that goal. But apart from safety, she had to risk bankruptcy throughout her twenties – taking odd jobs and once selling her plane in order to support herself. And finally, once she was able to support herself financially, she had to risk losing love and the chance at marriage. The publicist George Putnam had proposed and the two were preparing for marriage when she explained to him, “I cannot endure at all times even an attractive cage.”&lt;sup id=&quot;fnref:fn8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn8&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; Putnam eventually agreed to an unconventional open marriage, but Earhart’s letter suggests she was prepared to forgo it entirely if it interfered with her ability to fly. Like Earhart, many of the early aviators had to lose wealth, love, or life in the pursuit of flight.&lt;/p&gt;

&lt;p&gt;That was the nature of life on the new frontier.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%;margin-bottom: 100px; margin-top: 50px&quot;&gt;
    &lt;a href=&quot;../../../../2020/10/13/stepping-stones/&quot; id=&quot;featuredlink&quot; target=&quot;_blank&quot; style=&quot;margin-right: 10px;&quot;&gt;Post #2: The Stepping Stones of Flight&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;script language=&quot;javascript&quot;&gt;
  function toggleWingShape() {

    path = document.getElementById(&quot;wingShapeImage&quot;).src
      if (path.split(&apos;/&apos;).pop() == &quot;wing_shape.png&quot;) 
      {
          document.getElementById(&quot;wingShapeImage&quot;).src = &quot;/assets/story-of-flight/wing_summary.gif&quot;;
      }
      else 
      {
          document.getElementById(&quot;wingShapeImage&quot;).src = &quot;/assets/story-of-flight/wing_shape.png&quot;;
      }
  }
&lt;/script&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;White, Lynn Townsend Jr. &lt;a href=&quot;https://www.jstor.org/stable/pdf/3101411.pdf?seq=1&quot;&gt;Eilmer of Malmesbury, an Eleventh Century Aviator: A Case Study of Technological Innovation, Its Context and Tradition&lt;/a&gt;, &lt;em&gt;Technology and Culture 2&lt;/em&gt;, p. 97-111, 1961. For a quick but less scholarly overview, try &lt;a href=&quot;https://www.thefamouspeople.com/profiles/abbas-ibn-firnas-33319.php&quot;&gt;this online article&lt;/a&gt;. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Isaacson, Walter. Leonardo da Vinci, &lt;em&gt;Simon &amp;amp; Schuster&lt;/em&gt;, 2017. See also this New Yorker &lt;a href=&quot;https://www.newyorker.com/magazine/2017/10/16/the-secret-lives-of-leonardo-da-vinci&quot;&gt;review article&lt;/a&gt; about the book. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Duval, Clément. &lt;a href=&quot;https://online.ucpress.edu/hsns/article/doi/10.2307/27757275/33554/Pilatre-de-Rozier-1754-1785-Chemist-and-First&quot;&gt;Pilatre de Rozier (1754-1785), Chemist and First Aeronaut&lt;/a&gt;, &lt;em&gt;Chymia&lt;/em&gt;, 1967. This article is well written, and quite fun to read. I’d recommend the whole thing. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Penenberg, Adam L. &lt;a href=&quot;https://books.google.com/books?id=WCmUCwAAQBAJ&amp;amp;pg=PT56&amp;amp;lpg=PT56&amp;amp;dq=rozier+louis+criminal+balloon&amp;amp;source=bl&amp;amp;ots=c0b-7imHWp&amp;amp;sig=ACfU3U14AFxunsLlX7D6PxEp82CYpVC5FQ&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=2ahUKEwjHyZCZxJvqAhUU7J4KHRStCqcQ6AEwDHoECAwQAQ#v=onepage&amp;amp;q=rozier%20louis%20criminal%20balloon&amp;amp;f=false&quot;&gt;Sky Rivals: Two Men. Two Planes. An Epic Race Around the World.&lt;/a&gt;, &lt;em&gt;Wayzgoose Press&lt;/em&gt;, 2016 &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Schiff, Stacy. &lt;a href=&quot;https://web.archive.org/web/20161020193505/https://books.google.com/books?id=2G4Q_GNpCUMC&amp;amp;hl=en&quot;&gt;Saint-Exupéry: A Biography&lt;/a&gt;, &lt;em&gt;Da Capo Press&lt;/em&gt;, 1997. See also the &lt;a href=&quot;https://en.wikipedia.org/wiki/Antoine_de_Saint-Exup%C3%A9ry&quot;&gt;Wikipedia article&lt;/a&gt; about Saint-Exupéry. &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://www.huffpost.com/entry/amelia-earhart-prenup_n_2280057&quot;&gt;Amelia Earhart’s Prenup Is Remarkably Modern&lt;/a&gt;, &lt;em&gt;Huffington Post&lt;/em&gt;, 2017. An image of the prenuptual letter itself is &lt;a href=&quot;https://images.huffingtonpost.com/2012-12-11-earhart.jpg&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;#fnref:fn8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Why do humans want to fly? Let&apos;s start by looking at the humans for whom the desire to fly was strongest: the early aviators.</summary></entry><entry><title type="html">Self-classifying MNIST Digits</title><link href="http://greydanus.github.io/2020/08/27/selforg-mnist/" rel="alternate" type="text/html" title="Self-classifying MNIST Digits" /><published>2020-08-27T04:00:00-07:00</published><updated>2020-08-27T04:00:00-07:00</updated><id>http://greydanus.github.io/2020/08/27/selforg-mnist</id><content type="html" xml:base="http://greydanus.github.io/2020/08/27/selforg-mnist/">&lt;div&gt;
	&lt;style&gt;
        #linkbutton:link, #linkbutton:visited {
          padding: 6px 0px;
          text-decoration: none;
          display: inline-block;

          border: 2px solid #777;
          padding: 10px;
          font-size: 20px;
          min-width: 200px;
          width: 50%;
          text-align: center;
          color: #999;
          margin: 0px auto;
          cursor: pointer;
          margin-bottom: 10px;
        }

        #linkbutton:hover, #linkbutton:active {
          background-color: rgba(245, 245, 245);
        }

		.playbutton {
		  background-color: rgb(148, 196, 146);
		  border-width: 0;
		  /*background-color: rgba(255, 130, 0);*/
		  border-radius: 4px;
		  color: white;
		  padding: 5px 8px;
		  /*width: 60px;*/
		  text-align: center;
		  text-decoration: none;
		  text-transform: uppercase;
		  font-size: 12px;
		  /*display: block;*/
		  /*margin-left: auto;*/
		  margin: 8px 0px;
		  margin-right: auto;
		  min-width:60px;
		}

		.playbutton:hover, .playbutton:active {
		  background-color: rgb(128, 176, 126);
		}
	&lt;/style&gt;
&lt;/div&gt;

&lt;p&gt;In this project, we treat every pixel in an image as a biological cell. Then we train these cells to send signals to their neighbors so that, over time, the entire population will agree on what digit they are shaping. Every cell “votes” on the global shape by turning one of ten different colors, corresponding to the ten digits. Sometimes the truth prevails and sometimes they are collectively misguided. I like &lt;a href=&quot;https://twitter.com/hardmaru/status/1299152583328559105&quot;&gt;@hardmaru’s example&lt;/a&gt;, reproduced below, of a 4 vs. a 2 (🔴 🔵). It’s similar to an election process – it even has “swing states:”&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:100%; min-width:250px; display: inline-block; vertical-align: top;text-align:center;&quot;&gt;
    &lt;video style=&quot;width:100%;min-width:250px;&quot; controls=&quot;&quot;&gt;
    	&lt;source src=&quot;/assets/selforg-digits/screencapture.mp4&quot; type=&quot;video/mp4&quot; /&gt;
    &lt;/video&gt;
&lt;!--     &lt;div style=&quot;text-align: left;margin-left:10px;margin-right:10px;padding-top: 20px;&quot;&gt;

    	&lt;/div&gt; --&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I encourage you to read the article and try the interactive demo for yourself on Distill:&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;a href=&quot;https://distill.pub/2020/selforg/mnist/&quot; id=&quot;featuredlink&quot; target=&quot;_blank&quot; style=&quot;margin-right: 10px;&quot;&gt;Read the article on Distill&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;useful-properties-of-cellular-automata&quot;&gt;Useful properties of Cellular Automata&lt;/h2&gt;

&lt;p&gt;One of the takeaways from helping write this Distill article is that cellular automata are fascinating and underrated. In particular, I like them because they are:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Local.&lt;/strong&gt; All interactions in physics are local – aside from quantum entanglement, and even that is up for debate.&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; All interactions in chemistry and biology are also local, including the interactions between neurons that allow us to learn. The value of locality is that it is one of the &lt;em&gt;strongest&lt;/em&gt; bounds on the complexity of a system. Without locality, any unit (atom, molecule, cell, human) can interact with any other, leading to an exponential growth in causal influences on each unit as the size of the system increases. This is bad news if you want to establish any interesting chains of causality between various sub-units.&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; For example, when you store information using a small chunk of matter, you do so under the assumption that that information will remain where it is and not change in response to external factors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parallelizable.&lt;/strong&gt; One particularly important advantage of locality is that it makes CAs immensely parallelizable. It’s not hard to train or evaluate a large population of CAs asynchronously: disparate parts of the system never have to communicate or synchronize with one another. This is why, if we do live in a simulation, it is probably implemented with a CA.&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scalable in number of cells.&lt;/strong&gt; This is closely connected to “parallelizable.” Imagine training a 20x20 population of cells to do something and then running a 200x200 population of them on some downstream task. The numbers are different, but we actually do this in the demo. This is not something you can do with neural networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expressive.&lt;/strong&gt; Given how simple some CAs can be – for example, Conway’s Game of Life – they have impressive theoretical properties. They are Turing complete and can simulate any other system. You could even use Conway’s Game of Life to simulate Conway’s Game of Life…and yes, &lt;a href=&quot;https://twitter.com/AlanZucconi/status/1315967202797981696&quot;&gt;someone actually did this&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resilient.&lt;/strong&gt; Systems where local interactions eventually lead to global behavior are extraordinarily resilient. You can cut a 2-headed planarian in half and both halves will regenerate. You can cut a limb from a tree and the tree will survive. You can leave your company and your coworkers will continue on without you, barely noticing your absence. Ok, that was a joke, they will miss you, but in theory they should be able to cover for you when you take a few vacation days.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Likely to fail gracefully.&lt;/strong&gt; It’s hard to define what it means to “fail gracefully” so this last point is a bit subjective. Consider the failure case of the 4/2 pattern from the video above, reproduced below. That shape is far outside of the CA’s training distribution, but it responded in a fairly intuitive manner. On the left is another fun failure case where a CA was trained to grow, from a single cell, into a yellow fish emoji. The population of cells kept growing even after it became a mature fish, but did so in a way that preserved the fish’s shape and body texture.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:99.9%&quot;&gt;
  &lt;div style=&quot;width:47.3%; min-width:200px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/selforg-digits/42_color.png&quot; style=&quot;width:100%&quot; /&gt;
  &lt;/div&gt;
  &lt;div style=&quot;width:52%; min-width:300px; display: inline-block; vertical-align: top;&quot;&gt;
    &lt;img src=&quot;/assets/selforg-digits/fish.png&quot; style=&quot;width:100%&quot; /&gt;
&lt;!--     &lt;div style=&quot;text-align:left;&quot;&gt;A plot by &lt;a href=&quot;https://doi.org/10.1002/jmor.10013&quot;&gt;Lindhe (2002)&lt;/a&gt; showing aspect ratio versus wing loading index in some birds, airplanes, a hang-glider, a butterfly, and a maple seed. Just like the families of birds, different human flying machines display substantial variation along these axes.&lt;/div&gt; --&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I like CA as a design motif. They capture a set of elegant design principles that, even if we don’t follow them strictly at all times in other areas of science, are worth thinking about.&lt;/p&gt;

&lt;h2 id=&quot;parting-words&quot;&gt;Parting words&lt;/h2&gt;

&lt;p&gt;It feels good to have released the Distill article and demo to the world. Now, on thousands of different browser screens, our little cells are coming to life. They are looking at their particular MNIST pixels, talking to their neighbors, and trying to figure out what their overall digit shape is. Little do they know, they are part of a human scientific endeavor that is much the same. For we humans, too, are looking at our local surroundings, talking with our neighbors, and trying to agree on the overall shape of our reality.&lt;/p&gt;

&lt;p&gt;Best of luck to the little cells and to us humans as well.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;I want to write a post on this, but I have more reading to do first. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;One of the problems with fully-connected neural networks is that they use very dense connectivity patterns – denser, perhaps, than locality constraints permit in the brain. In recent years, we’ve seen that particular connectivity patterns (e.g. the local connectivity of ConvNets) have major advantages. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Which makes the fact that this article is about CA pretty meta. &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">We treat every pixel in an image as a biological cell. We train these cells to signal to one another and determine what digit they are shaping.</summary></entry><entry><title type="html">Lagrangian Neural Networks</title><link href="http://greydanus.github.io/2020/03/10/lagrangian-nns/" rel="alternate" type="text/html" title="Lagrangian Neural Networks" /><published>2020-03-10T04:00:00-07:00</published><updated>2020-03-10T04:00:00-07:00</updated><id>http://greydanus.github.io/2020/03/10/lagrangian-nns</id><content type="html" xml:base="http://greydanus.github.io/2020/03/10/lagrangian-nns/">&lt;p&gt;Accurate models of the world are built on notions of its underlying symmetries. In physics, these symmetries correspond to conservation laws, such as for energy and momentum. But neural network models struggle to learn these symmetries. To address this shortcoming, last year I introduced a class of models called Hamiltonian Neural Networks (HNNs) that can learn these invariant quantities directly from (pixel) data. In this project, some friends and I are going to introduce a complimentary class of models called Lagrangian Neural Networks (LNNs). These models are able to learn Lagrangian functions straight from data. They’re interesting because, like HNNs, they can learn exact conservation laws, but unlike HNNs they don’t require canonical coordinates.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:90%&quot;&gt;
	&lt;img src=&quot;/assets/lagrangian-nns/overall-idea.png&quot; style=&quot;padding: 0px 0px 10px 0px;&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto; width:90%&quot;&gt;&lt;b&gt;Figure 1:&lt;/b&gt; A Lagrangian Neural Network learns the Lagrangian of a double pendulum. In this post, we introduce Lagrangian Neural Networks (LNNs). Like Hamiltonian Neural Networks, they can learn arbitrary conservation laws. In some cases they are better since they do not require canonical coordinates.&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://arxiv.org/abs/2003.04630&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://colab.research.google.com/drive/1CSy-xfrnTX28p1difoTA8ulYw0zytJkq&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;colab-span&quot;&gt;Run&lt;/span&gt; in browser&lt;/a&gt;
	&lt;a href=&quot;https://github.com/MilesCranmer/lagrangian_nns&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;a-scientific-poem&quot;&gt;“A scientific poem”&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Joseph-Louis_Lagrange&quot;&gt;Joseph-Louis&lt;/a&gt; &lt;a href=&quot;https://www.famousscientists.org/joseph-louis-lagrange/&quot;&gt;Lagrange&lt;/a&gt; must have known that life is short. He was born to a family of 11 children and only two of them survived to adulthood. Then he spent his adult years in Paris, living through the Reign of Terror and &lt;a href=&quot;https://books.google.com/books?id=_q7zCAAAQBAJ&amp;amp;pg=PR28&amp;amp;lpg=PR28&amp;amp;dq=It+took+only+a+moment+to+cause+this+head+to+fall+and+a+hundred+years+will+not+suffice+to+produce+its+like.&amp;amp;source=bl&amp;amp;ots=pP-iyGhBRq&amp;amp;sig=ACfU3U1CqtjR-wSD1Zlt3uZX6SEbUwNRqg&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=2ahUKEwji8pma_pDoAhXXqZ4KHUl0DZcQ6AEwAHoECAgQAQ#v=onepage&amp;amp;q=It%20took%20only%20a%20moment%20to%20cause%20this%20head%20to%20fall%20and%20a%20hundred%20years%20will%20not%20suffice%20to%20produce%20its%20like.&amp;amp;f=false&quot;&gt;losing some of his closest friends to the guillotine&lt;/a&gt;. Sometimes I wonder if these hardships made him more sensitive to the world’s ephemeral beauty, and more determined to make the most of his short time here.&lt;/p&gt;

&lt;p&gt;Indeed, his path into research was notable for its passion and suddenness. Until the age of 17, Lagrange was a normal youth who planned to become a lawyer and showed no particular interest in mathematics. But all of that changed when he read an inspiring memoir by Edmund Halley and decided to embark on an obsessive course of self-study in mathematics. A mere two years later he published the principle of least action.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I will deduce the complete mechanics of solid and fluid bodies using the principle of least action.” – Joseph-Louis Lagrange, age 20&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:50%&quot;&gt;
	&lt;img src=&quot;/assets/lagrangian-nns/lagrange.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot;&gt;A French stamp commemorating Lagrange.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Lagrange’s work was notable for its purity and beauty, especially in contrast to the chaotic and broken times that he lived through. Expressing admiration for the principle of least action, William Hamilton once called it &lt;a href=&quot;https://books.google.com/books?id=j_kJCAAAQBAJ&amp;amp;pg=PA130&amp;amp;lpg=PA130&amp;amp;dq=joseph+lagrange+beauty+of+virtual+work&amp;amp;source=bl&amp;amp;ots=771naVFjo6&amp;amp;sig=ACfU3U0L4Bj9IabO1jFh7jJK0pEgoVVfWg&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=2ahUKEwjAppGZtY7oAhXcGTQIHfp3CncQ6AEwAHoECAwQAQ#v=onepage&amp;amp;q=joseph%20lagrange%20beauty%20of%20virtual%20work&amp;amp;f=false&quot;&gt;“a scientific poem”&lt;/a&gt;. In the following sections, I’ll introduce you to this “scientific poem” and then use it to derive Lagrangian Neural Networks.&lt;/p&gt;

&lt;h2 id=&quot;the-principle-of-least-action&quot;&gt;The Principle of Least Action&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;The Action.&lt;/strong&gt; Start with any physical system that has coordinates \(x_t = (q, \dot q)\). For example, we might describe a double pendulum using the angles of its arms and their respective angular velocities. Now, one simple observation is that these coordinates must start in one state \(x_0\) and end up in another, \(x_1\). There are many paths that these coordinates might take as they pass from \(x_0\) to \(x_1\), and we can associate each of these paths with a scalar value \(S\) called “the action.” Lagrangian mechanics tells us that the action is related to kinetic and potential energy, \(T\) and \(V\), by a functional&lt;/p&gt;

&lt;p&gt;\(\begin{equation}
S ~=~ \int_{t_0}^{t_1} T(q_t, \dot q_t) - V(q_t, \dot q_t) ~~ dt.
\label{eq:eqn1}
\tag{1}
\end{equation}\)
&lt;!-- &lt;div class=&quot;thecap&quot; style=&quot;text-align:center; width:50%&quot;&gt;&lt;b&gt;Figure 3:&lt;/b&gt; Possible paths from x0 to x1, plotted in configuration space. The action is stationary (δS = 0) for small perturbations (δq) to the path that the system actually takes (red). .&lt;/div&gt; --&gt;&lt;/p&gt;

&lt;p&gt;At first glance, \(S\) seems like an arbitrary combination of energies. But it has one remarkable property. It turns out that for all possible paths between \(x_0\) and \(x_1\), there is only one path that gives a stationary value of \(S\). Moreover, that path is the one that nature always takes.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:50%&quot;&gt;
	&lt;img src=&quot;/assets/lagrangian-nns/paths.png&quot; style=&quot;width:100%&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto;&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrangian_mechanics#/media/File:Least_action_principle.svg&quot; target=&quot;_blank&quot;&gt;Figure 3:&lt;/a&gt;&lt;/b&gt; Possible paths from q0 to q1, plotted in &lt;a href=&quot;https://en.wikipedia.org/wiki/Configuration_space_(physics)&quot;&gt;configuration space&lt;/a&gt;. The action is stationary (δS = 0) for small perturbations (δq) to the path that the system actually takes (red).&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;The Euler-Lagrange equation.&lt;/strong&gt; In order to “deduce the complete mechanics of solid and fluid bodies,” all Lagrange had to do was constrain every path to be a stationary point in \(S\). The modern principle of least action looks very similar: we let \(\mathcal{L} \equiv T - V\) (this is called the Lagrangian), and then write the constraint as \( \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot q_j} = \frac{\partial \mathcal{L}}{\partial q_j}\). Physicists call this constraint equation the &lt;em&gt;Euler-Lagrange equation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;When you first encounter it, the principle of least action can seem abstract and impractical. But it can be quite easy to apply in practice. Consider, for example, a single particle with mass \(m\), position \(q\), and potential energy \(V(q)\):&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;longEqnWithSmallScript_A&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\begin{align}
\scriptstyle \mathcal{L} &amp;amp; \scriptstyle ~=~ -V(q) + \frac{1}{2} m \dot q ^2 &amp;amp; \scriptstyle \text{write down the Lagrangian} \quad (2)\\
\scriptstyle -\frac{\partial V(q)}{\partial q} &amp;amp; \scriptstyle ~=~ m \ddot q &amp;amp; \scriptstyle \text{apply Euler-Lagrange} \quad (3)\\
\scriptstyle F &amp;amp; \scriptstyle ~=~ ma &amp;amp; \scriptstyle \text{this is Newton&apos;s second law } \quad (4)\\
\end{align}\)
&lt;/span&gt;
&lt;span id=&quot;longEqnWithLargeScript_A&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\begin{align}
\mathcal{L} &amp;amp; ~=~ -V(q) + \frac{1}{2} m \dot q ^2 &amp;amp; \text{write down the Lagrangian} \quad (2)\\
-\frac{\partial V(q)}{\partial q} &amp;amp; ~=~ m \ddot q &amp;amp;  \text{apply the Euler-Lagrange equation to } \mathcal{L} \quad (3)\\
 F &amp;amp; ~=~ ma &amp;amp; \text{this is Newton&apos;s second law } \quad (4)\\
\end{align}\)
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Nature’s cost function.&lt;/strong&gt; As a physicist who now does machine learning, I can’t help but think of \(S\) as Nature’s cost function. After all, it is a scalar quantity for which Nature finds a stationary point, usually a minimum, in order to generate the dynamics of the entire universe. The analogy gets even more interesting at small spatial scales, where quantum wavefunctions can be interpreted as Nature’s way of exploring multiple paths that are all very close to the path of stationary action.&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-we-usually-solve-lagrangians&quot;&gt;How we usually solve Lagrangians&lt;/h2&gt;

&lt;p&gt;Ever since Lagrange introduced the notion of stationary action, physicists have followed a simple formula:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Find analytic expressions for kinetic and potential energy&lt;/li&gt;
  &lt;li&gt;Write down the Lagrangian&lt;/li&gt;
  &lt;li&gt;Apply the Euler-Lagrange constraint&lt;/li&gt;
  &lt;li&gt;Solve the resulting system of differential equations&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But these analytic solutions are rather crude approximations of the real world. An alternative approach is to assume that the Lagrangian is an arbitrarily complicated function – a black box that does not permit analytical solutions. When this is the case, we must give up all hope of writing the Lagrangian out by hand. However, there is still a chance that we can parameterize it with a neural network and learn it straight from data. That is the main contribution of our recent paper.&lt;/p&gt;

&lt;h2 id=&quot;how-to-learn-lagrangians&quot;&gt;How to learn Lagrangians&lt;/h2&gt;

&lt;p&gt;The process of learning a Lagrangian differs from the traditional approach, but it also involves four basic steps:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Obtain data from a physical system&lt;/li&gt;
  &lt;li&gt;Parameterize the Lagrangian with a neural network (\(\mathcal{L}\equiv \mathcal{L}_{\theta}\)).&lt;/li&gt;
  &lt;li&gt;Apply the Euler-Lagrange constraint&lt;/li&gt;
  &lt;li&gt;Backpropagate through the constraint to train a parametric model that approximates the true Lagrangian&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first two steps are fairly straightforward, and we’ll see that automatic differentiation makes the fourth pretty painless. So let’s focus on step 3: applying the Euler-Lagrange constraint. Our angle of attack will be to write down the constraint equation, treat \(\mathcal{L}\) as a differentiable blackbox function, and see whether we can still obtain dynamics:&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;longEqnWithSmallScript_B&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\begin{align}
&amp;amp; \scriptstyle \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot q_j} \scriptstyle ~=~ \frac{\partial \mathcal{L}}{\partial q_j} &amp;amp; \scriptstyle \text{Euler-Lagrange } (5)\\
&amp;amp;\scriptstyle \frac{d}{dt} \nabla_{\dot q} \mathcal{L} \scriptstyle ~=~ \nabla_{q} \mathcal{L} &amp;amp; \scriptstyle \text{vectorize } (6)\\
&amp;amp;\scriptstyle \nabla_q \mathcal{L} \scriptstyle ~=~ (\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})\ddot q + (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L}) \dot q &amp;amp; \scriptstyle \text{expand }\frac{d}{dt} \text{ }(7)\\
&amp;amp;\scriptstyle \ddot q \scriptstyle ~=~ (\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})^{-1}[\nabla_q \mathcal{L} - (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L})\dot q] &amp;amp; \scriptstyle \text{solve for } \ddot q \text{ }(8)\\
\end{align}\)
&lt;/span&gt;
&lt;span id=&quot;longEqnWithLargeScript_B&quot; style=&quot;display:block; margin-left:auto;margin-right:auto;text-align:center;&quot;&gt;
\(\begin{align}
\frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot q_j} &amp;amp;= \frac{\partial \mathcal{L}}{\partial q_j} &amp;amp; \text{the Euler-Lagrange equation} \quad (5)\\
\frac{d}{dt} \nabla_{\dot q} \mathcal{L} &amp;amp;= \nabla_{q} \mathcal{L} &amp;amp; \text{switch to vector notation} \quad (6)\\
(\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})\ddot q + (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L}) \dot q &amp;amp;= \nabla_q \mathcal{L} &amp;amp; \text{expand time derivative }\frac{d}{dt} \quad (7)\\
\ddot q &amp;amp;= (\nabla_{\dot q}\nabla_{\dot q}^{\top}\mathcal{L})^{-1}[\nabla_q \mathcal{L} - (\nabla_{q}\nabla_{\dot q}^{\top}\mathcal{L})\dot q] &amp;amp; \text{matrix inverse to solve for } \ddot q \quad (8)\\
\end{align}\)
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;For a given set of coordinates \(x_t=(q_t,\dot q_t)\), we now have a method for calculating \(\dot x_t=(\dot q_t,\ddot q_t)\) from a blackbox Lagrangian. We can integrate this quantity to obtain the dynamics of the system. And in the same manner as Hamiltonian Neural Networks, we can learn \(\mathcal{L_{\theta}}\) by differentiating the MSE loss between \(\dot x_t^{\mathcal{L_{\theta}}}\) and \(\dot x_t^{\textrm{true}}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implementation.&lt;/strong&gt; If you look closely at Equation 8, you may notice that it involves both the Hessian and the gradient of a neural network during the forward pass of the LNN. This is not a trivial operation, but modern automatic differentiation makes things surprisingly smooth. Written in &lt;a href=&quot;https://github.com/google/jax&quot;&gt;JAX&lt;/a&gt;, Equation 8 is just a few lines of code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;q_tt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pinv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hessian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lagrangian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lagrangian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jacfwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lagrangian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_t&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;learning-real-lagrangians&quot;&gt;Learning real Lagrangians&lt;/h2&gt;

&lt;p&gt;In our paper, we conduct several experiments to validate this approach. In the first, we show that Lagrangian Neural Networks can learn the dynamics of a double pendulum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Double pendulum.&lt;/strong&gt; The double pendulum is a dynamics problem that regular neural networks struggle to fit because they have no prior for conserving the total energy of the system. It is also a problem where HNNs struggle, since the canonical coordinates of the system are not trivial to compute (see equations 1 and 2 of &lt;a href=&quot;https://diego.assencio.com/?index=e5ac36fcb129ce95a61f8e8ce0572dbf&quot;&gt;this derivation&lt;/a&gt; for example). But in contrast to these baseline methods, Figure 4 shows that LNNs are able to learn the Lagrangian of a double pendulum.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/lagrangian-nns/dblpend_error.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto;&quot;&gt;&lt;b&gt;Figure 4:&lt;/b&gt; Learning the dynamics of a double pendulum. Unlike the baseline neural network, our model learns to approximately conserve the total energy of the system. This is a consequence of the strong physical inductive bias of the Euler-Lagrange constraint.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;It’s also interesting to compare qualitative results. In the video below, we use a baseline neural network and an LNN to predict the dynamics of a double pendulum, starting from the same initial state. You’ll notice that both trajectories seem reasonable until the end of the video, when the baseline model shifts to states that have much lower total energies.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:80%&quot;&gt;
	&lt;div style=&quot;overflow:hidden; padding-top: 40%; position: relative;&quot;&gt;
		&lt;iframe style=&quot;border: 0;height: 100%;left: 0;position: absolute;top: 0;width: 100%;&quot; src=&quot;https://www.youtube.com/embed/ulQKNtTEuJI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:center; display: block; margin-left: auto; margin-right: auto; width:60%&quot;&gt;&lt;b&gt;Figure 5:&lt;/b&gt; Dynamics predictions of a baseline (left) versus an LNN (right)&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Relativistic particle.&lt;/strong&gt; Another system we considered was a particle of mass \(m=1\) moving at a relativistic velocity through a potential \(g\) with \(c=1\). The Lagrangian of the system is \(\mathcal{L} = ((1 - \dot{q}^2)^{-1/2} - 1) + g q\) and it is interesting because existing Hamiltonian and Lagrangian learning approaches fail. HNNs fail because the canonical momenta of the system are hard to compute. Deep Lagrangian Networks&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; fail because they make restrictive assumptions about the form of the Lagrangian.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:80%&quot;&gt;
	&lt;img src=&quot;/assets/lagrangian-nns/relativistic.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto;&quot;&gt;&lt;b&gt;Figure 6:&lt;/b&gt; Learning the dynamics of a relativistic particle. In the first plot (a), an HNN model fails to model the system because the default coordinates are non-canonical. In the second plot (b), we provide the HNN with proper canonical coordinates and it succeeds. In the third plot (c), we show that an LNN can fit the data even in the absence of canonical coordinates.&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related Work&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Learning invariant quantities.&lt;/strong&gt; This approach is similar in spirit to &lt;a href=&quot;https://greydanus.github.io/2019/05/15/hamiltonian-nns/&quot;&gt;Hamiltonian Neural Networks&lt;/a&gt; (HNNs) and Hamiltonian Generative Networks&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; (HGNs). In fact, this blog post was written as a compliment to the original HNN post and it has the same fundamental motivations. Unlike these previous works, our aim here is to learn a Lagrangian rather than a Hamiltonian so as not to restrict the inputs to being canonical coordinates. It’s worth noting that once we learn a Lagrangian, we can always use it to obtain the value of a Hamiltonian using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Legendre_transformation&quot;&gt;Legendre transformation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Lagrangian Networks (DeLaN, ICLR’19).&lt;/strong&gt; Another closely related work is Deep Lagrangian Networks&lt;sup id=&quot;fnref:fn3:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; in which the authors show how to learn specific types of Lagrangian systems. They assume that the kinetic energy is an inner product of the velocity, which works well for rigid body dynamics such as those in robotics. However, there are many physical systems that do not have this specific form. Some simple examples include a charged particle in a magnetic field or a fast-moving object with relativistic corrections. We see LNNs as a complement to DeLaNs in that they cover the cases where DeLaNs struggle but are less amenable to robotics applications.&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing Thoughts&lt;/h2&gt;

&lt;!-- Looking forward, we continue to be excited about the connection between machine learning and the principle of stationary action. One thing we&apos;d like to try is to write a loss function that _is_ the action \\(S\\) and then minimize it with gradient descent to obtain dynamics. On a similar note, we&apos;d like to think more about the connection between existing neural network training dynamics and the principle of least action. One of Yann LeCun&apos;s most beautiful papers, for example, is a derivation of backpropagation via the Euler-Lagrange constraint. This may be the proper way to speak about optimization dynamics such as catastrophic forgetting and deep double descent. --&gt;

&lt;p&gt;The principle of stationary action is a unifying force in physics. It represents a consistent “law of the universe” which holds true in every system humans have ever studied: from the very small&lt;sup id=&quot;fnref:fn1:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; to the very large, from the very slow to the very fast. Lagrangian Neural Networks represent a different sort of unification. They aim to strengthen the connection between real-world data and the underlying physical constraints that it obeys. This gives LNNs their own sort of beauty, a beauty that Lagrange himself may have admired.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;script&gt;
    function getBrowserSize(){
       var w, h;

         if(typeof window.innerWidth != &apos;undefined&apos;)
         {
          w = window.innerWidth; //other browsers
          h = window.innerHeight;
         } 
         else if(typeof document.documentElement != &apos;undefined&apos; &amp;&amp; typeof      document.documentElement.clientWidth != &apos;undefined&apos; &amp;&amp; document.documentElement.clientWidth != 0) 
         {
          w =  document.documentElement.clientWidth; //IE
          h = document.documentElement.clientHeight;
         }
         else{
          w = document.body.clientWidth; //IE
          h = document.body.clientHeight;
         }
       return {&apos;width&apos;:w, &apos;height&apos;: h};
}

if(parseInt(getBrowserSize().width) &lt; 800){
 document.getElementById(&quot;longEqnWithLargeScript_A&quot;).style.display = &quot;none&quot;;
}
if(parseInt(getBrowserSize().width) &gt; 800){
 document.getElementById(&quot;longEqnWithSmallScript_A&quot;).style.display = &quot;none&quot;;
}

if(parseInt(getBrowserSize().width) &lt; 800){
 document.getElementById(&quot;longEqnWithLargeScript_B&quot;).style.display = &quot;none&quot;;
}
if(parseInt(getBrowserSize().width) &gt; 800){
 document.getElementById(&quot;longEqnWithSmallScript_B&quot;).style.display = &quot;none&quot;;
}
&lt;/script&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Here \(e^{-S/h}\) is actually the probability of a particular path occurring. Because \(h\) is small, we usually only observe the minimum value of \(S\) on large scales. See &lt;a href=&quot;https://www.feynmanlectures.caltech.edu/II_19.html&quot;&gt;Feynman lecture 19&lt;/a&gt; for more on this. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn1:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Lutter, M., Ritter, C., and Peters, J. &lt;a href=&quot;https://arxiv.org/abs/1907.04490&quot;&gt;Deep lagrangian networks: Using physics as model prior for deep learning&lt;/a&gt;, &lt;em&gt;International Conference on Learning Representations&lt;/em&gt;, 2019. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn3:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Toth, P., Rezende, D. J., Jaegle, A., Racanière, S., Botev, A., &amp;amp; Higgins, I. &lt;a href=&quot;https://arxiv.org/abs/1909.13789&quot;&gt;Hamiltonian Generative Networks&lt;/a&gt;, &lt;em&gt;International Conference on Learning Representations&lt;/em&gt;, 2020. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>With Miles Cranmer and Stephan Hoyer</name></author><summary type="html">As a complement to Hamiltonian Neural Networks, I discuss how to parameterize Lagrangians with neural networks and then learn them from data.</summary></entry><entry><title type="html">The Paths Perspective on Value Learning</title><link href="http://greydanus.github.io/2020/01/27/paths-perspective/" rel="alternate" type="text/html" title="The Paths Perspective on Value Learning" /><published>2020-01-27T03:00:00-08:00</published><updated>2020-01-27T03:00:00-08:00</updated><id>http://greydanus.github.io/2020/01/27/paths-perspective</id><content type="html" xml:base="http://greydanus.github.io/2020/01/27/paths-perspective/">&lt;p&gt;I recently published a Distill article about value learning. This post includes a link to the article and some meta-commentary about the Distill format.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;a href=&quot;https://distill.pub/2019/paths-perspective-on-value-learning/&quot; id=&quot;featuredlink&quot; target=&quot;_blank&quot; style=&quot;margin-right: 10px;&quot;&gt;Read this article on Distill&lt;/a&gt;
&lt;/div&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;a href=&quot;https://distill.pub/2019/paths-perspective-on-value-learning/&quot; target=&quot;_blank&quot;&gt;
		&lt;img src=&quot;/assets/paths-perspective/screenshot.png&quot; /&gt;
	&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;thoughts-on-distill&quot;&gt;Thoughts on Distill&lt;/h2&gt;

&lt;p&gt;I’ve admired Distill since its inception. Early on I could tell by the clean diagrams, interactive demos, and digestible prose that the authors knew a lot about their craft. On top of that, I was excited because Distill filled two important niches.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Niche 1: Repaying research debt.&lt;/strong&gt; Our field has a rapid publication cycle and most researchers write more than one paper per year. The unintended consequence is that many of these papers are poorly written, quickly outdated, or even flat-out incorrect. Distill’s solution has been to collect the most important ideas and insights of machine learning in one place, without all the noise. In my experience this works well; I often learn as much from reading one Distill paper as I would from ten conference papers.&lt;/p&gt;

&lt;!-- &lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:53%&quot;&gt;
	&lt;img src=&quot;/assets/paths-perspective/arxiv-papers.jpeg&quot;&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 2.&lt;/b&gt; The number of ML papers on arXiv is rapidly increasing (plot credit: &lt;a href=&quot;https://t.co/6tjdLocleT?amp=1&quot;&gt;Jeff Dean&lt;/a&gt;). With this flood of new papers, much more &quot;publication noise&quot; has entered our field. Distill is one promising medium for separating the signal from the noise.&lt;/div&gt;
&lt;/div&gt; --&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:60%&quot;&gt;
	&lt;!-- &lt;img src=&quot;/assets/paths-perspective/research-debt.jpg&quot;&gt; --&gt;
	&lt;img src=&quot;/assets/paths-perspective/arxiv-papers.jpeg&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 1.&lt;/b&gt; The number of ML papers uploaded to ArXiv has increased exponentially in recent years. Distill aims to &lt;a href=&quot;https://distill.pub/2017/research-debt/&quot;&gt;reduce publication noise&lt;/a&gt; by summarizing key research ideas in a low-volume, peer-reviewed setting.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Niche 2: Highlighting qualitative results.&lt;/strong&gt; These days, it can be difficult to publish a deep learning paper &lt;a href=&quot;https://twitter.com/TacoCohen/status/1073902391270014976&quot;&gt;without a nice table showing that your approach achieves state-of-the-art results&lt;/a&gt;. These tables are certainly important, but a qualitative understanding of &lt;em&gt;what&lt;/em&gt; the model is doing and &lt;em&gt;why&lt;/em&gt; is just as important. Distill prioritizes these “science of deep learning” questions as Chris Olah told me, “because there is so much more to a neural network than its test loss.”&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:43%&quot;&gt;
	&lt;img src=&quot;/assets/paths-perspective/flowers.jpeg&quot; style=&quot;width:85%&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 2.&lt;/b&gt; Distill advocates &lt;a href=&quot;https://distill.pub/2017/feature-visualization/&quot;&gt;visualization&lt;/a&gt; &lt;a href=&quot;https://distill.pub/2018/differentiable-parameterizations/&quot;&gt;techniques&lt;/a&gt; that help researchers answer qualitative questions about their models.&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;my-experience-with-distill&quot;&gt;My experience with Distill&lt;/h2&gt;

&lt;p&gt;Writing a Distill article is Type 2 fun. It’s not easy and it’s not comfortable but it will make you a better researcher. My experience involved a lot of background research (re-reading Sutton’s RL textbook and watching David Silver’s lectures on YouTube) and a lot of work at a whiteboard. During the drafting process I had to delete everything and start from scratch a couple times. At times the process was frustrating and painful, but I sincerely believe that most of it was “growing pains” because I was pushing myself to create something really excellent.&lt;/p&gt;

&lt;p&gt;Writing a Distill article is not an individual pursuit. I was fortunate enough to work with Chris Olah and others from the editorial team. The editors have high standards but they make a sincere effort to get new people involved. They spent a lot of time teaching me the skills and thought processes I needed in order to make the article shine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advice.&lt;/strong&gt; My main advice is that &lt;em&gt;writing a Distill article is not like writing a conference paper&lt;/em&gt;. If you approach it with the same expectations, you will be sad. If you approach it with different expectations, you will be happy. A few key differences:&lt;/p&gt;

&lt;ul style=&quot;list-style-type:disc;&quot;&gt;
	&lt;li&gt;&lt;u&gt;Audience&lt;/u&gt;. Your audience is no longer your reviewers plus a smattering of people who study what you study. Now your audience is anyone who cares about ML research. When I write a conference paper, I imagine I&apos;m explaining my results to one of my professors. When I write a Distill article, I imagine I&apos;m explaining my results to a smart undergraduate.&lt;/li&gt;
	&lt;li&gt;&lt;u&gt;The story you tell&lt;/u&gt;. Many conference papers target a shortcoming of previous work and propose a better solution. Distill articles read more like natural science articles: the author collects data, analyzes it, and then reports what they found. A good example is &lt;a href=&quot;https://distill.pub/2019/activation-atlas/&quot;&gt;Activation Atlases&lt;/a&gt; where the authors &lt;i&gt;observe&lt;/i&gt; the features of a vision model, &lt;i&gt;hypothesize&lt;/i&gt; about what they are doing, and then &lt;i&gt;verify&lt;/i&gt; the hypothesis. Some articles such as &lt;a href=&quot;https://distill.pub/2016/misread-tsne/&quot;&gt;How to Use T-SNE Effectively&lt;/a&gt; don&apos;t even report new knowledge and instead focus on explaining a known concept really well.&lt;/li&gt;
	&lt;li&gt;&lt;u&gt;Diagrams and demos&lt;/u&gt;. Distill puts a premium on clarity. This doesn&apos;t mean that you &lt;i&gt;need&lt;/i&gt; to have fancy diagrams or demos in your article (some strong Distill articles do not), but if they are the best way to explain something, then use them! I got a lot of satisfaction from making my diagrams in Illustrator, coding my demos in JavaScript, and putting lots of time and thought into making things beautiful.&lt;/li&gt;
	&lt;li&gt;&lt;u&gt;Time to submission&lt;/u&gt;. From the initial idea to the final draft, you&apos;ll need about twice as much time as you&apos;d need for a conference paper.&lt;/li&gt;
	&lt;li&gt;&lt;u&gt;Time of review process&lt;/u&gt;. Plan on the review process also taking about twice as long.&lt;/li&gt;
	&lt;li&gt;&lt;u&gt;Sense of wonder&lt;/u&gt;. The very best modes of science communication have a way of inspiring wonder and excitement in their audience. Distill is no exception. Its articles help young researchers see the beauty and promise of the field in a way that conference papers, textbooks, and boring lectures cannot. An implicit part of writing a Distill article involves channeling your &quot;sense of wonder&quot; so that your readers can experience it too.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Takeaway.&lt;/strong&gt; I had a good experience working with Distill and would recommend it to others. I’m happy to answer specific questions about the process over email.&lt;/p&gt;</content><author><name>Sam Greydanus</name></author><summary type="html">I recently published a Distill article about value learning. This post includes a link to the article and some meta-commentary about the Distill format.</summary></entry><entry><title type="html">Neural Reparameterization Improves Structural Optimization</title><link href="http://greydanus.github.io/2019/12/15/neural-reparam/" rel="alternate" type="text/html" title="Neural Reparameterization Improves Structural Optimization" /><published>2019-12-15T03:00:00-08:00</published><updated>2019-12-15T03:00:00-08:00</updated><id>http://greydanus.github.io/2019/12/15/neural-reparam</id><content type="html" xml:base="http://greydanus.github.io/2019/12/15/neural-reparam/">&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:90%&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/neural-reparam/bridge-start.png&quot; width=&quot;95%&quot; id=&quot;bridgeImage&quot; /&gt;
    &lt;button id=&quot;bridgeButton&quot; onclick=&quot;toggleBridge()&quot; class=&quot;playbutton&quot;&gt;Play&lt;/button&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:85%;padding-left:22px&quot;&gt;&lt;b&gt;Figure 1:&lt;/b&gt; Optimizing a bridge structure. In the top frame, optimization happens in the weight space of a CNN. In the next two frames it happens on a finite element grid.&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleBridge() {

		path = document.getElementById(&quot;bridgeImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;bridge-start.png&quot;) 
	    {
	        document.getElementById(&quot;bridgeImage&quot;).src = &quot;/assets/neural-reparam/bridge.gif&quot;;
	        document.getElementById(&quot;bridgeButton&quot;).textContent = &quot;Reset&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;bridgeImage&quot;).src = &quot;/assets/neural-reparam/bridge-start.png&quot;;
	        document.getElementById(&quot;bridgeButton&quot;).textContent = &quot;Play&quot;;
	    }
	}
&lt;/script&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://arxiv.org/abs/1909.04240&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://colab.research.google.com/github/google-research/neural-structural-optimization/blob/master/notebooks/optimization-examples.ipynb&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;colab-span&quot;&gt;Run&lt;/span&gt; in browser&lt;/a&gt;
	&lt;a href=&quot;https://github.com/google-research/neural-structural-optimization&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;a-visual-introduction&quot;&gt;A Visual Introduction&lt;/h2&gt;

&lt;p&gt;In this post we propose using neural networks to reparameterize physics problems. This helps us design better bridges, skyscrapers, and cantilevers while enforcing hard physical constraints. In the figure above, you can see that our approach optimizes more quickly and has a smoother transition from large-scale to small-scale features. In the figure below, you can explore all 116 tasks that we studied.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/selected-tasks.png&quot; style=&quot;width:55%&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto; width:60%&quot;&gt;&lt;b&gt;Figure 2:&lt;/b&gt; Results from the 116 structural optimization tasks. The scores below each structure measure how much worse the design was than the best overall design.&lt;/div&gt;

	&lt;button id=&quot;tasksButton1&quot; onclick=&quot;toggleTasks1()&quot; class=&quot;playbutton&quot; style=&quot;display: block; margin-left: auto; margin-right: auto;&quot;&gt;Show more tasks&lt;/button&gt;
	&lt;div id=&quot;alltasks1&quot; style=&quot;display:none&quot;&gt;
		&lt;img src=&quot;/assets/neural-reparam/tasks/tasks1.png&quot; /&gt;
		&lt;img src=&quot;/assets/neural-reparam/tasks/tasks2.png&quot; /&gt;
		&lt;img src=&quot;/assets/neural-reparam/tasks/tasks3.png&quot; /&gt;
		&lt;button id=&quot;tasksButton2&quot; onclick=&quot;toggleTasks2()&quot; class=&quot;playbutton&quot; style=&quot;display: block; margin-left: auto; margin-right: auto;&quot;&gt;Show even more tasks&lt;/button&gt;
		&lt;div id=&quot;alltasks2&quot; style=&quot;display:none&quot;&gt;
			&lt;img src=&quot;/assets/neural-reparam/tasks/tasks4.png&quot; /&gt;
			&lt;img src=&quot;/assets/neural-reparam/tasks/tasks5.png&quot; /&gt;
			&lt;img src=&quot;/assets/neural-reparam/tasks/tasks6.png&quot; /&gt;
			&lt;img src=&quot;/assets/neural-reparam/tasks/tasks7.png&quot; /&gt;
			&lt;img src=&quot;/assets/neural-reparam/tasks/tasks8.png&quot; /&gt;
			&lt;button id=&quot;tasksButton3&quot; onclick=&quot;toggleTasks3()&quot; class=&quot;playbutton&quot; style=&quot;display: block; margin-left: auto; margin-right: auto;&quot;&gt;Show even more tasks&lt;/button&gt;
			&lt;div id=&quot;alltasks3&quot; style=&quot;display:none&quot;&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks9.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks10.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks11.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks12.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks13.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks14.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks15.png&quot; /&gt;
				&lt;img src=&quot;/assets/neural-reparam/tasks/tasks16.png&quot; /&gt;
			&lt;/div&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Now that I’ve sparked your curiosity, I’m going to use the rest of this post to put our results in the proper context. The proper context is &lt;em&gt;parameterization&lt;/em&gt; and my message is that it matters much more than you might expect.&lt;/p&gt;

&lt;h2 id=&quot;a-philosophical-take-on-parameterization&quot;&gt;A Philosophical Take on Parameterization&lt;/h2&gt;

&lt;p&gt;The word “parameterization” means different things in different fields. Generally speaking, it’s just a math term for the quirks and biases of a specific view of reality. Consider, for example, the parameterizations of a 3D surface. If the surface is rectilinear, then we’d probably want to use Cartesian coordinates. If it’s cylindrical or spherical, we may be better off using polar or spherical coordinates. So we have three parameterizations but each one describes the same underlying reality. After all, a sphere will remain a sphere regardless of how its equation is written.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reparameterization.&lt;/strong&gt; And yet, some parameterizations are better than others &lt;em&gt;for solving particular types of problems&lt;/em&gt;. This is why reparameterization – the process of switching between parameterizations – is so important. It lets us take advantage of the good properties of two different parameterizations at the same time. For example, when we are editing a photograph in Photoshop, we may edit specific objects while working in a pixel parameterization. Then we may switch to a Fourier basis in order to adjust lighting and saturation. Technically speaking, we’ve just taken advantage of reparameterization.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:60%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/photoshop.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 3:&lt;/b&gt; A simple example of reparameterization. We might use the pixel image of Baby Yoda (on the left) to make spatially localized edits. Then we might use its spectral decomposition (on the right) to adjust lighting and saturation.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Physics examples.&lt;/strong&gt; Physicists use reparameterization or “change of basis” tricks all the time. Sometimes it’s a matter of notation and other times it’s a matter of what question they are asking. Here are a few examples:&lt;/p&gt;
&lt;ul style=&quot;list-style-type:disc;&quot;&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fourier_analysis&quot;&gt;Spatial vs Fourier analysis&lt;/a&gt; for studying light and sound&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_map_projections&quot;&gt;Angle vs area preserving projections&lt;/a&gt; for studying different properties of Earth and space&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spherical_harmonics&quot;&gt;Spherical harmonics vs Cartesian coordinates&lt;/a&gt; for describing the position and momentum of an electron&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Topology_optimization&quot;&gt;Grids&lt;/a&gt; vs &lt;a href=&quot;https://arxiv.org/abs/1910.05585&quot;&gt;adaptive meshes&lt;/a&gt; for structural optimization problems&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Canonical_transformation&quot;&gt;Canonical transformations&lt;/a&gt; for transforming between arbitrary coordinate systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are some of the simplest examples, but there are countless others. In this post we’ll focus on an exciting new tool for doing this sort of thing: neural networks.&lt;/p&gt;

&lt;h2 id=&quot;reparameterization-and-neural-networks&quot;&gt;Reparameterization and Neural Networks&lt;/h2&gt;

&lt;p&gt;Neural networks have all sorts of nice properties. They work well with high-dimensional data, they have great spatial priors, and they can change their representations during learning. But there is still a lot that we don’t understand about them. In fact, two recent studies suggest that we’ve underestimated the importance of their architectural priors.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://dmitryulyanov.github.io/deep_image_prior&quot;&gt;The Deep Image Prior&lt;/a&gt;.&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt; The first study tells us that even untrained networks have fantastic image priors. The authors hammer this point home by showing that it’s possible to perform state-of-the-art denoising, super-resolution, and inpainting on a single image with an untrained network.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display:block; margin-left: auto; margin-right: auto; width:70%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/deep-prior.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 4:&lt;/b&gt; Visualization of the Deep Image Prior. Optimizing a single image using the weight space of an untrained CNN gives state of the art super-resolution results.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://distill.pub/2018/differentiable-parameterizations/&quot;&gt;Differentiable Image Parameterizations&lt;/a&gt;&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/strong&gt; The second study &lt;em&gt;highlights the relationship between image parameterizations and better optimization results&lt;/em&gt;. The authors argue that well-chosen parameterizations can&lt;/p&gt;
&lt;ul style=&quot;list-style-type:disc;&quot;&gt;
&lt;li&gt;Precondition the optimization landscape&lt;/li&gt;
&lt;li&gt;Enforce constraints (such as conservation of volume)&lt;/li&gt;
&lt;li&gt;Bias optimization towards certain outcomes&lt;/li&gt;
&lt;li&gt;Implicitly optimize other objects (eg a 3D surface projected to 2D)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display:block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/diff-params.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;&lt;b&gt;Figure 5:&lt;/b&gt; Specific examples of differentiable image parameterizations applied to neural network visualizations and art.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;These two papers are interesting because they don’t focus on the process of training neural networks. Rather, they focus on how this process is shaped by good priors.&lt;/p&gt;

&lt;h2 id=&quot;good-priors-for-physics&quot;&gt;Good Priors for Physics&lt;/h2&gt;

&lt;p&gt;With the rise of powerful neural network models, many scientists have grown interested in applying them to physics research. But there are some challenges. Data that is generated by physical processes is subject to exact physical constraints such as conservation of energy, mass, or charge and it can be challenging to enforce these constraints on neural network models. Another challenge is that neural networks require large datasets which are not always practical in physics. So the core challenge is to leverage deep learning…&lt;/p&gt;
&lt;ul style=&quot;list-style-type:disc;&quot;&gt;
&lt;li&gt;without sacrificing exact physics (many people train models to approximate physics, but often that isn’t enough)&lt;/li&gt;
&lt;li&gt;without excessively large training datasets (often we only care about a few solutions)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Satisfying these requirements with supervised learning methods is hard. But what if we used neural networks for &lt;em&gt;reparameterization&lt;/em&gt; instead? When we looked into this idea, we found lots of evidence that the deep image prior extends beyond natural images. Some examples include style transfer in fonts&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, uncertainty estimation in fluid dynamics&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, and data upsampling in medical imaging&lt;sup id=&quot;fnref:fn5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. Indeed, whenever data contains translation invariance, spatial correlation, or multi-scale features, the deep image prior is a useful tool. So we decided to push the limits of this idea in the context of physics. We chose structural optimization as a case study because it’s a domain where good spatial priors are essential.&lt;/p&gt;

&lt;h2 id=&quot;the-joys-of-structural-optimization&quot;&gt;The Joys of Structural Optimization&lt;/h2&gt;

&lt;p&gt;Structural optimization is a computational tool which, in an ironic turn of events, often comes up with more organic-looking structures than human engineers do. These structures are beautiful, lightweight, and extremely strong.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/autodesk.png&quot; style=&quot;width:50%&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:center; width:100%&quot;&gt;&lt;b&gt;Figure 6:&lt;/b&gt; Autodesk uses structural optimization to augment the design process.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;How it works.&lt;/strong&gt; In structural optimization, you are given a fixed amount of material, a set of anchor points, and a set of force points. Your goal is to design load-bearing structures which balance out the force points as much as possible. You are also given a physics simulator which computes how much your structure is displaced by a given load. By differentiating through this physics simulator, you can take the gradient of the structure’s performance (called compliance) with respect to each of its components. Then you can follow this gradient to improve your design.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Enforcing constraints.&lt;/strong&gt; The most common approach to topology optimization is the “modified SIMP” method&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. In this approach, we begin with a discretized domain of finite elements on a rectangular grid. We associate each grid element with an unconstrained logit and then map this logit to a mass density between 0 and 1. The mapping has two steps. The first step is to convolve the grid of logits with a cone filter in order to enforce local smoothness. The second step is to enforce volume constraints: 1) the volume of every grid cell must stay between 0 and 1 and 2) the total volume must not change.&lt;/p&gt;

&lt;p&gt;We satisfied the first constraint by applying an element-wise sigmoid function to the logits. Then we satisfied the second by using a root finder to choose the sigmoid saturation constant \(b\). We can write these two steps as a single operation&lt;/p&gt;

\[\begin{align}
    x_{ij} &amp;amp;= \frac{1}{1 + e^{- \hat x_{ij} - b}},\\
    &amp;amp;\quad\text{with $b$ such that} \quad
    V(x) = V_0.
\end{align}\]

&lt;p&gt;&lt;strong&gt;Simulating the physics.&lt;/strong&gt; Letting  \(K(\tilde x)\) be the global stiffness matrix, \(U(K, F)\) be the displacement vector, \(F\) be the vector of applied forces, and \(V (\tilde x)\) be the total volume, we simulated the physics of displacement and wrote our objective as&lt;/p&gt;

\[\begin{align}
    \min_x: c(x) &amp;amp;= U^T K U
    \quad\text{such that}\\
    &amp;amp;\quad
    K U = F, \quad
    V(x) = V_0, \\
    &amp;amp;\quad \text{and }
    0 \leq x_{ij} \leq 1
\end{align}\]

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:70%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/baseline-schema.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display: block; margin-left: auto; margin-right: auto; width:90%&quot;&gt;&lt;b&gt;Figure 7:&lt;/b&gt;  Visualization of structural optimization. Here we are using it to design a bridge.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Automatic differentiation.&lt;/strong&gt; The coolest thing about our implementation is that it is fully differentiable. In fact, we implemented everything in Autograd and then used automatic differentiation to solve for updates to the parameters. This made our code much simpler than previous approaches (which had implemented reverse-mode differentiation by hand).&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:60%; min-width:250px&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/implicit-diff.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 8:&lt;/b&gt; Instead of differentiating directly through the root finder, we can use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Implicit_function_theorem&quot;&gt;implicit function theorem&lt;/a&gt; to &lt;a href=&quot;https://link.springer.com/article/10.1023/A:1016051717120&quot;&gt;differentiate through the optimal point&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The careful reader might be wondering how we differentiated through our root finder. At first we tried to naively backpropagate through the full search process. Bad idea. A better solution is to &lt;a href=&quot;https://link.springer.com/article/10.1023/A:1016051717120&quot;&gt;differentiate straight through the optimal point&lt;/a&gt; using implicit differentiation&lt;sup id=&quot;fnref:fn7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; (Figure 7).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reparameterizing the problem.&lt;/strong&gt; Next, we built a CNN image generator in Keras and used it to reparameterize the grid of logits. The entire process, from the neural network forward pass to the constraint functions to the physics simulation, reduced to a single forward pass:&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:70%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/our-schema.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 9:&lt;/b&gt; Reparameterizing structural optimization. We implement the forward pass as a TensorFlow graph and compute gradients via automatic differentiation.&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;bridges-towers-and-trees&quot;&gt;Bridges, Towers, and Trees&lt;/h2&gt;

&lt;p&gt;In order to compare our method to baselines, we developed a suite of 116 structural optimization tasks. In designing these tasks, our goal was to create a distribution of diverse, well-studied problems with real-world significance. We started with a selection of problems from (Valdez et al. 2017)&lt;sup id=&quot;fnref:fn8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; and (Sokol 2011).&lt;sup id=&quot;fnref:fn9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; Most of these problems were simple beams with only a few forces, so we hand-designed additional tasks reflecting real-world designs such as bridges, towers, and trees.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:70%; min-width:280px&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/quant-results.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 10:&lt;/b&gt; Neural reparameterization improves structural optimization, especially for large problems.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Why do large problems benefit more?&lt;/strong&gt; One of the first things we noticed was that large problems benefit more from our approach. Why is this? It turns out that finite grids suffer from a “mesh-dependency problem,” with solutions varying as grid resolution changes.&lt;sup id=&quot;fnref:fn10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn10&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt; When grid resolution is high, small-scale “spiderweb” patterns interfere with large-scale structures. We suspect that working in the weight space of a CNN allows us to optimize structures on several spatial scales at once, effectively solving the mesh-dependency problem. To investigate this idea, we plotted structures from all 116 design tasks and then chose five examples to highlight important qualitative trends (Figure 2).&lt;/p&gt;

&lt;p&gt;One specific example is that the cantilever beam in Figure 2 had a total of eight supports under our method, whereas the next-best method (MMA&lt;sup id=&quot;fnref:fn11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn11&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;) used eighteen. Most of the qualitative results are at the beginning of this post, so refer to that section for more details.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:90%&quot;&gt;
    &lt;button id=&quot;buildingButton&quot; onclick=&quot;toggleBuilding()&quot; class=&quot;playbutton&quot;&gt;Play&lt;/button&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/neural-reparam/building.png&quot; width=&quot;95%&quot; id=&quot;buildingImage&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:90%;padding-left:22px&quot;&gt;&lt;b&gt;Figure 11:&lt;/b&gt; Optimizing a multistory building. In the first frame, optimization happens in the weight space of a CNN. In the next two frames it happens on a finite element grid. Structures 2 and 3 are 7% and 54% worse.&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleBuilding() {

		path = document.getElementById(&quot;buildingImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;building.png&quot;) 
	    {
	        document.getElementById(&quot;buildingImage&quot;).src = &quot;/assets/neural-reparam/building.gif&quot;;
	        document.getElementById(&quot;buildingButton&quot;).textContent = &quot;Reset&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;buildingImage&quot;).src = &quot;/assets/neural-reparam/building.png&quot;;
	        document.getElementById(&quot;buildingButton&quot;).textContent = &quot;Play&quot;;
	    }
	}
&lt;/script&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing thoughts&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Structural optimization.&lt;/strong&gt; This was a fun project because many of the results were beautiful and surprising. In fact, it convinced me that structural optimization is an undervalued tool for augmenting human creativity. With advances in 3D printing and fabrication, I hope it becomes more common in fields such as engineering and architecture.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameterization.&lt;/strong&gt; A more general theme of this project is that &lt;em&gt;parameterization matters much more than you might expect.&lt;/em&gt; We see this again and again. The most fundamental advances in deep learning – convolutional filters, forget gates, residual connections, and self-attention – should be thought of as advances in parameterization.&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:70%&quot;&gt;
	&lt;img src=&quot;/assets/neural-reparam/elegans-connectome.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; width:100%&quot;&gt;&lt;b&gt;Figure 12:&lt;/b&gt; Parameterization is important in biological systems as well. What sorts of priors might the &lt;a href=&quot;https://wormwiring.org/&quot;&gt;C. elegans connectome&lt;/a&gt; encode?&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This leads me to ask what other sorts of priors one could encode via parameterization. I’m particularly excited about a series of recent works that show how to encode complex, dataset-specific priors via network connectivity: “&lt;a href=&quot;https://weightagnostic.github.io/&quot;&gt;Weight Agnostic Neural Networks&lt;/a&gt;&lt;sup id=&quot;fnref:fn12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn12&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;”, “&lt;a href=&quot;https://arxiv.org/abs/1803.03635&quot;&gt;Lottery Tickets&lt;/a&gt;&lt;sup id=&quot;fnref:fn13&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn13&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;,” and “&lt;a href=&quot;http://papers.nips.cc/paper/6417-interaction-networks-for-learning-about-objects-relations-and-physics&quot;&gt;Interaction Networks&lt;/a&gt;&lt;sup id=&quot;fnref:fn14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn14&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;”. There’s evidence that nature hard codes priors in a similar way. For example, a baby antelope can walk just a few minutes after birth, suggesting that this skill is hard-wired into the connectivity structure of its brain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Takeaway.&lt;/strong&gt; Regardless of whether you care about physics, deep learning, or biological analogies, I hope this post helped you appreciate the pivotal role of parameterization.&lt;/p&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related Work&lt;/h2&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleTasks1() {

		var x = document.getElementById(&quot;alltasks1&quot;);
		if (x.style.display === &quot;none&quot;) {
			x.style.display = &quot;block&quot;;
			document.getElementById(&quot;tasksButton1&quot;).textContent = &quot;Hide tasks&quot;;
		} else {
			x.style.display = &quot;none&quot;;
			document.getElementById(&quot;tasksButton1&quot;).textContent = &quot;Show more tasks&quot;;
		}
	}
&lt;/script&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleTasks2() {

		var x = document.getElementById(&quot;alltasks2&quot;);
		if (x.style.display === &quot;none&quot;) {
			x.style.display = &quot;block&quot;;
			document.getElementById(&quot;tasksButton2&quot;).textContent = &quot;Hide tasks&quot;;
			document.getElementById(&quot;tasksButton1&quot;).textContent = &quot;Hide all tasks&quot;;
		} else {
			x.style.display = &quot;none&quot;;
			document.getElementById(&quot;tasksButton2&quot;).textContent = &quot;Show even more tasks&quot;;
			document.getElementById(&quot;tasksButton1&quot;).textContent = &quot;Hide tasks&quot;;
		}
	}
&lt;/script&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleTasks3() {

		var x = document.getElementById(&quot;alltasks3&quot;);
		if (x.style.display === &quot;none&quot;) {
			x.style.display = &quot;block&quot;;
			document.getElementById(&quot;tasksButton3&quot;).textContent = &quot;Hide tasks&quot;;
		} else {
			x.style.display = &quot;none&quot;;
			document.getElementById(&quot;tasksButton3&quot;).textContent = &quot;Show even more tasks&quot;;
		}
	}
&lt;/script&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Ulyanov, Dmitry, Andrea Vedaldi, and Victor Lempitsky. &lt;a href=&quot;https://dmitryulyanov.github.io/deep_image_prior&quot;&gt;Deep Image Prior&lt;/a&gt;. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Mordvintsev, Alexander, et al. &lt;a href=&quot;https://distill.pub/2018/differentiable-parameterizations/&quot;&gt;Differentiable Image Parameterizations&lt;/a&gt;. Distill 3.7 (2018): e12. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Azadi, S., Fisher, M., Kim, V. G., Wang, Z., Shechtman, E., and Darrell, T. &lt;a href=&quot;https://arxiv.org/abs/1712.00516&quot;&gt;Multi-content GAN for few-shot font style transfer&lt;/a&gt;. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Zhu, Y., Zabaras, N., Koutsourelakis, P.-S., and Perdikaris, P. &lt;a href=&quot;https://arxiv.org/abs/1901.06314&quot;&gt;Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data&lt;/a&gt;. Journal of Computational Physics, 394:56–81, 2019. &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Dittmer, S., Kluth, T., Maass, P., and Baguer, D. O. &lt;a href=&quot;https://arxiv.org/abs/1812.03889&quot;&gt;Regularization by architecture: A deep prior approach for inverse problems&lt;/a&gt;. Preprint, 2018. &lt;a href=&quot;#fnref:fn5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Andreassen, E., Clausen, A., Schevenels, M., Lazarov, B. S., and Sigmund, O. &lt;a href=&quot;https://link.springer.com/article/10.1007/s00158-010-0594-7&quot;&gt;Efficient topology optimization in MATLAB using 88 lines of code&lt;/a&gt;. Structural and Multidisciplinary Optimization, 43(1):1–16, 2011. &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Griewank, A. and Faure, C. &lt;a href=&quot;https://link.springer.com/article/10.1023/A:1016051717120&quot;&gt;Reduced functions, gradients and hessians from fixed-point iterations for state equations&lt;/a&gt;. Numerical Algorithms, 30(2):113–139, 2002. &lt;a href=&quot;#fnref:fn7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Valdez, S. I., Botello, S., Ochoa, M. A., Marroquín, J. L., and Cardoso, V. &lt;a href=&quot;https://link.springer.com/article/10.1007/s11831-016-9190-3&quot;&gt;Topology optimization benchmarks in 2D: Results for minimum compliance and minimum volume in planar stress problems&lt;/a&gt;. Arch. Comput. Methods Eng., 24(4):803–839, November 2017. &lt;a href=&quot;#fnref:fn8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Sokol, T. &lt;a href=&quot;https://link.springer.com/article/10.1007/s00158-010-0557-z&quot;&gt;A 99 line code for discretized Michell truss optimization written in Mathematica&lt;/a&gt;. Structural and Multidisciplinary Optimization, 43(2):181–190, 2011. &lt;a href=&quot;#fnref:fn9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Sigmund, O. and Petersson, J. &lt;a href=&quot;https://link.springer.com/article/10.1007/BF01214002&quot;&gt;Numerical instabilities in topology optimization: A survey on procedures dealing with checkerboards, mesh-dependencies and local minima&lt;/a&gt;. Structural optimization, 16:68–75, 1998. &lt;a href=&quot;#fnref:fn10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Svanberg, K. &lt;a href=&quot;https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.1620240207&quot;&gt;The method of moving asymptotes-a new method for structural optimization&lt;/a&gt;. International Journal for Numerical Methods in Engineering, 24(2):359–373, 1987. &lt;a href=&quot;#fnref:fn11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Gaier, Adam, and David Ha. &lt;a href=&quot;https://weightagnostic.github.io/&quot;&gt;Weight Agnostic Neural Networks&lt;/a&gt;. Neural Information Processing Systems (2019). &lt;a href=&quot;#fnref:fn12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn13&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Frankle, Jonathan, and Michael Carbin. “&lt;a href=&quot;https://arxiv.org/abs/1803.03635&quot;&gt;The lottery ticket hypothesis: Finding sparse, trainable neural networks&lt;/a&gt;.” ICLR 2019. &lt;a href=&quot;#fnref:fn13&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Battaglia, Peter, et al. “&lt;a href=&quot;http://papers.nips.cc/paper/6417-interaction-networks-for-learning-about-objects-relations-and-physics&quot;&gt;Interaction networks for learning about objects, relations and physics&lt;/a&gt;.” Advances in neural information processing systems. 2016. &lt;a href=&quot;#fnref:fn14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">We use neural networks to reparameterize structural optimization, building better bridges, skyscrapers, and cantilevers while enforcing hard physical constraints.</summary></entry><entry><title type="html">Hamiltonian Neural Networks</title><link href="http://greydanus.github.io/2019/05/15/hamiltonian-nns/" rel="alternate" type="text/html" title="Hamiltonian Neural Networks" /><published>2019-05-15T04:00:00-07:00</published><updated>2019-05-15T04:00:00-07:00</updated><id>http://greydanus.github.io/2019/05/15/hamiltonian-nns</id><content type="html" xml:base="http://greydanus.github.io/2019/05/15/hamiltonian-nns/">&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/hamiltonian-nns/overall-idea.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left; display:block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;&lt;b&gt;Figure 1:&lt;/b&gt; Instead of crafting a Hamiltonian by hand, we parameterize it with a neural network and then learn it directly from data. The variables &lt;b&gt;q&lt;/b&gt; and &lt;b&gt;p&lt;/b&gt; correspond to position and momentum coordinates. As there is no friction, the baseline&apos;s inward spiral is due to model errors. By comparison, the Hamiltonian Neural Network learns to exactly conserve an energy-like quantity.&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;display: block; margin-left: auto; margin-right:auto; width:100%; text-align:center;&quot;&gt;
	&lt;a href=&quot;https://arxiv.org/abs/1906.01563v1&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Read the paper&lt;/a&gt;
	&lt;a href=&quot;https://github.com/greydanus/hamiltonian-nn&quot; id=&quot;linkbutton&quot; target=&quot;_blank&quot;&gt;Get the code&lt;/a&gt;
&lt;/div&gt;

&lt;h2 id=&quot;the-wisdom-of-learning-invariant-quantities&quot;&gt;The Wisdom of Learning Invariant Quantities&lt;/h2&gt;

&lt;p&gt;It’s remarkable that we ever have an “ordinary day.” If we were to sit down and catalogue all of our experiences – the flavors of our sandwich, the quality of the sunlight, or the texture of our cat’s fur – no day would look like any other. The stew of sensory information would be simply overwhelming.&lt;/p&gt;

&lt;p&gt;The only way to make sense of our complicated day-to-day experiences is to focus on the things that don’t change. The invariants. The conserved quantities. Over time, we pick up on these things and use them as anchors or reference points for our sense of reality. Our sandwich tastes different…maybe the bread is stale. The cat doesn’t feel as soft as usual…maybe it needs a bath. It’s beneficial to understand what does not vary in order to make sense of what does.&lt;/p&gt;

&lt;p&gt;This is a common theme in physics. Physicists start with a small set of “invariant quantities” such as total energy, total momentum, and (sometimes) total mass. Then they use these invariances to predict the dynamics of a system. “If energy is conserved,” they might say, “when I throw a ball upwards, it will return to my hand with the same speed as when it left.”&lt;/p&gt;

&lt;p&gt;But these common-sense rules can be difficult to learn straight from data. On tasks such as &lt;a href=&quot;https://research.google.com/pubs/archive/42455.pdf&quot;&gt;video classification&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;reinforcement learning&lt;/a&gt;, or &lt;a href=&quot;https://openai.com/blog/learning-dexterity/&quot;&gt;robotic dexterity&lt;/a&gt;, machine learning researchers train neural networks on millions of examples. And yet, even after seeing all of these examples, neural networks don’t learn exact conservation laws. The best they can do is gradually improve their approximations.&lt;/p&gt;

&lt;p&gt;As an example, consider the ideal mass-spring system shown in Figure 1. Here the total energy of the system is being conserved. More specifically, a quantity proportional to \(q^2+p^2\) is being conserved, where \(q\) is the position and \(p\) is the momentum of the mass. The baseline neural network learns an approximation of this conservation law, and yet the approximation is imperfect enough that a forward simulation of the system drifts slowly to a different energy state. Can we design a model that doesn’t drift?&lt;/p&gt;

&lt;h2 id=&quot;hamiltonian-neural-networks&quot;&gt;Hamiltonian Neural Networks&lt;/h2&gt;

&lt;p&gt;It turns out we can. Drawing inspiration from Hamiltonian mechanics, a branch of physics concerned with conservation laws and invariances, we define Hamiltonian Neural Networks, or HNNs. By construction, these models learn conservation laws from data. We’ll show that they have some major advantages over regular neural networks on a variety of physics problems.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%;&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/hamiltonian-nns/orbits-compare.png&quot; width=&quot;70%&quot; id=&quot;orbitImage&quot; /&gt;&lt;br /&gt;
    &lt;button id=&quot;orbitButton&quot; onclick=&quot;toggleOrbits()&quot; class=&quot;playbutton&quot;&gt;Play&lt;/button&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 3:&lt;/b&gt; Two bodies interact via a gravitational force. The dynamics of the baseline model do not conserve total energy and quickly diverge from ground truth. Meanwhile, the HNN learns to conserve a quantity that is close to total energy. This makes its predicted trajectories more stable.&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleOrbits() {

		path = document.getElementById(&quot;orbitImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;orbits-compare.png&quot;) 
	    {
	        document.getElementById(&quot;orbitImage&quot;).src = &quot;/assets/hamiltonian-nns/orbits-compare.gif&quot;;
	        document.getElementById(&quot;orbitButton&quot;).textContent = &quot;Reset&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;orbitImage&quot;).src = &quot;/assets/hamiltonian-nns/orbits-compare.png&quot;;
	        document.getElementById(&quot;orbitButton&quot;).textContent = &quot;Play&quot;;
	    }
	}
&lt;/script&gt;

&lt;p&gt;We begin with an equation called the Hamiltonian, which relates the state of a system to some conserved quantity (usually energy) and lets us simulate how the system changes with time. Physicists generally use domain-specific knowledge to find this equation, but here we try a different approach: &lt;i&gt;Instead of crafting Hamiltonians by hand, we parameterize them with neural networks and then learn them directly from data.&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Related work.&lt;/strong&gt; A variety of previous works have sought to endow neural networks with intuitive physics priors. Some of these works were domain-specific: they solved problems in molecular dynamics&lt;sup id=&quot;fnref:fn1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, quantum mechanics&lt;sup id=&quot;fnref:fn2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, or robotics&lt;sup id=&quot;fnref:fn3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. Others, such as Interaction Networks&lt;sup id=&quot;fnref:fn4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, were meant to be fully general. A common pattern among these works, is that none of them showed how to learn invariant quantities. Schmidt and Lipson&lt;sup id=&quot;fnref:fn7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn7&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; did tackle this challenge, but whereas they used a genetic algorithm to search over a space of mathematical expressions, in this work we train a neural network with gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;a-quick-tour-of-hamiltonian-mechanics&quot;&gt;A Quick Tour of Hamiltonian Mechanics&lt;/h2&gt;

&lt;p&gt;In order to situate our model in the proper context, we will use this section to review the basics of Hamiltonian mechanics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;History.&lt;/strong&gt; William Hamilton introduced Hamiltonian mechanics in the 19th century as a mathematical reformulation of classical mechanics. Its original purpose was to express classical mechanics in a more unified and general manner. Over time, though, scientists have applied it to nearly every area of physics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theory.&lt;/strong&gt; In Hamiltonian mechanics, we begin with a set of coordinates \((\mathbf{q},\mathbf{p})\). Usually, \(\mathbf{q}=(q_1,…,q_N)\) represents the positions of a set of objects whereas \(\mathbf{p}=(p_1,…, p_N)\) denotes their momentum. Note how this gives us \(N\) coordinate pairs \((q_1,p_1)…(q_N,p_N)\). Taken together, they offer a complete description of the system. Next, we define a scalar function, \(\mathcal{H}(\mathbf{q},\mathbf{p})\) called the Hamiltonian so that&lt;/p&gt;

\[\begin{equation}
\frac{d\mathbf{q}}{dt} ~=~ \frac{\partial \mathcal{H}}{\partial \mathbf{p}}, \quad \frac{d\mathbf{p}}{dt} ~= - \frac{\partial \mathcal{H}}{\partial \mathbf{q}}
\label{eq:eqn1}
\tag{1}
\end{equation}\]

&lt;p&gt;This equation tells us that moving coordinates in the direction \(\mathbf{S_{\mathcal{H}}} = \big(\frac{\partial \mathcal{H}}{\partial \mathbf{p}}, -\frac{\partial \mathcal{H}}{\partial \mathbf{q}} \big)\) gives us the time evolution of the coordinates. We can think of \(\mathbf{S}\) as a vector field over the inputs of \(\mathcal{H}\). In fact, it is a special kind of vector called a “symplectic gradient’’. Whereas moving in the direction of the gradient of \(\mathcal{H}\) changes the output as quickly as possible, moving in the direction of the symplectic gradient keeps the output exactly constant. Hamilton used this mathematical framework to relate the position and momentum vectors \((\mathbf{q},\mathbf{p})\) of a system to its total energy \( E_{tot}=\mathcal{H}(\mathbf{q},\mathbf{p}) \). Then, he obtained the time evolution of the system by integrating this field according to&lt;/p&gt;

\[\begin{equation}
(\mathbf{q}_1,\mathbf{p}_1) ~=~ (\mathbf{q}_0,\mathbf{p}_0) ~+~ \int_{t_0}^{t_1} \mathbf{S}(\mathbf{q},\mathbf{p}) ~~ dt \qquad  (2)
\end{equation}\]

&lt;p&gt;&lt;strong&gt;Uses.&lt;/strong&gt; This is a powerful approach because it works for almost any system where the total energy is conserved. Like Newtonian mechanics, it can predict the motion of a mass-spring system or a single pendulum. But its true strengths become apparent when we tackle large and/or chaotic systems like quantum many-body problems, fluid simulations, and celestial orbitals. Hamiltonian mechanics gives us a common language to describe these systems as well as set of first-order differential equations for their dynamics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Overview.&lt;/strong&gt; To summarize, Hamiltonian mechanics is a tool for modeling large and chaotic physical systems. It’s useful because it generalizes to almost any field of physics and can handle systems that are large and chaotic. The general recipe for applying Hamiltonian mechanics to a problem is:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Choose a set of coordinates that describe the state of a system&lt;sup id=&quot;fnref:fn5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn5&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. A common choice is position and momentum \((\mathbf{q},\mathbf{p})\).&lt;/li&gt;
  &lt;li&gt;Write the total energy of the system as a function of those coordinates&lt;sup id=&quot;fnref:fn6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn6&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. This equation is called the Hamiltonian.&lt;/li&gt;
  &lt;li&gt;Compute the partial derivatives of the Hamiltonian w.r.t. the coordinates. Then use Hamilton’s equations (Equation 1) to find the time derivatives of the system.&lt;/li&gt;
  &lt;li&gt;Integrate the time derivatives to predict the state of the system at some time in the future (Equation 2).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;learning-hamiltonians-from-data&quot;&gt;Learning Hamiltonians from Data&lt;/h2&gt;

&lt;p&gt;Let’s use neural networks to learn Hamiltonians from data. In particular, let’s consider a dataset that consists of coordinate trajectories through time: either directly (the actual \((\mathbf{q},\mathbf{p})\) coordinates) or indirectly (pixel images that contain \((\mathbf{q},\mathbf{p})\) information). Also, let’s suppose that we’ve parameterized a Hamiltonian with neural network parameters \(\theta\). The first thing to notice is that we can rewrite Equation \eqref{eq:eqn1} so that both terms are on the left side:&lt;/p&gt;

\[\begin{equation}
 \frac{d\mathbf{q}}{dt} - \frac{\partial \mathcal{H_{\theta}}}{\partial \mathbf{p}} = 0, \quad \frac{d\mathbf{p}}{dt} + \frac{\partial \mathcal{H_{\theta}}}{\partial \mathbf{q}}=0 \qquad (3)
\end{equation}\]

&lt;p&gt;Since we know that the function \(\mathcal{H}\) is a Hamiltonian when both of these terms go to zero, we can rewrite it as a solution to the following minimization objective:&lt;/p&gt;

\[\begin{equation}
 \operatorname*{argmin}_\theta \bigg \Vert \frac{d\mathbf{q}}{dt} - \frac{\partial \mathcal{H_{\theta}}}{\partial \mathbf{p}} \bigg \Vert^2 ~+~ \bigg \Vert \frac{d\mathbf{p}}{dt} + \frac{\partial \mathcal{H_{\theta}}}{\partial \mathbf{q}} \bigg \Vert^2
\end{equation} \qquad (4)\]

&lt;p&gt;Now this expression is beginning to look like the \(\mathcal{L_2}\) loss function used in supervised learning. The \(\mathcal{L_2}\) loss term usually takes the form \(\big \Vert y - f_{\theta}(x) \big \Vert^2 \) where \(x\) is the input and \(y\) is the target. The key difference is that here we are minimizing something of the form \( \big \Vert y - \frac{\partial f_{\theta}(x)}{\partial x} \big \Vert^2 \). In other words, we are optimizing the gradient of a neural network.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/hamiltonian-nns/overall-schema.png&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 4:&lt;/b&gt; Schema of the Baseline and HNN models. The Baseline NN in the figure above represents the supervised learning approach to modeling the time derivatives of (&lt;b&gt;q&lt;/b&gt;, &lt;b&gt;p&lt;/b&gt;). In both cases, the inputs are the coordinates of the system and the targets are their time derivatives.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;There are not many previous works that optimize the gradients of a neural network. Work by Schmidt and Lipson&lt;sup id=&quot;fnref:fn7:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn7&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; uses a loss function of this form, but they do not use it to optimize a neural network. Wang et al.&lt;sup id=&quot;fnref:fn8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; optimize the gradients of a neural network, but not for the purpose of learning Hamiltonians. But not only is this technique possible; we also found that it works reasonably well.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Results on simple tasks.&lt;/strong&gt; We trained an HNN and a baseline model on three simple physics tasks. You can explore the setup and results for each of these tasks in Figure 5. Generally speaking, the HNN trained about as easily as the baseline model and produced better results. In order to predict dynamics, we integrated our models using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy.integrate.solve_ivp&lt;/code&gt; and set the error tolerance to \(10^{-9}\)&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%;text-align:center;&quot;&gt;
	&lt;img alt=&quot;&quot; src=&quot;/assets/hamiltonian-nns/blog-summary-spring.png&quot; width=&quot;100%&quot; id=&quot;simpleImage&quot; /&gt;&lt;br /&gt;
	&lt;button id=&quot;simpleButton&quot; onclick=&quot;toggleSimple()&quot; class=&quot;playbutton&quot;&gt;Next task&lt;/button&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 5:&lt;/b&gt;
		&lt;span id=&quot;simpleImageCap&quot;&gt;In Task 1, we trained the HNN on data from a simulated mass-spring system. The dynamics of this system were perfectly linear, making this the simplest system we considered. Notice how the HNN learns to conserve a quantity very similar to the total energy of the system.&lt;/span&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleSimple() {

		path = document.getElementById(&quot;simpleImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;blog-summary-spring.png&quot;) 
	    {
	        document.getElementById(&quot;simpleImage&quot;).src = &quot;/assets/hamiltonian-nns/blog-summary-pend.png&quot;;
	        document.getElementById(&quot;simpleButton&quot;).textContent = &quot;Next task&quot;;
	        document.getElementById(&quot;simpleImageCap&quot;).textContent = &quot;In Task 2, we trained the HNN on data from a simulated pendulum. The dynamics of this system were nonlinear, making the task slightly more difficult than Task 1. Once again, the HNN outperformed the baseline model. In this case, the baseline diverges to a higher energy rather than a lower energy level (as in Task 1).&quot;;
	    }
	    else if (path.split(&apos;/&apos;).pop() == &quot;blog-summary-pend.png&quot;) 
	    {
	    	document.getElementById(&quot;simpleImage&quot;).src = &quot;/assets/hamiltonian-nns/blog-summary-real.png&quot;;
	    	document.getElementById(&quot;simpleButton&quot;).textContent = &quot;Reset&quot;;
	    	document.getElementById(&quot;simpleImageCap&quot;).textContent = &quot;In Task 3, we trained the HNN on data from a real pendulum. The dynamics of this system were noisy and nonlinear, making the task even more difficult. The HNN outperformed the baseline model, but it&apos;s interesting to note that the true energy of the system was not perfectly conserved due to friction, and the HNN was not able to account for this effect.&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;simpleImage&quot;).src = &quot;/assets/hamiltonian-nns/blog-summary-spring.png&quot;;
	        document.getElementById(&quot;simpleButton&quot;).textContent = &quot;Next task&quot;;
	        document.getElementById(&quot;simpleImageCap&quot;).textContent = &quot;In Task 1, we trained the HNN on data from a simulated mass-spring system. The dynamics of this system were perfectly linear, making this the simplest system we considered. Notice how the HNN learns to conserve a quantity very similar to the total energy of the system.&quot;;
	    }
	}
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;What is the HNN conserving?&lt;/strong&gt; It’s worth noting that the quantity conserved by the HNN is not equivalent to the total energy; rather, it’s something very close to the total energy. The last two plots in Figure 5 provide a useful comparison between the HNN-conserved quantity and the total energy. Looking closely at the spacing of the \(y\) axes, you can see that the HNN-conserved quantity has the same scale as total energy, but differs by a constant factor. Since energy is a relative quantity, this is perfectly acceptable&lt;sup id=&quot;fnref:fn9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:fn9&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h2 id=&quot;modeling-larger-systems&quot;&gt;Modeling Larger Systems&lt;/h2&gt;

&lt;p&gt;Having established baselines on a few simple tasks, our next step was to tackle a larger system involving more than one pair of \((\mathbf{q},\mathbf{p})\) coordinates. One well-studied problem that fits this description is the \(N\)-body problem, which requires \(2N\) pairs, where \(N\) is the number of bodies.&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/hamiltonian-nns/orbit-results.png&quot; style=&quot;width:49%;&quot; /&gt;
	&lt;img src=&quot;/assets/hamiltonian-nns/3body-results.png&quot; style=&quot;width:49%; padding-left:1%&quot; /&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 6: (Left)&lt;/b&gt; Two bodies interact via a gravitational force. The dynamics of the baseline model do not conserve total energy and quickly diverge from ground truth. The HNN, meanwhile, approximately conserves total energy and accrues a small amount of error after one full orbit. &lt;b&gt;(Right)&lt;/b&gt; Three bodies interact via a gravitational force. This system is chaotic and has a large dynamic range. While neither of our models achieves good performance on this dataset, the HNN substantially outperforms the baseline and shows promising generalization.&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Figure 6 shows qualitative results for systems with two and three bodies. We suspect that neither model converged to a good solution on the three body task because of the large dynamic range of the dataset; we hope to fix this in future work.&lt;/p&gt;

&lt;h2 id=&quot;learning-a-hamiltonian-from-pixels&quot;&gt;Learning a Hamiltonian from Pixels&lt;/h2&gt;

&lt;p&gt;One of the key strengths of neural networks is that they can learn abstract representations directly from high-dimensional data such as pixels or words. Having trained HNN models on position and momentum coordinates, we were eager to see whether we could train them on arbitrary coordinates like the latent vectors of an autoencoder.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Pixel Pendulum.&lt;/strong&gt; First, we constructed a dataset of pixel observations of a pendulum by stepping through the OpenAI Gym &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pendulum-v0&lt;/code&gt; environment. Then we combined an autoencoder with an HNN to learn the dynamics of the system. The autoencoder would consume two adjacent frames (for velocity information) and then pass its latent codes to the HNN, which used them just as it would a set of \((\mathbf{q},\mathbf{p})\) coordinates. We trained the entire model end-to-end and found that it outperformed the baseline by a significant margin. To our knowledge this is the first instance of a Hamiltonian learned directly from pixel data!&lt;/p&gt;

&lt;div class=&quot;imgcap&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%;text-align: center;&quot;&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/hamiltonian-nns/pend-compare.png&quot; width=&quot;60%&quot; id=&quot;pendImage&quot; /&gt;&lt;br /&gt;
    &lt;button id=&quot;pendButton&quot; onclick=&quot;togglePend()&quot; class=&quot;playbutton&quot;&gt;Play&lt;/button&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 7:&lt;/b&gt; Predicting the dynamics of the pixel pendulum. We train an HNN and its baseline to predict dynamics in the latent space of an autoencoder. Then we project the latent trajectory back to pixel space for visualization. The baseline model rapidly decays to lower energy states whereas the HNN remains close to ground truth even after hundreds of frames.&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function togglePend() {

		path = document.getElementById(&quot;pendImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;pend-compare.png&quot;) 
	    {
	        document.getElementById(&quot;pendImage&quot;).src = &quot;/assets/hamiltonian-nns/pend-compare.gif&quot;;
	        document.getElementById(&quot;pendButton&quot;).textContent = &quot;Reset&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;pendImage&quot;).src = &quot;/assets/hamiltonian-nns/pend-compare.png&quot;;
	        document.getElementById(&quot;pendButton&quot;).textContent = &quot;Play&quot;;
	    }
	}
&lt;/script&gt;

&lt;p&gt;For full disclosure, we did end up adding an auxiliary loss to the model in order to make the latent space look more like a set of canonical coordinates (see paper for details). However, this is not domain-specific and did not affect the performance of the autoencoder.&lt;/p&gt;

&lt;h2 id=&quot;other-mischief-with-hnns&quot;&gt;Other Mischief with HNNs&lt;/h2&gt;

&lt;p&gt;While the main purpose of HNNs is to endow neural networks with better physics priors, they have a few other nice properties. It’s worth touching on these before wrapping things up.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adding and removing energy.&lt;/strong&gt; So far, we have only integrated the symplectic gradient of the Hamiltonian. This keeps the scalar, energy-like value of \(\mathcal{H}(\mathbf{q},\mathbf{p})\) fixed. But we could just as easily follow the regular gradient of the Hamiltonian in order to increase or decrease \(\mathcal{H}\). We can even alternate between changing and conserving the energy-like value. Figure 8 shows how we can use this process to “bump” the pendulum to a higher energy level. We could imagine using this technique to answer counterfactual questions e.g. “What would have happened if we added 1 Joule of energy?””&lt;/p&gt;

&lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:100%&quot;&gt;
	&lt;img src=&quot;/assets/hamiltonian-nns/addenergy-static.png&quot; style=&quot;width:60%&quot; /&gt;
    &lt;img alt=&quot;&quot; src=&quot;/assets/hamiltonian-nns/addenergy.png&quot; style=&quot;width:25%;padding-bottom:35px&quot; id=&quot;energyImage&quot; /&gt;&lt;br /&gt;
    &lt;button id=&quot;energyButton&quot; onclick=&quot;toggleEnergy()&quot; class=&quot;playbutton&quot;&gt;Play&lt;/button&gt;
	&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 8:&lt;/b&gt; Visualizing integration in the latent space of the Pixel Pendulum model. We alternate between integrating the symplectic gradient at low energy (blue circle), the regular gradient (purple line), and then the symplectic gradient at higher energy (red circle).&lt;/div&gt;
&lt;/div&gt;

&lt;script language=&quot;javascript&quot;&gt;
	function toggleEnergy() {

		path = document.getElementById(&quot;energyImage&quot;).src
	    if (path.split(&apos;/&apos;).pop() == &quot;addenergy.png&quot;) 
	    {
	        document.getElementById(&quot;energyImage&quot;).src = &quot;/assets/hamiltonian-nns/addenergy.gif&quot;;
	        document.getElementById(&quot;energyButton&quot;).textContent = &quot;Reset&quot;;
	    }
	    else 
	    {
	        document.getElementById(&quot;energyImage&quot;).src = &quot;/assets/hamiltonian-nns/addenergy.png&quot;;
	        document.getElementById(&quot;energyButton&quot;).textContent = &quot;Play&quot;;
	    }
	}
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Perfect reversibility.&lt;/strong&gt; The HNN learns a vector field that has zero divergence. In other words, there are no sources or sinks. This means that we could integrate our model forward for an arbitrary amount of time and then run it backwards and exactly recover the original inputs. Check out the paper for more on this idea!&lt;/p&gt;

&lt;h2 id=&quot;closing-thoughts&quot;&gt;Closing Thoughts&lt;/h2&gt;

&lt;p&gt;Whereas Hamiltonian mechanics is an old and well-established theory, the science of deep learning is still in its infancy. Whereas Hamiltonian mechanics describes the real world from first principles, deep learning does so starting from data. We believe that Hamiltonian Neural Networks, and models like them, represent a promising way of bringing together the strengths of both approaches.&lt;/p&gt;

&lt;h2 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h2&gt;

&lt;p&gt;Thanks to the Google AI Residency for providing me with all the mentorship and resources that a young researcher could dare to dream of. Thanks to Nic Ford, Trevor Gale, Rapha Gontijo Lopes, Keren Gu, Ben Caine, Mark Woodward, Stephan Hoyer, and Jascha Sohl-Dickstein for insightful conversations and advice. Thanks to Jason Yosinski and Misko Dzamba for being awesome coauthors and for the informal conversations that sparked this work.&lt;/p&gt;

&lt;!-- &lt;div class=&quot;imgcap_noborder&quot; style=&quot;display: block; margin-left: auto; margin-right: auto; width:50%&quot;&gt;
	&lt;img style=&quot;width:50%&quot; src=&quot;/assets/hamiltonian-nns/cat.png&quot;&gt;
		&lt;div class=&quot;thecap&quot; style=&quot;text-align:left&quot;&gt;&lt;b&gt;Figure 9:&lt;/b&gt; Thanks To Misko&apos;s cat, Daisy, for being the most chaotic physical system of all the ones we considered.&lt;/div&gt;
&lt;/div&gt; --&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:fn1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Rupp, M., Tkatchenko, A., Muller, K.R., and Von Lilienfeld, O. A. &lt;a href=&quot;https://arxiv.org/abs/1109.2618&quot;&gt;Fast and accurate modeling of molecular atomization energies with machine learning&lt;/a&gt;. Physical review letters, 108(5): 058301, 2012. &lt;a href=&quot;#fnref:fn1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Schutt, K. T., Arbabzadah, F., Chmiela, S., Muller, K. R., and Tkatchenko, A. &lt;a href=&quot;Quantum chemical insights from deep tensor neural networks&quot;&gt;Quantum chemical insights from deep tensor neural networks&lt;/a&gt;. Nature communications, 8:13890, 2017. &lt;a href=&quot;#fnref:fn2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Lutter, M., Ritter, C., and Peters, J. &lt;a href=&quot;https://openreview.net/forum?id=BklHpjCqKm&quot;&gt;Deep lagrangian networks: Using physics as model prior for deep learning.&lt;/a&gt;, International Conference on Learning Representations, 2019. &lt;a href=&quot;#fnref:fn3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Battaglia P, Pascanu R, Lai M, Rezende DJ. &lt;a href=&quot;https://arxiv.org/abs/1612.00222&quot;&gt;Interaction networks for learning about objects, relations and physics&lt;/a&gt;. Advances in neural information processing systems, 2016 &lt;a href=&quot;#fnref:fn4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Schmidt, M. and Lipson, H. &lt;a href=&quot;https://science.sciencemag.org/content/324/5923/81&quot;&gt;Distilling free-form natural laws from experimental data&lt;/a&gt;. Science, 324(5923):81–85, 2009. &lt;a href=&quot;#fnref:fn7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:fn7:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;They also need to obey a set of relations called the Poisson bracket relations, but we’ll ignore those for now. &lt;a href=&quot;#fnref:fn5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;More generally, this quantity can be anything that does not change over time and has nonzero derivatives w.r.t. the coordinates of the system. But in this work we’ll focus on total energy. &lt;a href=&quot;#fnref:fn6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Wang, J., Olsson, S., Wehmeyer, C., Perez, A., Charron, N. E., de Fabritiis, G., Noe, F., and Clementi, C. &lt;a href=&quot;https://pubs.acs.org/doi/full/10.1021/acscentsci.8b00913&quot;&gt;Machine learning of coarse-grained molecular dynamics force fields&lt;/a&gt;. ACS Central Science, 2018. &lt;a href=&quot;#fnref:fn8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:fn9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;To see why energy is relative, imagine a cat that is at an elevation of 0 m in one reference frame and 1 m in another. Its potential energy (and total energy) will differ by a constant factor depending on frame of reference. &lt;a href=&quot;#fnref:fn9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>With Misko Dzamba and Jason Yosinski</name></author><summary type="html">Instead of crafting Hamiltonians by hand, we propose parameterizing them with neural networks and then learning them directly from data.</summary></entry></feed>