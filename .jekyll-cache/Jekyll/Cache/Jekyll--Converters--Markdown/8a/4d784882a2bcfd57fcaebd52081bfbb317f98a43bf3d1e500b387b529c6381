I"Å<div class="imgcap_noborder" style="display: block; margin-left: auto; margin-right: auto; width:100%">
  <img src="/assets/dissipative-hnns/hero.jpg" />
  <div class="thecap" style="text-align:left; display:block; margin-left: auto; margin-right: auto; width:100%">
  Dissipative HNNs (D-HNNs) output two scalar functions, denoted here by <i><b>H</b></i> and <i><b>D</b></i>. The first of these two, <i><b>H</b></i>, is the Hamiltonian. We use its symplectic gradient to model energy-conserving dynamics. The second, <i><b>D</b></i>, is the Rayleigh dissipation function. It models the dissipative component of the dynamics of a physical system. The addition of the dissipation function is what sets this model apart from Hamiltonian Neural Networks; it allows D-HNNs to model systems where energy is not quite conserved â€“ as, for example, in the case of a damped mass-spring system.
  </div>
</div>

<div style="display: block; margin-left: auto; margin-right:auto; width:100%; text-align:center;">
  <a href="https://arxiv.org/abs/2201.10085" id="linkbutton" target="_blank">Read the paper</a>
  <a href="https://github.com/greydanus/dissipative_hnns" id="linkbutton" target="_blank">Get the code</a>
</div>

<h2 id="a-sea-of-change">A sea of change</h2>

<p>We are immersed in a complex, dynamic world where change is the only constant. And yet there are certain patterns to this change that suggest natural laws. These laws include conservation of mass, energy, and momentum. Taken together, they constitute a powerful simplifying constraint on reality. Indeed, physics tells us that a small set of laws and their associated invariances are at the heart of all natural phenomena. Whether we are studying weather, ocean currents, earthquakes, or molecular interactions, we should take care to respect these laws. And when we apply learning algorithms to these domains, we should ensure that they, too, respect these laws.</p>

<p>We can do this by building models that are primed to learn invariant quantities from data: these models include HNNs, LNNs, and a growing class of related models. But one problem with this models is that, for the most part, they can only handle data where some quantity (such as energy) is exactly conserved. If the data is collected in the real world, and there is even a small amount of friction, then these models will struggle. In this post, weâ€™ll indroduce Dissipative HNNs, a class of models which can learn conservation laws from data even when energy isnâ€™t perfectly conserved.</p>

<div class="imgcap_noborder" style="display: block; margin-left: auto; margin-right: auto; width:100%">
  <img src="/assets/dissipative-hnns/sea_of_change.jpg" />
  <div class="thecap" style="text-align:left; display:block; margin-left: auto; margin-right: auto; width:100%">
  We live in a sea of change. But no matter how complex a system's dynamics are, they can always be decomposed into the sum of dissipative dynamics and conservative dynamics.
  </div>
</div>

<p>The core idea is to parameterize both a Hamiltonian <em>and</em> a Rayleigh dissipation function. During training, the Hamiltonian function fits the conservative (rotational) component of the dynamics whereas the Rayleigh function fits the dissipative (irrotational) component.</p>

<h2 id="how-it-works">How it works</h2>

<p>The Hamiltonian \(\mathcal{H}(\textbf{q},\textbf{p})\) is scalar function such that
\(\frac{\partial \mathcal{H}}{\partial \textbf{p}} = \frac{\partial \textbf{q}}{dt},  -\frac{\partial \mathcal{H}}{\partial \textbf{q}} = \frac{\partial \textbf{p}}{dt}\)</p>

<p>The Rayleigh dissipation function \(\mathcal{D}(\dot{\textbf{q}})\) is a scalar function that provides a way to account for generalized, velocity-dependent dissipative forcesâ€”such as frictionâ€”in the context of Hamiltonian mechanics. The equation below shows the Rayleigh function for linear, velocity-dependent dissipation. Here $\rho$ is a constant and $\dot q$ is the velocity coordinate.</p>

\[\mathcal{D} = \frac{1}{2}\rho\dot{q}^2\]

<p>Nonlinear, velocity-dependent dissipation forces \(F_i\) within the system can be accounted for as long as they are defined as 
\(F^{f}_i = -\frac{\partial \mathcal{D}(\dot{\textbf{q}})}{\partial \dot{\textbf{q}}}\)</p>

<h2 id="experiments">Experiments</h2>

<div class="imgcap_noborder" style="display: block; margin-left: auto; margin-right: auto; width:100%">
  <img src="/assets/dissipative-hnns/dampedspring.jpg" style="width:80%" />
  <div class="thecap" style="text-align:left; display:block; margin-left: auto; margin-right: auto; width:100%">
  Training a Dissipative Hamiltonian Neural Network (D-HNN) and several baseline models on a damped spring task. <b>Row 1.</b> We decompose the original dataset by interpolating the training data onto a grid with a nearest-neighbors approach and then decomposing the field into two components. In practice, we accomplish this using a few hundred iterations of the Gauss-Seidel method to solve Poisson's equation. <b>Row 2.</b> We train a D-HNN on the same data. The first half of this model looks exactly like an HNN. The second half also looks like an HNN, except we use the gradient of the scalar field directly rather than rearranging it according to Hamilton's equations. This gives us a trainable \textit{dissipative} field which is able to model the dissipative components of the damped spring's dynamics. Summing these two fields, we obtain an accurate model of the dynamics of the system. <b>Row 3.</b> We train the baseline model (MLP) on the training set; this model gives a good fit and can be integrated as a Neural ODE, but it cannot be used to decompose the field into conservative and dissipative components. <b>Row 4.</b> We train a Hamiltonian Neural Network (HNN) on the same dataset and find that it is only able to model the conservative component of the system's dynamics. In other words, it strictly enforces conservation of energy in a scenario where energy is not actually conserved.
  </div>
</div>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>D-HNNs build on the foundations of HNNs by bridging the gap between the clean, natural symmetries of physics and the imperfect, messy data often found in the real world. They employ the tools of Hamiltonian mechanics and Helmholtz decomposition to separate conserved quantities from dissipative quantities. In doing so, they allow us to model complex physical systems while enforcing strict conservation laws. They represent a small, practical advance in that they can help us see our datasets, like the ocean currents dataset, in a new way. And at the same time, they represent progress towards the more ambitious goal of building models which make sense of the incredible complexity of the real world by focusing on its invariant quantities.</p>

<h2 id="footnotes">Footnotes</h2>

:ET