I"æ1<p>This post is a little more exotic than usual. I‚Äôm posting it with humility ‚Äì ready to be shown where my reasoning is flawed. If I learn that I was wrong, I will update or remove this post as necessary.</p>

<h2 id="the-universe-as-a-simulation">The universe as a simulation</h2>

<p>Let‚Äôs imagine the universe is being simulated. Based on what we know about physics, what can we say about how it would be implemented? Here are a few ideas. It would have:</p>

<ol>
  <li><strong>Massive parallelism.</strong> By taking advantage of the fact that all interactions are local, one could parallelize the simulation in a dramatic way. Spatially adjacent parts of the simulation would be run on the same CPUs and spatially distant parts would be run on separate CPUs.</li>
  <li><strong>Conservation laws enforced.</strong> Physics is built on the idea that certain quantities are strictly conserved. Scalar quantities like mass-energy are conserved. So are vector quantities like angular momentum and polarization.</li>
  <li><strong>Binary logic.</strong> Our computers use discrete, binary logic to represent and manipulate information. Non-discrete numbers are represented with sequences of discrete symbols (see <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">float32</a>). Let‚Äôs assume our simulation does the same thing.</li>
  <li><strong>Adaptive computation.</strong> A lot more happens in some times and places than in others. To simulate the universe efficiently, we would want to use a particle-based (Lagrangian) simulation where most computation is spent simulating regions with high mass-energy density.</li>
</ol>

<p>We can check to see whether these are good assumptions by looking at whether they hold true for existing state-of-the-art physics simulations. They appear to hold true for the best <a href="https://www.myroms.org/">oceanography</a>, <a href="https://confluence.ecmwf.int/display/S2S/ECMWF+model+description">meteorology</a>, <a href="https://arxiv.org/abs/0810.5757">plasma</a>, and <a href="https://en.wikipedia.org/wiki/Computational_fluid_dynamics">computational fluid dynamics</a> models. So, having laid out some basic assumptions about how our simulation would be implemented, let‚Äôs look at their implications.</p>

<h2 id="enforcing-conservation-laws-in-parallel">Enforcing conservation laws in parallel</h2>

<p>The first thing to see is that assumptions 1 and 2 are in tension with one another. In order to ensure that a quantity (eg. mass or energy or mass-energy) is conserved, you need to sum that quantity across the entire simulation, determine whether a correction is needed, and then apply that correction to the system as a whole. Computationally, this requires a synchronous reduction operation and an element-wise divide across the whole system ‚Äì and this has to be done at virtually every simulation step. When you write a single-threaded physics simulation, this can account for about half of the computational cost (these <a href="https://github.com/greydanus/optimize_wing/blob/3d661cae6ca6a320981fd5fc29848e1233d891cd/simulate.py#L57">fluid</a> and <a href="https://github.com/google-research/neural-structural-optimization/blob/1c11b8c6ef50274802a84cf1a244735c3ed9394d/neural_structural_optimization/topo_physics.py#L236">topology</a> simulations I wrote are good examples).</p>

<p>As you parallelize the simulation, you can expect the cost of enforcing conservation laws to grow much higher. This is because simulating interactions between adjacent particles is pretty easy to do in a parallel and asynchronous manner. But enforcing system-wide conservation laws requires transferring data between distant CPU cores and keeping them more or less in sync. As a result, enforcing conservation laws in this manner quickly grows to be a limiting factor on runtime.</p>

<p>We may ask if perhaps there is some other way to enforce conservation laws without tallying conserved quantities across the entire simulation at each step. Probably yes! One way to do this is to quantize the conserved quantity. For example, we could quantize energy and then only transfer it in the form of discrete packets.</p>

<p>To see why this would be a good idea, let‚Äôs use financial markets as an analogy. Financial markets are massively parallel and keeping a proper accounting of the total amount of currency in circulation is a priority for everyone involved. The solution is to allow currency to function as a continuous value on a practical level, but to quantize it by making small measures of value (pennies) indivisible. For similar reasons, we‚Äôd want to quantize energy.</p>

<h2 id="conserving-vector-quantities">Conserving vector quantities</h2>

<p>Quantization may work well for conserving scalar values like energy. But what about conserving vector quantities like angular momentum? In these cases, rotational symmetry makes things difficult. Imagine two particles with angular momentum vectors pointing in arbitrary directions. When we compute the angular momentum of the entire system, odds are we will get an irrational number. There is simply no way to quantize the directions of the two particles‚Äô angular momentum vectors so that the sum of the two is also quantized without sacrificing rotational symmetry.</p>

<p>So how are we to implement exact conservation of vector quantities without sacrificing rotational symmetry? One option is to require that a particle‚Äôs vector quantities always be defined in reference to some other particle‚Äôs vector quantities. This could be implemented by creating multiple <a href="https://en.wikipedia.org/wiki/Pointer_(computer_programming)">pointer references</a> to a single variable and then giving each of those pointers to a different particle. As a concrete example, we might imagine an atom releasing energy in the form of two photons. The polarization angle of the first photon could be expressed as a pointer to variable <code class="language-plaintext highlighter-rouge">x</code> and the polarization of the second photon could be expressed as a 90\(^\circ\) rotation of a pointer to variable <code class="language-plaintext highlighter-rouge">x</code>. As we move our simulation forward, the polarization angles of the two photons would change over time and perhaps some small integration errors would accumulate. But even when that happens, we could still say with confidence that the net polarization of the two photons would be zero because they are defined using the same latent variable.</p>

<p>This approach comes at a price. It demands that we sacrifice locality: the principle that an object is influenced directly only by its immediate surroundings. It‚Äôs one of the most sacred principles in physics. This gets violated in the example of the two photons because a change in the polarization of the first photon will update the value of <code class="language-plaintext highlighter-rouge">x</code>, implicitly changing the polarization of the second photon.</p>

<p>Interestingly, the mechanics of this nonlocal relationship would predict the violation of <a href="https://www.youtube.com/watch?v=zcqZHYo7ONs&amp;vl=en">Bell‚Äôs inequality</a>. Physicists agree that the violation of Bell‚Äôs inequality implies that nature violates either realism (the principle that reality exists with definite properties even when not being observed) or locality. Since locality is seen as a more fundamental principle than realism, the modern consensus is that quantum mechanics violates realism: in other words, that entangled particles cannot be said to have deterministic states and instead exist in a state of superposition until they are measured. But in our simulated universe, realism would be preserved whereas exact locality would be sacrificed. Entangled particles could be said to have definite states at all times, but sometimes those states would change due to ‚Äú<a href="https://www.quantamagazine.org/how-bells-theorem-proved-spooky-action-at-a-distance-is-real-20210720/">spooky action at a distance</a>.‚Äù</p>

<h2 id="explaining-the-double-slit-experiment">Explaining the double slit experiment</h2>

<p>Our findings thusfar may lead us to ask whether other quantum mechanical phenomena can be explained with the simulation <em>ansatz</em>. The double slit experiment is an interesting example. It cannot be explained using the arguments about conservation laws that we made above. And yet, there are is a good argument to be made that simulating the universe could lead to wave-particle duality.</p>

<p>The important idea here is filtering. <a href="https://en.wikipedia.org/wiki/Filter_(large_eddy_simulation)">Filtering</a> is a common technique where a Gaussian or cone filter is convolved with a grid in order to smooth out the physics on the grid, make it appear as though the physics were occuring on a continuous medium. This step is absolutely essential; the the <a href="https://github.com/greydanus/optimize_wing/blob/3d661cae6ca6a320981fd5fc29848e1233d891cd/simulate.py#L83">fluid</a> and <a href="https://github.com/google-research/neural-structural-optimization/blob/1c11b8c6ef50274802a84cf1a244735c3ed9394d/neural_structural_optimization/topo_physics.py#L84">topology</a> simulations I wrote did not work properly until I added filtering.</p>

<p>How would one implement filtering in a large-scale particle-based simulation of the universe? Well, if the simulation were adaptively integrated across space, it would be hard to apply a Gaussian or cone filter. An alternative would be to use ensembles to simulate the dynamics of every particle. You could initialize a cloud of particles with slightly different initial conditions and then simulate all of them through time. If you allowed them to interact with one another then collectively they could behave like a wave.</p>

<p>Now you might notice that there is a tension between this spatially delocalized, wave-like behavior (a consequence of filtering, which is related to assumption 3) and the exact conservation and therefore quantization of quantities like energy (assumption 2). The tension is this: when a wave interacts with an object, it transfers energy in a manner that is delocalized and in proportion to its amplitude at a given location. But we have decided to quantize energy in order to keep an exact accounting of it across our simulation. So when our ensemble of particles interacts with some matter, it must transfer exactly one quanta of energy and it must do so at one particular location.</p>

<p>The simplest way to implement this would be to choose one particle out of the ensemble and allow it to interact with other matter and transfer energy. The rest of the particles in the ensemble would be removed from the simulation upon coming into contact with other matter. This approach would reproduce the empirical results of the double slit experiment in a fully deterministic manner.</p>

<h2 id="testing-this-theory">Testing this theory</h2>

<p>Suppose all of the ideas we have discussed are true. How would we be able to test them? And how would we show that quantum mechanical system sacrifice locality but preserve realism?</p>

<p>I can‚Äôt think of a good way to do it yet. I have the sense that it could be done by modifying the polarizer apparatus used by Clauser and Horne (1974) to test Bell‚Äôs theorem. So far I haven‚Äôt the faintest idea how it could be modified so as to rule out realism and demonstrate the particular flavor of nonlocality we‚Äôve described in this post.</p>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>To the followers of Plato, the world of the senses was akin to shadows dancing on the wall of a cave. The essential truths and realities of life were not to be found on the wall at all, but rather somewhere behind you in the form of real dancers and real flames. A meaningful life was to be spent seeking to understand those forms, elusive as they might seem.</p>

<p>The philosophy behind modern physics, by contrast, is less optimistic about how much we can know about our world. ‚ÄúPhysics is not about how the world is,‚Äù wrote Niels Bohr, ‚Äúit is about what we can say about the world.‚Äù Such a statement implies that there are certain truths about nature which are fundamentally unknowable.</p>

<p>The ideas we have presented in this post sacrifice the principle of locality. But in doing so, they restore the principle of realism. They suggest that the nature of the universe is much stranger than we may have thought, and yet it may still operate according to definite rules. If this is true, then modern physics may be able to depart from Bohr‚Äôs restricted definition and return to its Platonic roots.</p>
:ET